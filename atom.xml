<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Wolfeyes Bioinformatics beta]]></title>
  <link href="http://yagays.github.io/atom.xml" rel="self"/>
  <link href="http://yagays.github.io/"/>
  <updated>2014-12-08T16:46:15+09:00</updated>
  <id>http://yagays.github.io/</id>
  <author>
    <name><![CDATA[yag_ays]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[「「ニセ医学」に騙されないために」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/12/08/review-natrom-quackery/"/>
    <updated>2014-12-08T00:05:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/12/08/review-natrom-quackery</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4895958647" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>はてな界隈ではみなさんご存知NATROM先生の著作．題名の通り「ニセ医学」と呼ばれる根拠のない病気の治療であったり健康になるための謳い文句について，個々の豊富な事例をもとにその真偽を検証し事実を明らかにしていくという本書．おそらくNATROM先生がこれまでに書きためてきたblog記事が元になっているとは思うが，恐らくほぼすべての文章を書き下ろしているであろう本書は，より一般読者向けの内容になっており1冊の書籍として非常に読みやすい．</p>

<p>当然ながら本書は一貫して科学的なスタンスで進んでいく．ただ頭ごなしに否定するのではなく，きちんと相手の意見を踏まえた上での反証や矛盾を突いた意見を述べることで，一つ一つ検証していく．例えば本書の最初に出てくる「日本人は薬中毒か」という問いには国際的に集計された医療統計を出して反証し，その背景にある日本の過去の医療事情を引き合いに出す．</p>

<p>それに加えて，良くある論調として「医者や政府は利益のための重大なことを隠している！」ということがあるが，それについても医者と保険者と患者の関係性についてきちんと解説している点が評価できる．というよりこの辺りは実際に中の人に解説してもらわないと見えてこない部分もあるので，概要ながらも内情について知ることができたのは良かった．当たり前といえばそうなんだけれども，日本であれば国民皆保険制度を元にした医療行為への支払いを考えれば明らかなんだと感じる．</p>

<p>本書を読めば誰でもニセ医学を暴けるかというと，必ずしもそうはならない．「健康」という分野は広大でかつ未だに未知の領域だ．医学的な知識のみならず，栄養学といった他分野であったり統計の素養が必要になる．そういうときに，目に入る情報すべてについて元論文を当たったり検証することは不可能だ．結局は「人の甘い言葉に乗るな」ということになるのだけれども，人間というものは親族が病気にかかったり心的余裕が無いときには，つい藁をもつかむ思いで騙されてしまうものだ．それは本書著者も指摘しておりかつそれを悪いとは言っていない．そこに漬け込むニセ医者や悪徳業者が悪いのであって，それについてきちんと追求していくことは医療従事者や政府の社会的責任といえる．そういう意味で，出版社を背後に堂々と批判しづらい現状において，本書は非常に価値ある出版だと思う．それと同時に，日頃から自衛できるような知識を身につけること，そこまでいかなくても注意を払うことの大事さを思い直す1冊だった．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「国際メディア情報戦」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/12/07/review-international-media-iw/"/>
    <updated>2014-12-07T00:01:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/12/07/review-international-media-iw</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4062882477" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p><a href="http://yagays.github.io/blog/2014/12/06/review-bosnian-war-and-pr/">「ドキュメント 戦争広告代理店〜情報操作とボスニア紛争」</a>の高木徹氏の2014年の著作．前作は1990年代のボスニア紛争を題材にした作品だったが，今回はその後の21世紀に起こったテロリズムの台頭とメディアを取り巻く情報戦について書かれている．前作と比較して全体的に情報の厚みが薄く物足りない部分も見受けられるが，それでも著者ならではのポイントを抑えた簡潔な解説を読むことができる．</p>

<p>本書冒頭は「戦争広告代理店」のおさらいといった立ち位置で，ボスニア紛争での民間PR会社の影響力を振り返るというもの．当時の取材時の印象であったり後日談的なものが少し加えられている．そしてその次に取り上げられる題材が，オサマ・ビン・ラディンとアメリカの対テロ戦争である．そもそものオサマ・ビン・ラディンがいかに情報戦に優れていたか，そのオサマ・ビン・ラディンが殺害された後の主導者不在の中でのテロリズムの変化，それらと対峙してきたアメリカの政党や大統領候補同士での情報戦などが語られる．この時代の情報戦では，ボスニア紛争で登場しなかったインターネットであったりSNS，動画共有サイトなどが登場し，TV放送局のグローバル展開も相まって，情報戦はより一層複雑化する．例えば，アルジャジーラというカタールの国際衛星ニュース局が，イスラム過激派による映像を頻繁に放送していたことはまだ記憶に新しいが，このメディアをうまく活用したのがオサマ・ビン・ラディンだったという．一方でアメリカも，メディアをうまく活用した情報公開の戦術によって，オサマ・ビン・ラディン殺害の正当性を主張したり，オサマ・ビン・ラディン自体の神格化を防ぐように悪いイメージを植え付けるようなことを行ったとされる．</p>

<p>本書で出てくる個々の事実は日本でもニュースで放送されるものばかりだが，本書のような専門家の見る目をもってして解説されると，その本質が見えてくる．ではそういった情報に私たちはどう向き合っていけばいいのか，高木徹氏は本書あとがきでこのように述べている．</p>

<blockquote><p>問題の解決は、私達一人一人情報の受け手に託されている。自分のもとに届く情報が、そこまでにどのような「情報戦」をくぐり抜けてきたかを考える。それを続けていれば、自分なりの真実と世界観を自分の中に形成できるようになる。それをまた他の情報と比較して検証してみる。</p>

<p>「国際メディア情報戦」の時代を生き抜くには、そのようにして情報戦そのものを「楽しむ」ような余裕とタフさが必要なのではないかと私は考える。</p>

<p><a href="http://www.amazon.co.jp/gp/product/4062882477/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=4062882477&linkCode=as2&tag=yagays-22">国際メディア情報戦 (講談社現代新書)</a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=yagays-22&l=as2&o=9&a=4062882477" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /> (pp. 258-259)</p></blockquote>

<p>本書も含め，真の意味で中立な立場で解説してくれる人は誰もいない．他人からもたらされる情報は常に他人の思想や立場によって切り取られ加工されたものであることを強く意識して，身の回りにあふれる情報と向き合っていかなければならないと思い知らされる．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「ドキュメント 戦争広告代理店〜情報操作とボスニア紛争」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/12/06/review-bosnian-war-and-pr/"/>
    <updated>2014-12-06T00:00:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/12/06/review-bosnian-war-and-pr</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4062750961" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>戦争は情報戦だといった話はよく耳にするが，それが常に秘密軍事工作といった影の存在とは限らない．通信手段の発達によってメディア報道が高速化し，国際世論の形成がより迅速かつ平等になった現代において，真の情報戦とは国民や国家に向けられたオープンな場が舞台であることを，本書は露わにする．</p>

<p>本書「戦争広告代理店」は，ボスニア紛争を影で操ったフィクサーが実は米国PR会社だったという衝撃のドキュメンタリーだ．クウェート侵攻後の1990年台において勃発した旧ユーゴスラビア地域における民族対立は，アメリカにとって石油利権も何もない辺境の地でのただの紛争の1つだった．唯一知られていることは1984年にボスニア・ヘルツェゴビナ共和国首都のサラエボで冬季オリンピックが開催されたことだけ．そのような状態のアメリカに，自国の支援を訴えてボスニア・ヘルツェゴビナ共和国の一人の外務大臣が降り立つところから話は始まる．</p>

<p>何より本書の内容に驚きを覚えるのは，紛争という国家間の衝突に民間会社が介入していることだろう．それも政治の中枢にまで入り込み，必要とあらば国連での国際会議の討論原稿すら書き上げるような，そんな民間PR会社が存在することだ．そしてそれがボスニア紛争の世論形成にどれほどの影響力を及ぼしてきたかということに尽きる．それが奇しくも，民間PR会社の協力を得られたボスニア・ヘルツェゴビナ共和国側と，民間PR会社の協力が得られなかったセルビア共和国・ユーゴスラビア連邦側の2局にきれいに分かれたということも，民間PR会社の実力を如実に示している．</p>

<p>結果的に世論は，モスレム人(ムスリム)を中心としたボスニア・ヘルツェゴビナ共和国が，セルビア人を中心としたセルビア共和国に弾圧されているという構図となった．善と悪，弱き者と強き者といった単純な構造を世論は好む．民間PR会社はこの対立構造を巧みに作り上げ，顧客を悲劇の主人公に仕立てあげたということだ．唯一言えるのは，この紛争に対するアメリカの世論が，メディアによる公正な報道と法のもとでの正義によって自然に組み上がったわけでは決して無いということだろう．</p>

<p>著者は本書の最後で，今回の取材の総まとめとしてのボスニア紛争について「どちらにも責任がある」とした上で，PRの重要性とその効果，情報操作の倫理的側面について考察している．いくらマスコミの偏向報道が悪い，情報操作は良くない，正義は中立であるべきだ，といった綺麗事を並べても，世論自体がそれに答えてくれるわけではない．本書で描かれるような事実をもとにして，如何に自分を中心としたコミュニティが成功を収めるか，そのことについて真剣に考えていかなければならない．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「黒幕: 巨大企業とマスコミがすがった「裏社会の案内人」」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/12/05/review-kuromaku/"/>
    <updated>2014-12-05T13:01:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/12/05/review-kuromaku</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4093798656" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>企業向けの情報誌「現代産業情報」を刊行し，兜町の石原と呼ばれた情報屋である石原俊介を追ったノンフィクション作品．彼と親睦の深かった同業者の著者が，石原俊介が生きた時代に起きた平和相銀事件やリクルート事件などの政官財を巻き込む事件を中心に，その仕事の軌跡を紐解いていく．</p>

<p>そもそも私に本書を読むためのバックグラウンドが無いのは当然といえば当然で，本書に登場する平和相互銀行をはじめとした数々の銀行の名前は，私が物心付いた頃にはもう既になくなっており，かろうじて現在の大手銀行の名前に名残があるくらいだ．当然ながら，そういった銀行が起こしてきた事件はそもそもあったことすら知らなかった．そういう状態で本書を手に取ったものの，自分の知識不足を感じることはほとんどなかったと思う．事件の概要から始まり，中心人物たちの経歴，まだ総会屋が活躍し暴力団が今ほどに影を潜めてなかった時代の世相，そして石原の仕事とその役割など，そういった事件を多面的に理解するための材料はひと通り本書の中に揃っていた．そもそもが業界の裏を書いたノンフィクションであり，他の読者も私と同様に知識を持ち合わせていない人が大多数なのだろう．そういう意味で，読者を選ばないような丁寧な解説ぶりが印象に残る．</p>

<p>一方で，あまりに自分の世界とかけ離れていて想像が及ばない部分もある．そもそもの高度経済成長期からバブル崩壊までの日本，情報誌というものが重宝された時代，そして政官財の世界．過去のことだと割り切ってなかば昔話として考えることも可能だけれども，とりあえずはいままで見聞きしたことや本書を読んで学んだことをもとに再構築していくしかない．</p>

<p>ただそこに存在した情報屋の価値は，今でもはっきりとわかる．インターネットで様々な情報が瞬時に手に入る時代だからこその，生の情報の大切さ．新聞やマスコミの偏向が明らかになるほどに，情報というものがいかに不確実なもの，一つの側面を映し出したにすぎないということがわかってくる．そういうときに，石原俊介のような情報屋が，利害や契約関係を超えて情報誌として告発や批判記事を公開することや，相談役としての企業へのアドバイスが重宝された理由というものがわかる．と同時に，それが並大抵の人では不可能なほどに難しく，稀有な存在であったことも事実だ．本書では石原がそれを成し得た理由というものが各所で考察されるが，彼の卓越した情報処理能力や立場を限定しない取材態度，銀座のクラブを起点とした情報のハブとしての役割など，その仕事術の一端を垣間見ることができる．</p>

<p>個人的な経験として，インターネットに本格的に触れ始めた時に叩きこまれた教訓として「情報というのもは自ら発信することによって集まってくる」ということがある．本書はある意味でその教訓をまさに体現する1冊として，興味深い内容だった．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「世界を変えた確率と統計のからくり134話」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/11/15/review-probability-and-statistics-134-stories/"/>
    <updated>2014-11-15T15:41:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/11/15/review-probability-and-statistics-134-stories</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4797376023" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>本書はむしろ確率論・統計学の科学史についてのライトな読み物だ．著者は本書のことを「確率や統計の教科書にあるようなコラムをまとめて1冊にした本」のように言い表しているが，そういった欄外の豆知識にとどまらない，科学史としての体系だった内容になっている．</p>

<p>本書は基本的に確率や統計にまつわる逸話をもとにして，その背景にある数学的な理論であったり，数学の一分野として発展してきた歴史やそれを支えた数学者を紹介するという流れになっている．例えば「サイコロを4回振って6の目が1回以上出る確率と，2つのサイコロを24回振って6のゾロ目が1回以上出る確率をそれぞれ求めよ」(本書P.25より)といった具体的な問題から，当時の天才数学者のだれそれが分野の発展に一役買っただとか，数学者の名前が付けられた定理や手法は数あれど実際に初めてそれを発見した人物の名が付けられていない場合が多いといった逸話などが，本書題名にある通りいくつも盛り込まれている．</p>

<p>取り扱う確率や統計の内容だって．そこいらの教科書に引けを取らない充実ぶりだ．むしろ本書は歴史的経緯や逸話と絡めて紹介されるぶん，教科書よりもはるかに分かりやすいところも多い．例えば，母関数とジッシャーマン・ダイスの例なんてのは目から鱗だった．それこそ教科書では何故そのような関数が出てくるかなんて分からなかったから，実際の使い方を見ることで私はやっと腑に落ちた．具体的な内容はぜひ本書を読んでもらいたい．そういった点で，確率や統計について既に知識がある人でも，どれだけ勉強してもいまだに苦手意識が拭えない人にとっても面白い内容だと思う．</p>

<p>確率や統計の科学史に関する読み物だと「<a href="http://www.amazon.co.jp/gp/product/4532351944/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=4532351944&linkCode=as2&tag=yagays-22">統計学を拓いた異才たち―経験則から科学へ進展した一世紀</a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=yagays-22&l=as2&o=9&a=4532351944" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />」や「<a href="http://www.amazon.co.jp/gp/product/4794220014/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=4794220014&linkCode=as2&tag=yagays-22">異端の統計学 ベイズ</a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=yagays-22&l=as2&o=9&a=4794220014" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />」があり，本書後半でもたびたびこの2冊の内容に触れている．ただし，これらの本はかなり分量があり，この分野に関する前提知識もそれなりに要求される．その点本書は基本的な部分についてもその都度きちんと解説が入るし，解説を読み飛ばしたとしても問題ないようになっている点で，気構えず読み進められる1冊となっている．</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4532351944" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>


<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4794220014" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[L1 regularizationのLassoはなんと発音するのか？]]></title>
    <link href="http://yagays.github.io/blog/2014/11/06/lasso-pronunciation/"/>
    <updated>2014-11-06T18:12:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/11/06/lasso-pronunciation</id>
    <content type="html"><![CDATA[<blockquote class="twitter-tweet" lang="en"><p>LASSOの発音、ラスーみたいな感じなのか</p>&mdash; 便所糞虫 (@y_benjo) <a href="https://twitter.com/y_benjo/status/530274684097421312">November 6, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>


<h4>Lassoの発音</h4>

<p>今まで<a href="http://en.wikipedia.org/wiki/Least_squares#Lasso_method">Lasso</a>はラッソだと思っていたのだけれども，どうやら違うらしい．YouTubeにある幾つかの動画で確認してみると，ラッソというよりかはラッスーに近い．無理矢理カタカナで書くと「ラッスゥー」で，スにアクセントがある感じ．</p>

<p>実際の発音は以下の動画で確認できる．発音している箇所に動画再生ポイントを合わせてあるので，聞き逃しに注意．</p>

<iframe width="560" height="315" src="http://yagays.github.io//www.youtube.com/embed/UvxHOkYQl8g?start=620" frameborder="0" allowfullscreen></iframe>


<p>ちなみにこれは<a href="http://www.amazon.co.jp/gp/product/B00475AS2E/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=B00475AS2E&linkCode=as2&tag=yagays-22">The Elements of Statistical Learning</a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=yagays-22&l=as2&o=9&a=B00475AS2E" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />でお馴染みのHastie&amp;Tibshirani先生の動画．</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=432012362X" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>




<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=0387848576" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>


<p>他にも幾つか確認してみたが，同様の発音だった．</p>

<iframe width="560" height="315" src="http://yagays.github.io//www.youtube.com/embed/PKXpaLUigA8?start=952" frameborder="0" allowfullscreen></iframe>




<iframe width="420" height="315" src="http://yagays.github.io//www.youtube.com/embed/XDtgZFIXDds?start=1390" frameborder="0" allowfullscreen></iframe>


<h4>実際にはどちらの発音もある</h4>

<p>ただし，オンライン辞書で調べてみると，どうやらどちらの発音もあるらしい．British Englishだと「ラッスゥー」，American Englishだと「ラッソ」，と発音しているようだ．なので厳密にはどちらでも間違いではないけれども，機械学習の文脈で発音するときには「ラッスゥー」が無難かもしれない．</p>

<ul>
<li><a href="http://dictionary.cambridge.org/pronunciation/british/lasso">lasso - pronunciation of lasso by Cambridge Dictionaries Online</a></li>
<li><a href="http://www.oxforddictionaries.com/definition/english/lasso">lasso: definition of lasso in Oxford dictionary (British &amp; World English)</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「Think Simple―アップルを生みだす熱狂的哲学」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/10/25/review-think-simple/"/>
    <updated>2014-10-25T13:13:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/10/25/review-think-simple</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4140815450" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>Appleのデザイン哲学とともいうべき本書は，&#8221;Think Different&#8221;やiMacのマーケティングに携わってきたクリエイティブディレクターのケン・シーガルによるAppleのマーケティング戦略の裏側を描いている．Appleにおけるスティーブ・ジョブズの異常なまでのデザインへのこだわりは有名であり，なぜそれが成功したのか，今までの大企業ができなかったことがなぜできたのか，その哲学を第三者の視点から捉えようとする書籍は多数出版されている．しかし本書は，実際にスティーブ・ジョブズとともにマーケティングのパートナーとしてAppleのブランドとマーケティング戦略を作り上げてきた人物によるものだ．奇しくも彼が関わっていたのは，Appleが一度スティーブ・ジョブズの手から離れた後の凋落の時期と，スティーブ・ジョブズ復帰後の華麗な復活を遂げるまでの間である．製品としてはiMacが生まれiPodが生まれ，Appleという会社のイメージが洗練された時代である．その内部で何が行われていたのかが本書にはこれでもかというくらい詰め込まれている．キーワードはもちろん「シンプル」だ．</p>

<p>この本は読んでいると不思議な気分になる．どこを切り取ってもおんなじことしか書いてないように思えるのだ．少なくとも全10章，Think Brutalにはじまり，Small, Minimal, Motion,Iconic,Phrasal,Casual,Human,Skeptic,Warというそれぞれの考え方に分かれているものの，出てくる逸話はどれも「Appleらしさ」以外の何者でもないという感じだ．もちろんスティーブ・ジョブズというAppleそのものを体現する人物が出ているというのもあるのだが，著者らの考え方であったり，マーケティングという理詰めでは不可能な課題に対するアプローチは，一貫して私たちが想像するAppleそのものだ．</p>

<p>このようにAppleのデザイン哲学を知ることができる一方で，スティーブ・ジョブズの芸術肌によって独裁的に決められていったわけではないことも次第に見えてくる．言ってみればスティーブ・ジョブズの失敗談だ．自分の感性を強く信じる一方で，人に意見を求めることが多かったり，周囲の意見も広く取り入れたようだ．例えば，初代iPodのシルエットのCMを最初は嫌がったり（それまで白が背景のシンプルなCMが多かったから），iMacを当初はMacManと付けようとしたり，今となっては信じられないような話が出てくる．スティーブ・ジョブズのマーケティングに対する考え方や彼の人となりを知ることができる興味深い1冊だった．</p>

<p>これだけApple流のマーケティングが成功していても，依然としてスペックを売りにした広告や人間が読むのを想定していないような商品名が出てくるのは何故なんだろうなというのが，本書を読めば分かる．みんな気付いてはいるし理想だってあるんだけれども，大企業という構造の中でいつの間にか無難なものへと変わっていくのだ．著者がAppleとともにマーケティングを担当したデルやインテルが失敗例として挙げられていて少々可哀想だが，そこから得られる教訓は大きい．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「How Google Works ―私たちの働き方とマネジメント」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/10/24/review-how-google-works/"/>
    <updated>2014-10-24T18:40:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/10/24/review-how-google-works</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4532319552" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>Google前CEOのエリック・シュミットと前プロダクト担当シニア・バイスプレジデントのジョナサン・ローゼンバーグが出した本書「How Google Works」は，21世紀の新しい社会の働き方を決定付ける1冊になるのは間違いない．それは現在もっとも成功している会社として，そしてもっとも今の社会に則した働き方として迎え入れられることになるだろう．インターネットや様々な技術の普及によって私たちの生活が変わったように，私たちの働き方も変える必要がある．その下地はインターネットの普及によって進み，そしてGoogle自体がそれに沿うようにともに作り上げてきたといえる．その試行錯誤の結果，失敗と成功，それらの一部始終が本書には詰まっている．</p>

<p>本書は，Googleにまつわる文化，戦略，人材，意思決定，コミュニケーション，イノベーションという6つの章から成り立っているが，そのどれもに共通しているのが人の大切さである．Googleはエンジニアの会社だ．それはセルゲイ・ブリンとラリー・ペイジが会社を興した時から変わらない．本書ではGoogleが雇いたいと思う有能な人材のことを「スマート・クリエイティブ」と呼ぶ．スマート・クリエイティブとは，知的労働において専門性と創造性を併せ持つ人材のことを指し，旧来のナレッジワーカーとは別のタイプだという．そのスマート・クリエイティブが最大限に成果を生み出せるような場所を作り上げるのが会社の目的だ．そのために人材を雇用し，会社のシステムを作り上げたといえる．例えば，おもちゃの散乱した遊び場のようなイメージで有名なGoogleも，実際に机に向かうオフィス部分では手を伸ばせば隣の人に届くようなスペースに社員を詰め込んで，お互いにコミュニケーションが生まれるようなデザインにしているという．これも文化の一つとしてよく知られていることだが，きちんとした理由が裏にはある．</p>

<p>この他にも本当にたくさんのGoogleらしさが本書には詰まっている．明日から実践できそうなことや，そもそも成功しているGoogleじゃないと到底できそうにないこと，そもそもスマート・クリエイティブなんてどこにいてどうやったら採用できるんだといったことまで様々だ．少なくともこれまで数々のGoogleにまつわる本が出版されてきたが，この本ほどGoogleの本質に迫るものは無いだろう．とにかく読んでみて，Googleという巨人の巨人たる所以に触れてみてほしい．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[私は如何にしてKaggleで9位から600位台まで順位を落とし，private leaderboardでベンチマークすら下回ったか？]]></title>
    <link href="http://yagays.github.io/blog/2014/10/23/kaggle-africa-soil-property-prediction-challenge/"/>
    <updated>2014-10-23T06:55:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/10/23/kaggle-africa-soil-property-prediction-challenge</id>
    <content type="html"><![CDATA[<p>タイトルは釣りです（元ネタ：<a href="http://d.hatena.ne.jp/repose/20120723/1343025035">過学習の恐怖，またはいかにして私は1分間でランキングを50位も落としたか(要約) - 糞ネット弁慶</a>）</p>

<h3>Africa Soil Property Prediction Challenge</h3>

<p>8月終わりからKaggleで行われていた<a href="https://www.kaggle.com/c/afsis-soil-properties">&#8220;Africa Soil Property Prediction Challenge&#8221;</a>，通称AfSISが終わりました．このコンペは衛星から取得したアフリカの各地点の吸光度などの数値情報を元に，その場所のSOC,pH,Ca,P,Sandの計5種類の地質学的な測定値を推定するという問題でした．問題設定としては定番っぽくて取っ付き易いものの，実際にやってみるとこれまた難しい感じでした．</p>

<p>私は開催当初から参加していて，一時期9位まで上がったものの，そこから何もしなかったらどんどん抜かされたというわけです．</p>

<blockquote class="twitter-tweet" lang="en"><p>Hold my calls. Top 10 on <a href="https://twitter.com/hashtag/kaggle?src=hash">#kaggle</a> - <a href="https://t.co/EUmPGDB0oq">https://t.co/EUmPGDB0oq</a></p>&mdash; やぐ (@yag_ays) <a href="https://twitter.com/yag_ays/status/506999657243766785">September 3, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>忙しさが一段落したのでkaggleに戻ってきたらランクが150位くらい下がってて厳しさがある</p>&mdash; やぐ (@yag_ays) <a href="https://twitter.com/yag_ays/status/512983920262918144">September 19, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>それに加えて開催期間が終わってテストデータ全体での評価が出た結果，おそらく過学習でスコアが下がり，開催側が設定したBART Benchmarkよりも下回るという有り様でした．Kaggle怖いです&#8230;．</p>

<h3>私は如何にして（ry</h3>

<p>今回は時間があったので，今回は色々試した気がします．定番のSVRに始まり，Gradient Boosting Regression Treesしたり，Random Forest Regressor使ったり，あとはForumに投稿されたH2Oでのdeep learningもどきもひと通り動かしたのですが，結果的に一番良かったのがSVRだったのでその中から前処理を幾つかやったやつを最終的にサブミット．実際はAbhishekの<a href="https://www.kaggle.com/c/afsis-soil-properties/forums/t/10351/beating-the-benchmark">Beating the Benchmark ;)</a>のやり方とほとんど変わらないと思います．どこで差が付いたのか，あとAbhishekを代表とするSVR勢は過学習を回避して大勝利となったのか，気になるところです．</p>

<p>いや確かにpublic leaderboardは手元で算出したスコアとかなり乖離があって謎いとは常々思っていたのですが，一応scikit-learnのgrid searchでチューニングはしているので大丈夫だと&#8230;厳しい．</p>

<p>といっても上位陣もかなり大荒れだった模様．以下のランクはpublic→privateの順で，これを見てもらえればわかる通り上位陣は著しくランクを落としている人が多い．逆にprivateでは100位以内くらいから上がってきた人が多く，今回は本当に結果が読めなかったようでした．</p>

<h4>public上位</h4>

<p><a href="http://www.kaggle.com/c/afsis-soil-properties/leaderboard/public">Public Leaderboard - Africa Soil Property Prediction Challenge | Kaggle</a></p>

<ul>
<li>sorpmaL：1位→515位</li>
<li>Dmitry &amp; Abhishek：2位→7位</li>
<li>vsu：3位→484位</li>
<li>Redwoods：4位→34位</li>
<li>ahaldenby：5位→517位</li>
</ul>


<h4>private上位</h4>

<p><a href="http://www.kaggle.com/c/afsis-soil-properties/leaderboard/private">Private Leaderboard - Africa Soil Property Prediction Challenge | Kaggle</a></p>

<ul>
<li>Yasser Tabandeh 14位→1位</li>
<li>Charly B. ：428位→2位</li>
<li>CodiLime.com：42位→3位</li>
<li>seewaters：61位→4位</li>
<li>UK calling Africa：88位→5位</li>
</ul>


<p>詳しいことは後々明らかになっていくことでしょう．Forumを静観．</p>

<p>あと，悔しいので念のために書いておきますが最終サブミッションに選択した以外のやつではきちんとベンチマーク上回っているのありました．ただ，スコアがいいやつに限って最初の方にサブミットした何のひねりも無いSVRだったりして，心が折れそう．</p>

<h3>Lessons Learned</h3>

<p>社会は厳しい．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kaggle初心者がDisplay Advertising Challengeに挑んだ結果354th/718だった]]></title>
    <link href="http://yagays.github.io/blog/2014/09/26/kaggle-criteo-display-advertising-challenge/"/>
    <updated>2014-09-26T16:41:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/09/26/kaggle-criteo-display-advertising-challenge</id>
    <content type="html"><![CDATA[<p>Kaggleで行われていたcriteoのDisplay Advertising Challengeが終了し，最終的にPublic LB:0.47880，Private LB:0.47831の354th/718だった．1位のチームが0.44464，Top10あたりが0.44台のスコアを叩き出しているので，結果としては惨敗だけれども，初めてにしては健闘できたほうだと思う．まあ最初の方はLogistic regressionのBenchmarkすら越せなくて厳しい状態だったが，そこから抜けだしてある程度成果が出始めると，あとは計算してはサブミットしてを繰り返しスコアに一喜一憂するという感じで競技性があって非常に楽しめた．次はもっと上の方に行きたいと思いつつ，現在参加しているAfrica Soil Property Prediction Challengeは一時期10位圏内まで行ったもののそこから怒涛のランク落ちで現在300位くらいまで下がってしまったので，世間は厳しい．Kaggle Masterへの道はまだまだ遠い．</p>

<h3>予測方法</h3>

<p>さて，こんな中途半端な順位のヤツの解法なんて見てもどうしょうもないとは思うけれども，個人的な記録のためにも書いておく．</p>

<p>使用したのは<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">Vowpal Wabbit</a>(VW)．主に参考にしたのはMLWaveの<a href="http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/">Predicting CTR with online machine learning</a>で，とりあえず動くコードの例があって，あとはVWのパラメータチューニングで頑張ったという流れ．実はこれ以前にscikit-learn + pandasも試していたのだけれども，あまりにデータ量が多すぎてpandasのget_dummiesでダミー変数作るのが不可能だったりと早々に諦めていた．その点VWは高速で動いてメモリ消費量も少ないので，初心者にとっては使いやすいソフトウェアだった．あと<a href="https://github.com/MLWave/kaggle-criteo">MLWave/kaggle-criteo</a>でデータ形式の変換コードがあったのが助かった．</p>

<p>さて，最終的なサブミットに使用したのは以下のパラメータ．</p>

<ul>
<li>損失関数(&#8211;loss_function)：logistic</li>
<li>Feature Hashingのbit数(-b)：30</li>
<li>L2正則化(&#8211;l2): 1e-08</li>
<li>データのイテレーション回数(&#8211;passes):10</li>
</ul>


<p>少し前の記事の<a href="http://yagays.github.io/blog/2014/08/31/vowpal-wabbit/">私的Vowpal Wabbitまとめ - Wolfeyes Bioinformatics beta</a>にも書いたけど，loss_functionはlogisticにしておくと学習が終わったときにだいたいのスコアがわかって便利．あと-bを増やすとfeature hashingでcollisionしなくなるけれども，そのかわり必要なメモリ容量が増える．L2正則化はL1とともに1e-01から1e-12くらいまで試したんだけど，スコアが劇的に変わるわけではなかった．&#8211;passesは必須だけど，ある程度のイテレーション回数でスコアに変動がなければ途中で切られるみたいなので，パラメータを変更後に必要回数を確認してからは変えていない．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>vw click.train.vw -f click.model.b30.pass10.l2_1e-08.vw --loss_function logistic -c -k -b 30 --passes 10 --l2 0.00000001
</span><span class='line'><span class="nv">$ </span>vw click.test.vw -t -i click.model.b30.pass10.l2_1e-08.vw -p click.preds.b30.pass10.l2_1e-08.vw
</span></code></pre></td></tr></table></div></figure>


<h3>感想戦</h3>

<ul>
<li><a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners">Congratulations to the winners! - Display Advertising Challenge | Kaggle</a></li>
</ul>


<p>Kaggleのフォーラムで上位ランクの人が自分の解析方法を公開してくれているので，その中からVWに関するトピックを幾つか拾ってみる．</p>

<p>まずは，15thのLuca MassaronがVWを使った解析例を示してくれている(<a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners/54591#post54591">link</a>)．VWのコマンドは非常に参考になるし，自分もNNのHidden Unitsを10とか20でやったんだけどなーと思いつつ，何よりもまずデータの前処理の必要性を感じた．</p>

<p>あとは19thのKonrad BanachewiczはVWのより詳細な結果を示してくれていて(<a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners/54595#post54595">link</a>)，こっちではNNが効かないみたいな話があったり，quadratic feature頑張ってたり．</p>

<p>あとはLibFMとかNNとかAutoencoderとか色々な方法で予測している人がいて，非常に参考になる．</p>

<h3>今後のCriteo Display Advertising Challengeの動向</h3>

<p>Kaggleでのコンペは終わってしまったが，上に書いたようなフォーラムでの議論は続くし，それにコンペ用のデータセットが学術向けに公開された．これでもしかしたら上位ランクのグループの成果が論文として出てくるかもしれない．</p>

<ul>
<li><a href="http://labs.criteo.com/2014/09/kaggle-contest-dataset-now-available-academic-use/">Kaggle contest dataset is now available for academic use! - Criteo Labs</a></li>
</ul>


<p>あと，<a href="https://docs.google.com/file/d/0BzrlDxVZWSUpNFdscnRmUUdJWk5qYVhkVVE0WjV1LUxpZlhr/edit">Criteoの資料</a>によると&#8221;Winners will release code publicly(Popular OSI-approved license)&#8221;らしいので，ぜひともコードを公開してほしいところ．</p>

<p>といった感じで，まだまだCriteo Display Advertising Challengeは終わらない．</p>

<h4>追記：</h4>

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/yag_ays">@yag_ays</a> kaggleのコンペのほとんど（全て？）は、Prizeに入った人は手法の説明とコード(OSI承認ライセンス)をフォーラムに投稿しなければならないとルールに書いてあるので、なんらかトラブルがない限り上位陣の成果は公開されると思います。</p>&mdash; id:ultraist (@ultraistter) <a href="https://twitter.com/ultraistter/status/515428100847304704">September 26, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「暴露:スノーデンが私に託したファイル」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/09/23/review-no-place-to-hide/"/>
    <updated>2014-09-23T15:27:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/09/23/review-no-place-to-hide</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4105066919" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<blockquote><p>「われわれ自身が自らの行動を通して人生に意味を与え，物語を紡いでいく」</p>

<p><a href="http://www.amazon.co.jp/gp/product/4105066919/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=4105066919&linkCode=as2&tag=yagays-22">暴露:スノーデンが私に託したファイル</a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=yagays-22&l=as2&o=9&a=4105066919" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /> P.76</p>

<p>&#8220;it is we who infuse life with meaning through our actions and the stories we create with them.&#8221;</p>

<p><a href="http://www.nytimes.com/2014/05/13/books/no-place-to-hide-by-glenn-greenwald.html">‘No Place to Hide,’ by Glenn Greenwald - NYTimes.com</a></p></blockquote>

<p>これは本書の中で語られるエドワード・スノーデンの言葉だ．彼がなぜNSAやCIA，そしてアメリカという国家が作り上げた監視システムに異を唱えて機密書類を暴露したか，その理由を本書著者であるグレン・グリーンワルドに聞かれたときの答えの一つである．</p>

<p>これはエドワード・スノーデンの内部告発をめぐる一連の事件を一番近くで見ていたジャーナリストの著作である．彼がローラ・ポイトラスとともに，スノーデンの内部告発の報道をガーディアン紙に掲載した．そのスクープまでの長い道のりと，スノーデンがもたらした機密文章の内容，内部告発後の世界の反応，そしてジャーナリズムという本質を，本書「暴露」は露わにする．</p>

<p>本書はまるで別の本を繋ぎあわせたと思うくらいに内容が章によって異なる．まず第1章は，著者とスノーデンの出会いから接触と情報提供までの一連の流れを時系列で記述した，なかば小説的な内容．次に2章と3章ではスノーデンが持ちだした機密文章をもとにNSAやアメリカ国家が行ってきた監視システムの解明．そして第4章では監視システムの是非について，最後に5章ではジャーナリズムの意義について，告発後に著者のグレン・グリーンウォルドが経験した賞賛とバッシングなどの反応を元に書かれている．ジャーナリズムに身を奉じる一人の記者として一貫した信念を持つ著者には，どこか自身の自由や立場を犠牲にしてでも告発に踏み切ったスノーデン氏と同じものを感じる．</p>

<p>情報科学に身を置く者としても，そして多少なりとも他の人よりかはインターネットやプライバシーや暗号に関して知識はあるだろうという少しの傲慢さをもってしても，今回のスノーデンをめぐる事実については今でも信じ切れない部分がある．それはテロ対策という名目の元に監視システムを作り上げてしまったアメリカ自体よりも，それを実際に運用して何億通ものメールや電話を収集しメタデータを含めた個人情報を掌握するという異常なスケールの情報処理を行っている技術すべてに対してだ．それこそ昨今のビックデータなんて霞むほどの想像のつかないほどのデータ量になるだろう．実際は集めるだけ集めて解析なんてまともにできていないだろうという，なかば希望的な推測もあるけれども，それを差し置いても監視システムの持つポテンシャルにはただ圧倒されるしかない．それに，その体制を支える技術自体も想像がつかない．ネットワークの盗聴や暗号解読．しまいにはIBM,Yahoo,Google,Facebookなどの企業からの情報提供など，世の中の前提が崩れかねない内容だ．いっそ007などのスパイ映画さながらの奇抜な方法でやってくれていたほうが幾分マシだったと思える．それくらい今回発覚した事実には驚かざるをえない．</p>

<p>世界は変わる．身体，宗教，政治思想，職業，人種，そうしたすべての立ち位置において，昨日までマジョリティだった人間が突然マイノリティになる瞬間が訪れる可能性がある．社会の自由は弱者に対する寛容さをもってして計られる．自分が安全だからという短期的な考えではなく，もっと長期的で大域的な，どんな状態になっても自分の望む自由な世界にするべく，考えて行動していかなければならない．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[スライドメモ:KDD2014 Tutorial "The Recommender Problem Revisited"]]></title>
    <link href="http://yagays.github.io/blog/2014/09/08/kdd2014-tutorial-recommendation/"/>
    <updated>2014-09-08T15:21:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/09/08/kdd2014-tutorial-recommendation</id>
    <content type="html"><![CDATA[<p>Netflixの中の人によるKDD2014 Tutorialの&#8221;The Recommender Problem Revisited&#8221;のスライド1を読んだので，簡単にまとめてみた．レコメンドのこれまでと現状をひと通り網羅したチュートリアルという感じ．このスライドはKDD2014 Tutorial向けだけれど，今度のRecSys 2014のTutorialでも同様の発表があるようだ(<a href="http://recsys.acm.org/recsys14/tutorials/">link</a>)．</p>

<ul>
<li><strong>レコメンドの大まかな流れを知りたい人</strong>

<ul>
<li>このチュートリアルもいいけど，日本語で書かれた<a href="http://www.kamishima.net/archive/recsys.pdf">しましま先生の資料</a>の方が丁寧でわかりやすいかも</li>
</ul>
</li>
<li><strong>レコメンドの具体的な手法や流行を知りたい人</strong>

<ul>
<li>このチュートリアルで興味ある分野の箇所を見て個別にReferenceを当たる</li>
</ul>
</li>
</ul>


<p>どっちにしろ素人のまとめなので，以下のメモは参考程度にお願いします．</p>

<p><a href="http://www.slideshare.net/xamat/kdd-2014-tutorial-the-recommender-problem-revisited">Kdd 2014 Tutorial - the recommender problem revisited</a></p>

<iframe src="http://yagays.github.io//www.slideshare.net/slideshow/embed_code/38241291" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="https://www.slideshare.net/xamat/kdd-2014-tutorial-the-recommender-problem-revisited" title="Kdd 2014 Tutorial - the recommender problem revisited" target="_blank">Kdd 2014 Tutorial - the recommender problem revisited</a> </strong> from <strong><a href="http://www.slideshare.net/xamat" target="_blank">Xavier Amatriain</a></strong> </div></p>

<p><strong>(追記:2014.10.8) RECSYSのスライドも公開された．</strong></p>

<p><a href="http://www.slideshare.net/xamat/recsys-2014-tutorial-the-recommender-problem-revisited">Recsys 2014 Tutorial - The Recommender Problem Revisited</a></p>

<h3>TL;DR</h3>

<p>レコメンドのこれまでと現状をひと通り網羅した資料．情報過多の時代においてレコメンドは必要不可欠な技術であり，いまでは従来のレコメンドに加えてパーソナライズやインターフェイスなどの複合要素を考慮したレコメンドが必要になってきた．それにともなって，レコメンド手法としても古典的な協調フィルタリングから，Netflix Prizeにより出現した次元削除の手法，ランキングアルゴリズムやディープラーニングを用いたコンテンツベースのレコメンドなどへと広がりをみせている．</p>

<h3>1. The Recommender Problem</h3>

<ul>
<li>レコメンデーションは必須

<ul>
<li>情報量の肥大化(情報過多)</li>
<li>個人向けの推薦（パーソナライズ）

<ul>
<li><a href="http://www.huffingtonpost.com/2013/08/21/netflix-my-list_n_3790472.html">Netflix&#8217;s New &#8216;My List&#8217; Feature Knows You Better Than You Know Yourself (Because Algorithms)</a></li>
</ul>
</li>
</ul>
</li>
<li>レコメンドの定義

<ul>
<li>今までの定義：ユーザが好きなアイテムを自動的に予測する効用関数を作る</li>
<li>これからのレコメンド：今までのレコメンド＋α

<ul>
<li>セレンディピティ（偶然の発見＆ユーザが既に知っているアイテムを推薦しない）</li>
<li>ユーザインターフェイス，パーソナライズなど</li>
</ul>
</li>
</ul>
</li>
<li>レコメンドの進化

<ul>
<li>単純なレート付け→ランキング→ページ最適化→コンテキストを含めたレコメンドへ</li>
</ul>
</li>
</ul>


<h3>2. Traditional Approaches</h3>

<h4>2.1 Collaborative Filtering (CF)</h4>

<p><strong>協調フィルタリングの基本</strong></p>

<ul>
<li>協調フィルタリングの構成要素

<ul>
<li>ユーザがアイテムに付けたレートが基本</li>
<li>レートが無くても購買履歴などから補完することもできる</li>
</ul>
</li>
<li>アクティブユーザの情報がメイン</li>
<li>ユーザ間の類似度を使う

<ul>
<li>一種のパーソナライズと取れる</li>
<li>ピアソンの相関係数/コサイン類似度</li>
</ul>
</li>
<li>あるユーザに類似したユーザを探しだしてレート付けされてない作品を推測する</li>
<li>ユーザベースの協調フィルタリング / アイテムベースの協調フィルタリング</li>
<li>協調フィルタリングの特徴

<ul>
<li>長所：最小限の情報で計算できて，だいたいにおいて性能が良い</li>
<li>短所：アイテム数が増えるとスパースになる＆スケールが難しい

<ul>
<li>ユーザ数xアイテム数のうち，値が入っているのはごく僅か(1%以下)</li>
</ul>
</li>
</ul>
</li>
</ul>


<p><strong>モデルベースの協調フィルタリング Model-based CF</strong></p>

<ul>
<li><p><a href="http://www.netflixprize.com/">Netflix Prize</a></p>

<ul>
<li>アルゴリズム的にRMSE基準でトップ2つのアルゴリズム

<ul>
<li>SVD</li>
<li>RBM</li>
</ul>
</li>
<li>今でもNetflixのレート推定の一部に使われている

<ul>
<li>SVD++とRBMの組み合わせ</li>
</ul>
</li>
</ul>
</li>
<li><p>Simon Funk&#8217;s SVD</p>

<ul>
<li>Netflix Prizeで出てきた面白いアルゴリズム（Blogが初出）</li>
<li><a href="http://www.recsyswiki.com/wiki/SVD%2B%2B">SVD++</a></li>
</ul>
</li>
<li><p>Restricted Boltzmann Machines</p>

<ul>
<li>制限ボルツマンマシン</li>
<li><a href="http://machinelearning.wustl.edu/mlpapers/paper_files/icml2007_SalakhutdinovMH07.pdf">Restricted Boltzmann Machines for Collaborative Filtering</a></li>
</ul>
</li>
</ul>


<p><strong>クラスタリング Clustering</strong></p>

<p>クラスタリング：ユーザを特定の好みごとにクラスタリングして推薦する</p>

<ul>
<li>Locality-sensitive Hashing(LSH)

<ul>
<li>高次元空間で類似したアイテムをクラスタリングする手法</li>
<li>似たアイテムが近くにくるようなハッシュ関数を探す</li>
<li>最近傍探索(NN)によく使われる</li>
</ul>
</li>
<li>他のクラスタリングアルゴリズム

<ul>
<li>k-means</li>
<li>Affinity Propagation</li>
<li>Spectral Clustering</li>
<li>HDPs</li>
</ul>
</li>
</ul>


<p><strong>相関ルール Association Rule</strong></p>

<ul>
<li>アプリオリ・アルゴリズムなど</li>
</ul>


<p><strong>分類器 Classifiers</strong></p>

<ul>
<li>いわゆる普通の分類器

<ul>
<li>使い勝手が良くて組み合わせも可能だが，トレーニングセットが必要で正則化などが必要</li>
<li>ロジスティック回帰，ベイジアンネット，SVM，決定木など</li>
</ul>
</li>
</ul>


<p><strong>協調フィルタリングの限界 Limitations of Collaborative Filtering</strong></p>

<ul>
<li>コールドスタート問題

<ul>
<li>他のユーザの評価が十分に無いと機能しない</li>
<li>新しいアイテムなどで推薦が難しい</li>
</ul>
</li>
<li>人気バイアス

<ul>
<li>既に人気のあるアイテムを推薦しがち</li>
</ul>
</li>
</ul>


<h3>2.2 Content-based Recommenders</h3>

<ul>
<li>他のユーザの挙動ではなくアイテムの内容をベースにしたレコメンド

<ul>
<li>テキスト，キーワードなど</li>
</ul>
</li>
<li>目標：ユーザの好みに沿ったアイテムを推薦する</li>
<li>コンテンツベースのほうがうまくいくとは限らない

<ul>
<li><a href="http://dl.acm.org/citation.cfm?id=1639731">Recommending new movies: even a few ratings are more valuable than metadata</a>, RecSys2009</li>
</ul>
</li>
</ul>


<p><strong>コンテンツベースの特徴</strong></p>

<ul>
<li>長所

<ul>
<li>他のユーザ情報が不要なためコールドスタートやスパース性を考慮しなくて良い</li>
<li>ユーザ独自の好みに合わせることができる</li>
<li>新しいアイテムを推薦することができる</li>
<li>レコメンドの理由を説明しやすい</li>
</ul>
</li>
<li>短所

<ul>
<li>アイテムの内容から意味のある特徴量を抽出する必要がある</li>
<li>セレンディピティのある推薦が難しい</li>
<li>ユーザに最適化されすぎる</li>
</ul>
</li>
</ul>


<h3>2.3 Hybrid Approach</h3>

<ul>
<li>Content-based recommendation with Bayesian classifier</li>
<li>Hybridization Method

<ul>
<li>(see P.68)</li>
</ul>
</li>
</ul>


<h3>3. Beyond traditional Approarches to Recommendation</h3>

<h4>3.1 Ranking</h4>

<ul>
<li>ほとんどのレコメンドアルゴリズムは推薦するアイテムをソート済みのリストで返すから，レコメンドはランキングの問題とも捉えることができる</li>
<li>レートでランキングの順位を付ける</li>
<li>RMSEはランキングに使えない(?)

<ul>
<li>Linear modelで考えた時に，RMSEを最小にした結果ランキングに違いが生じる（Predicted RankingとFinal Rankingが違う）</li>
<li>(詳しくは図を参照)</li>
</ul>
</li>
<li>ランキングを測る指標

<ul>
<li>Normalized Discounted Cumulative Gain</li>
<li>Mean Reciprocal Rank (MRR)</li>
<li>Fraction of Concordant Pairs (FCP)</li>
</ul>
</li>
<li>最近はランキング指標自体を最適化する研究も</li>
</ul>


<h4>3.2 Similarity</h4>

<ul>
<li>SimRank

<ul>
<li>グラフベースの類似度を考える</li>
</ul>
</li>
<li>幾つかの類似度を組み合わせる

<ul>
<li>データごとに様々な類似度がある（e.g. タグ，ユーザの行動，ユーザのレート付け）</li>
<li>組み合わせの時の重みは回帰で学習する</li>
</ul>
</li>
</ul>


<h4>3.3 Deep Learning for Recommendation</h4>

<ul>
<li>Spotifyのプレイリスト推薦の例

<ul>
<li><a href="http://erikbern.com/?p=589">Recurrent Neural Networks for Collaborative Filtering | Erik Bernhardsson</a></li>
<li><a href="http://benanne.github.io/2014/08/05/spotify-cnns.html">Recommending music on Spotify with deep learning – Sander Dieleman</a></li>
</ul>
</li>
</ul>


<h4>3.4 Social Recommendations</h4>

<ul>
<li>(詳細は省略)</li>
</ul>


<h4>3.5 Page Optimization</h4>

<ul>
<li>どうやって推薦したアイテムを表示させるかというページ構成の話

<ul>
<li>デバイスによって表示できるアイテム数などが違う</li>
</ul>
</li>
<li>ユーザの注目度をモデリング，ヒートマップで可視化</li>
<li>限られた状態で何を重視するか

<ul>
<li>正確さか多様性か，新しものか続き物か，狭く深くか広く浅くか，など</li>
<li><a href="http://dl.acm.org/citation.cfm?id=2124337">Fair and balanced: learning to present news stories</a>,WSDM2014</li>
</ul>
</li>
<li>共存させるためのモデル

<ul>
<li>Navigational/Attention Model</li>
<li>Personalized Relevance Model</li>
<li>Diversity Model</li>
</ul>
</li>
</ul>


<h4>3.6 Tensor Factorization &amp; Factirization Machines</h4>

<ul>
<li>ユーザxアイテムxコンテキストのテンソルを[U,M,C]に分解する

<ul>
<li>Tensor Factorization</li>
</ul>
</li>
<li>Factorization Machines</li>
<li>(参考)

<ul>
<li><a href="http://qiita.com/ysks3n/items/c81ff24da0390a74fc6c">機械学習 - Matrix Factorizationとは - Qiita</a></li>
<li><a href="http://d.hatena.ne.jp/harapon1012/20140906/1410013995">すべてがMFになる - Fire and Motion</a></li>
</ul>
</li>
</ul>


<h4>3.7 MAB Explore/Exploit</h4>

<ul>
<li>多腕バンディット Multi-armed Bandits</li>
<li>パーソナライズは以下の2つのトレードオフ

<ul>
<li>Exploitation：活用</li>
<li>Exploration：探索</li>
</ul>
</li>
<li><a href="http://www.ueo-workshop.com/wp-content/uploads/2013/10/UEO-Deepak.pdf">http://www.ueo-workshop.com/wp-content/uploads/2013/10/UEO-Deepak.pdf</a>, CIKM2013</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[私的Vowpal Wabbitまとめ]]></title>
    <link href="http://yagays.github.io/blog/2014/08/31/vowpal-wabbit/"/>
    <updated>2014-08-31T10:47:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/08/31/vowpal-wabbit</id>
    <content type="html"><![CDATA[<h2>VWとは</h2>

<blockquote><p>The Vowpal Wabbit (VW) project is a fast out-of-core learning system sponsored by Microsoft Research and (previously) Yahoo! Research.</p>

<p><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">Home · JohnLangford/vowpal_wabbit Wiki</a></p></blockquote>

<h2>Install</h2>

<p>要Boost．</p>

<h4>Linux</h4>

<p><a href="https://github.com/JohnLangford/vowpal_wabbit/blob/master/README.md">vowpal_wabbit/README.md</a>に書いてある通り，git cloneしてmakeする．それが駄目なら./autogen.shしてからmakeする．</p>

<p>自分の場合は./autogen.shがエラーを吐いたので調べたところ，./autogen.sh内部でldconfigに失敗してBOOST_DIR_ARGが取得できていないのが原因だった．su権限でldconfigをしてLIBFILEの箇所を以下のように書き換えて対処した．当然ながらこれは環境に依存するので，自身の環境でLIBFILEに渡すコマンドを実行して置き換える．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="c">#  LIBFILE=`ldconfig -p | grep program_options | tail -n 1 | cut -d &#39;&gt;&#39; -f 2`</span>
</span><span class='line'>  <span class="nv">LIBFILE</span><span class="o">=</span><span class="s2">&quot;/usr/lib64/libboost_program_options-mt.so&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<h4>Mac OS X</h4>

<p>Mac OS Xの場合Homebrewでバイナリをインストール可能だが，vw-varinfo等のutil系は入らない．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>brew info vowpal-wabbit
</span><span class='line'>vowpal-wabbit: stable 7.7 <span class="o">(</span>bottled<span class="o">)</span>, HEAD
</span><span class='line'>https://github.com/JohnLangford/vowpal_wabbit
</span><span class='line'>/usr/local/Cellar/vowpal-wabbit/7.7 <span class="o">(</span>30 files, 4.7M<span class="o">)</span> *
</span><span class='line'>  Poured from bottle
</span><span class='line'>From: https://github.com/Homebrew/homebrew/blob/master/Library/Formula/vowpal-wabbit.rb
</span><span class='line'><span class="o">==</span>&gt; Dependencies
</span><span class='line'>Build: boost ✔, autoconf ✔, automake ✔, libtool ✔
</span><span class='line'>
</span><span class='line'><span class="nv">$ </span>brew install vowpal-wabbit
</span></code></pre></td></tr></table></div></figure>


<h4>Windows</h4>

<ul>
<li><a href="http://qiita.com/shima_x/items/9147eaa3626fab87ada2">機械学習 - windowsマシンでvowpal wabbitを使う（個人的メモ） - Qiita</a></li>
</ul>


<h2>VWを始めるときに気をつけるポイント</h2>

<ul>
<li>VWの独自フォーマット

<ul>
<li>VWを使いはじめるときの最初の難関ポイント</li>
<li>自分でcsvなどのデータをVWフォーマットに変換する必要がある</li>
<li>カテゴリ変数やテキストはそのまま列挙しても大丈夫．VWの方でn-gramも取ることができる</li>
</ul>
</li>
<li>VWのパラメータ名

<ul>
<li>資料によってパラメータの名前が違うので注意</li>
<li>自分の環境で<code>vw --help</code>して適宜読み替える</li>
</ul>
</li>
</ul>


<h2>Tutorial</h2>

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial">Tutorial · JohnLangford/vowpal_wabbit Wiki</a>

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/v7.0_tutorial.pdf">https://github.com/JohnLangford/vowpal_wabbit/wiki/v7.0_tutorial.pdf</a>

<ul>
<li>Binary Classification and Regression</li>
<li>Multiclass Classification</li>
<li>“Offline” Contextual Bandit</li>
<li>Sequence Predictions</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://zinkov.com/posts/2013-08-13-vowpal-tutorial/">Convex Optimized - Vowpal Wabbit tutorial for the Uninitiated</a>

<ul>
<li>かなり幅広く網羅したtutorial</li>
</ul>
</li>
</ul>


<h2>vw-varinfoについて</h2>

<p>vw-varinfoを使うことによって，変数ごとに重み等の情報を出力することができる．</p>

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/using-vw-varinfo">using vw varinfo · JohnLangford/vowpal_wabbit Wiki</a></li>
</ul>


<h2>Other Resources</h2>

<ul>
<li><a href="http://www.slideshare.net/pauldix/terascale-learning">Terascale Learning</a></li>
<li><a href="http://www.slideshare.net/jakehofman/technical-tricks-of-vowpal-wabbit">Technical Tricks of Vowpal Wabbit</a></li>
<li><a href="http://fastml.com/large-scale-l1-feature-selection-with-vowpal-wabbit/">Large scale L1 feature selection with Vowpal Wabbit - FastML</a>

<ul>
<li>L1 Regularizationについて

<ul>
<li><a href="http://www.kaggle.com/c/job-salary-prediction">Job Salary Prediction | Kaggle</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="http://fastml.com/vowpal-wabbit-eats-big-data-from-the-criteo-competition-for-breakfast/">Vowpal Wabbit eats big data from the Criteo competition for breakfast - FastML</a>

<ul>
<li>コンペの評価方法がLogarithmic Lossだから，VWの<code>--loss_function</code>をlogisticにしてくとVWの標準出力のaverage lossの部分がだいたいKaggleのスコアになるという話

<ul>
<li><a href="http://www.kaggle.com/c/criteo-display-ad-challenge">Display Advertising Challenge | Kaggle</a></li>
</ul>
</li>
<li>変数が大量にあるとfeature hashingの時にHashValが衝突(collision)するから，<code>-b</code>でhashing spaceをちょっと大きめにしておくといいという話

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction">Feature Hashing and Extraction · JohnLangford/vowpal_wabbit Wiki</a></li>
<li>-bのデフォルトが18なので，2<sup>18</sup> =262,144くらいのfeature数なら問題無い．むやみに大きくしても意味がないので，使用するデータのfeature数に合わせて調節する</li>
<li>VWは通常メモリ使わないほうだけど，<code>-b</code>を大きくするとGBレベルでメモリ消費するようになる．最大の<code>-b 32</code>だと64GB程度</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://blogs.technet.com/b/machinelearning/archive/2014/08/13/vowpal-wabbit-for-fast-learning.aspx">Vowpal Wabbit for Fast Learning - Machine Learning - Site Home - TechNet Blogs</a>

<ul>
<li>Vowpal Wabbitの名前の由来が書いてある</li>
</ul>
</li>
<li><a href="http://fastml.com/go-non-linear-with-vowpal-wabbit/">Go non-linear with Vowpal Wabbit - FastML</a>

<ul>
<li>VWの様々な機能(Neural Network,Quadratic and cubic features, N-grams)について

<ul>
<li><a href="https://www.kaggle.com/c/amazon-employee-access-challenge">Amazon.com - Employee Access Challenge | Kaggle</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="http://mlwave.com/movie-review-sentiment-analysis-with-vowpal-wabbit/">Movie Review Sentiment Analysis with Vowpal Wabbit | MLWave</a>

<ul>
<li>映画レビューサイトのテキストを使ったsentiment analysisにVWを使った話

<ul>
<li><a href="http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews">Sentiment Analysis on Movie Reviews | Kaggle</a></li>
</ul>
</li>
<li>vw-varinfoを使うことによってpositive/negativeな単語のfeature relevanceを可視化している</li>
</ul>
</li>
<li><a href="http://fastml.com/vowpal-wabbit-liblinear-sbm-and-streamsvm-compared/">Vowpal Wabbit, Liblinear/SBM and StreamSVM compared - FastML</a>

<ul>
<li>Vowpal Wabbit，LiblinearとStreamSVMの比較</li>
</ul>
</li>
<li><a href="http://hunch.net/~nyoml/">Open Machine Learning</a>

<ul>
<li>以下の2つの講演を見ることができる</li>
<li>&#8221; Vowpal Wabbit and Learning to Search by John Langford and Hal Daume&#8221;

<ul>
<li><a href="http://msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4">msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4</a></li>
<li><a href="http://research.microsoft.com/apps/video/default.aspx?id=227011">Vowpal Wabbit - Microsoft Research</a>のほうが，講演とスライドが並列に見ることができて便利</li>
</ul>
</li>
<li>&#8220;Vowpal Wabbit future plans&#8221;

<ul>
<li><a href="http://msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4">msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="http://fastml.com/how-to-run-external-programs-from-python-and-capture-their-output/">How to run external programs from Python and capture their output - FastML</a>

<ul>
<li>Vowpal WabbitをPythonから動かして出力をスクリプト内で取得する方法</li>
<li>記事内にも書いてあるけれども，PythonでVowpal Wabbitを扱うならvowpal_porpoiseやpyvw，wabbit_wappaなどのパッケージを使うという手もある</li>
</ul>
</li>
<li><a href="http://hunch.net/?p=222592">Vowpal Wabbit 7.8 at NIPS « Machine Learning (Theory)</a>

<ul>
<li>Vowpal Wabbit 7.8のリリースノート</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[kimonoでKaggleユーザのクロールをしてみた]]></title>
    <link href="http://yagays.github.io/blog/2014/08/18/kaggle-users-japan/"/>
    <updated>2014-08-18T20:37:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/08/18/kaggle-users-japan</id>
    <content type="html"><![CDATA[<p>ふとKaggleに参加している日本人がどれくらいいるのかが気になったので，簡単にクローラーを作って調べてみた．</p>

<h3>Kimonoを使ったクロール</h3>

<p>手動でクローラーを書いてもいいのだけれども，今回は<a href="https://www.kimonolabs.com/">kimono</a>というクローラーを使ってみた．</p>

<ul>
<li>参考：<a href="http://blog.takuros.net/entry/2014/08/13/212838">プログラミング・レスで5分でサックリWebスクレイピング「kimonolabs」 - プログラマになりたい</a></li>
</ul>


<p>kimonoはWebから簡単にクローラーを作成してAPIやJSON形式で取得できるようにするようなアプリケーションで，Chrome Extensionを使うことでインタラクティブにクロールする内容を選択することができる．今回は，<a href="http://www.kaggle.com/users/">Kaggle Rankings</a>のランキング500ページ分をクロールして，20000人分のユーザの情報（名前，ランク，ポイント，ロケーション）を取得した．今回クロールした結果は，以下のkimonoのウェブページから誰でも利用できるはず(アカウント持ってないと見れないかな)．ただしrankとptsが一緒になってたりとちょっと汚いので注意．</p>

<ul>
<li><a href="https://www.kimonolabs.com/apis/dyo7tdm8">https://www.kimonolabs.com/apis/dyo7tdm8</a></li>
</ul>


<p>ちなみに，どれくらい簡単にできるかをgif動画にしてみた．最初は色々戸惑った部分もあったけれど，慣れてしまえば本当に簡単に扱える．以下の場合だと，ユーザ情報がページあたり50人分あるので，ある部分を選択したあとに他の部分も同様に取得するようにチェックを付けるのが重要．あと，paginationはいわゆる「次」にあたる部分を選択する．本当は選択した部分に対して正規表現を掛けてテキスト処理をかけることもできるのだけれども，今回は行っていない．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/kimono.gif" alt="" /></p>

<h3>後処理</h3>

<p>クロール自体はkimonoに任せることができたので，ここからはpythonスクリプトをちゃちゃっと書いて整形作業．クロールしたデータはJSON形式やcsv形式でダウンロードすることもできるが，今回はAPIから叩いてみる．kimonoの&#8221;Use in code&#8221;というタブに，CurlやjQuery，Node，PHP，Python，Rubyでそれぞれ書かれたスクリプトがあるので，それを使ってデータを取得する．例えば，curlとPythonだと以下のようになる</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl --include --request GET "https://www.kimonolabs.com/api/dyo7tdm8?apikey=7ZTTugRoP8xgIlOdAdyiHmwP4rFLviDO"</span></code></pre></td></tr></table></div></figure>




<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">json</span>
</span><span class='line'><span class="kn">import</span> <span class="nn">urllib</span>
</span><span class='line'>
</span><span class='line'><span class="n">results</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="s">&quot;https://www.kimonolabs.com/api/dyo7tdm8?apikey=7ZTTugRoP8xgIlOdAdyiHmwP4rFLviDO&quot;</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure>


<p>今回は日本人のアカウント一覧が欲しいので，&#8221;Country of residence&#8221;にJapanと書かれていてかつポイントを持っているアカウント一覧を出力した．なお，ユーザプロフィールの記入は基本任意なので，<strong>プロフィールで&#8221;Country of residence&#8221;を編集していない日本人は対象外になっている</strong>．</p>

<h3>リスト(2014/08/18現在)</h3>

<p>ユーザページに飛べるように一応HTMLにした．気が向いたら定期的にアップデートするようにして，もっときちんと体裁整えるかも．こういった公開も含めてkimono側で簡単なインターフェイスがあると楽なんだけどなーと思った．</p>

<ul>
<li><a href="https://dl.dropboxusercontent.com/u/142306/kaggle_jpn.html">https://dl.dropboxusercontent.com/u/142306/kaggle_jpn.html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「バッドデータハンドブック ―データにまつわる問題への19の処方箋」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/08/16/review-bad-data-handbook/"/>
    <updated>2014-08-16T16:51:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/08/16/review-bad-data-handbook</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4873116406" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>最近流行りの華々しいデータ解析の現実をつきつけられる1冊．ビッグデータといって騒いでいるお偉いさんは「顧客の行動データを収集して解析することで業務効率化」といった言葉を軽々しく口にするけれども，実際はそんな一言で片付けられるほど容易ではない．現実のデータ解析は泥臭く，手垢にまみれていて，そしていつも試行錯誤の繰り返しだ．手に入るデータがどれも十分な量あって構造化されていて綺麗なことなんてあるわけがない．そんなバッドデータを相手にどう立ち振る舞うかについて，大学で統計学を教えている講師から，データサイエンティスト，経済学者，スタートアップの共同創業者などなど，様々な分野の人間が自身の体験や知識をもとに書いている．それぞれがコンパクトにまとまっていて関連性が無いので，雑誌をペラペラめくる感覚で好きな箇所を読むことができる．</p>

<p>そのなかで個人的に面白かった章を幾つかピックアップして紹介してみる．</p>

<h4>3章 機械ではなく人間が使うことを意図したデータ</h4>

<p>いわゆるネ申エクセルのような人間が読むことを前提にした非構造化データを，いかにプログラムで読み取るかという話．ここではニュージーランドの学校ごとの成績の統計を取ろうとしているのだけれども，Excelのスプレッドシートにまとめられているうえに，男子校だからという理由で女生徒の情報が入力されていなかったり，男子校なのになぜか女生徒の結果が入っていたり&#8230;とデータ取得の苦労が見られる．それでも著者は，コードを書くことが解決法であり，データフォーマットを自在に変換できることこそが重要な能力であると断言する．実際には厳しい道だけれども，まさにその通りだと思う．</p>

<h4>8章 血と汗と尿</h4>

<p>英国安全衛生研究所に持ち込まれる大量のサンプルの化学的解析を行っていた著者の話．化学者のカルチャーを身をもって体験した話がとても面白く，実験系の人のことを知っていれば非常に共感できる内容になっている．著者の同僚の化学者はその道のプロフェッショナルで，データの測り方に必要な計器のキャリブレーション，実験で出てくるデータのピアレビューといった方法など，化学の世界で独自に発展させてきた技術や経験があるものの，いまだにExcelですべて完結させていたりと，データ解析の面では改良の余地がある．なんとかして構造化データとしてまとめた上で自動化したいんだけど，現実にはデータのタイプや欠損値の扱いなど様々なハードルがある．それでも怠惰という自動化は素晴らしいし，適切なコードを書くことで達成できるというもの．</p>

<h4>14章 クラウドコンピューティングの神話</h4>

<p>この章はちょっと系統が違っていて，データ解析というよりかはクラウドの現実に焦点が当てられている．著者はMongoDBを開発している10genのエバンジェリスト．内容はストーリー仕立てで，自分のサービスをクラウドで運用しはじめたスタートアップCTOの主人公が，次第に規模が大きくなっていくにつれて様々な障害に直面していくという流れになっている．地道なパフォーマンスチューニングにはじまり，クラウドが落ちてどうしようもなくなったり，小規模だからといって手動で行っていたことが仇となったり，次第にスケールしなくなっていく水平方向のサーバ増強，コストの増加など，非常にリアルな話が次々と出てくる．結局はバズワードに飛びつくのは勝手だが現状を打破して何でも解決してくれる技術なんて存在しないということなんだけれども，将来的に技術が発展してそういう未来になるといいよねという，本来私たちが望んでいる理想で締められているところが良い．</p>

<h4>16章 機械学習の専門家の手なづけ方</h4>

<p>Kaggleというデータ解析のコンテストに出題側として参加したスタートアップの創業者の話．サービスに合う機械学習アルゴリズムの開発をKaggleを通してアウトソースするのは，一見簡単そうに見えて実は大変で，データセットの作成から評価方法の検討，匿名化，コンテスト運営など，クリアしなければいけない関門は意外に多い．それでもコンテストの結果は満足のいくものだったし，自分たちで正解セットをタグ付けしたり特徴量を考えたりすることによって，結果的に出題者自身が問題を正しく理解できたという側面もあったという．こういったデータ解析分野としての新しいコミュニティやプラットフォームが出てきて企業の問題解決につながるというのは，データ解析に身をおく人間として望む未来だよなぁとしみじみ思う．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iPython Notebookの--pylab inlineは使うのをやめようという話]]></title>
    <link href="http://yagays.github.io/blog/2014/08/15/ipython-notebook-matplotlib-inline/"/>
    <updated>2014-08-15T09:48:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/08/15/ipython-notebook-matplotlib-inline</id>
    <content type="html"><![CDATA[<h3>TL;DR</h3>

<p><code>ipython notebook --pylab inline</code>のかわりに<code>ipython notebook --matplotlib inline</code>を使おう．もしくはipythonの始めに<code>%matplotlib inline</code>を実行しておく．</p>

<h3>iPython Notebookについて</h3>

<p>周知の事実だとは思うが，<a href="http://ipython.org/index.html">iPython</a>は超便利なPythonのインタラクティブシェルだ．その一部として<a href="http://ipython.org/notebook.html">iPython Notebook</a>というのがあり，ブラウザでコードを実行できたり，実行結果をノートとして保存したり，matplotlibなどで描写したグラフをノートの中にそのまま表示したりできる．RでいうところのRstudio+knitrのような，解析レポートを作るときには重宝するツールとなっている．</p>

<br/>


<p><img src="https://dl.dropboxusercontent.com/u/142306/b/ipythonnotebook.png" alt="http://nbviewer.ipython.org/gist/twiecki/3962843より" /></p>

<p>(<a href="http://nbviewer.ipython.org/gist/twiecki/3962843">http://nbviewer.ipython.org/gist/twiecki/3962843</a>より)</p>

<p>で，iPython Notebookに関する記事を見ていると，だいたい以下のようなコマンドで実行している．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ipython notebook --pylab inline
</span></code></pre></td></tr></table></div></figure>


<p>ipython notebookで起動，それにくわえて&#8211;pylab inlineとすることでiPython Notebook内で描写したグラフが展開できて嬉しいわけだけど，一つ問題がある．それはpylabをインポートしている点だ．</p>

<h3>無意識にpylabを使うとなにが危ないか</h3>

<p>pylab自体は色々と便利なパッケージなんだけれども，そのpylabの挙動に少し問題がある．上で示したようなコマンドでpylabフラグを付けて実行すると，実は裏ではnumpyのモジュールがnpのエイリアスとともに，トップレベルでもインポートされている．実際にコマンドを叩いて確かめてみると以下のようになる．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ipython --pylab
</span><span class='line'>
</span><span class='line'>In <span class="o">[</span>1<span class="o">]</span>: np.arange<span class="o">(</span>0,10<span class="o">)</span>
</span><span class='line'>Out<span class="o">[</span>1<span class="o">]</span>: array<span class="o">([</span>0, 1, 2, 3, 4, 5, 6, 7, 8, 9<span class="o">])</span>
</span><span class='line'>
</span><span class='line'>In <span class="o">[</span>2<span class="o">]</span>: arange<span class="o">(</span>0,10<span class="o">)</span>
</span><span class='line'>Out<span class="o">[</span>2<span class="o">]</span>: array<span class="o">([</span>0, 1, 2, 3, 4, 5, 6, 7, 8, 9<span class="o">])</span>
</span></code></pre></td></tr></table></div></figure>


<p>どっちも実行できていて何の変哲もないように見えるんだけど，よくNumpyの実行環境で見るimport numpy as npの場合だと，1行目の書き方では実行できるが，2行目の書き方では実行できない．それが，pylabをインポートしているとどちらもできてしまう，正確に言えば，Numpyの関数がモジュール名もしくはエイリアスを先頭に付けなくても実行できてしまう．</p>

<p>ではこれの何が問題かというと，関数の名前がかぶるというわけだ．たとえば組み込み関数の<a href="http://docs.python.jp/2/library/functions.html#sum">sum()</a>や<a href="http://docs.python.jp/2/library/functions.html#all">all()</a>は，実はNumpyにも同様の名前の関数がある（<a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html">sum()</a>,<a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.all.html">all()</a>）．なのでpylabをインポートすると，勝手にsumやallがNumpyのモジュールのものに置き換わってしまう．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="c"># pylabをインポートしない場合</span>
</span><span class='line'><span class="nv">$ </span>ipython
</span><span class='line'>
</span><span class='line'>In <span class="o">[</span>1<span class="o">]</span>: sum,all
</span><span class='line'>Out<span class="o">[</span>1<span class="o">]</span>: <span class="o">(</span>&lt;<span class="k">function </span>sum&gt;, &lt;<span class="k">function </span>all&gt;<span class="o">)</span>
</span><span class='line'>
</span><span class='line'><span class="c"># pylabをインポートした場合</span>
</span><span class='line'><span class="nv">$ </span>ipython --pylab
</span><span class='line'>
</span><span class='line'>In <span class="o">[</span>1<span class="o">]</span>: sum,all
</span><span class='line'>Out<span class="o">[</span>1<span class="o">]</span>: <span class="o">(</span>&lt;<span class="k">function </span>numpy.core.fromnumeric.sum&gt;, &lt;<span class="k">function </span>numpy.core.fromnumeric.all&gt;<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>意識的にpylabを使おうと思って書くコードなら良いんだけど，もしpylab関係なくいつもiPython Notebook使ってるからという感覚でpythonのコードを書いたとして，あとで普通のpythonで実行したら動かない，なんてことが起こりかねない．まあ気をつければ済む話かもしれないが，こういう地雷は踏まないに限る．</p>

<h3>公式にも&#8211;pylabは使えなくなる見込み</h3>

<p>あと，&#8211;pylabを使ってiPython Notebookを起動すると以下のような警告文が出る．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>ipython notebook --pylab inline
</span><span class='line'>
</span><span class='line'><span class="o">[</span>...<span class="o">]</span>
</span><span class='line'>
</span><span class='line'><span class="o">[</span>NotebookApp<span class="o">]</span> WARNING | Starting all kernels in pylab mode is not recommended,
</span><span class='line'>    and will be disabled in a future release.
</span><span class='line'>    Please use the %matplotlib magic to <span class="nb">enable </span>matplotlib instead.
</span><span class='line'>    pylab implies many imports, which can have confusing side effects
</span><span class='line'>    and harm the reproducibility of your notebooks.
</span></code></pre></td></tr></table></div></figure>


<p>ということで，iPython Notebookを使うときには&#8211;pylabで読み込みをしないほうが良い．</p>

<h3>pylabを使わないでinline表示させるには</h3>

<p>&#8211;pylab inlineを回避する方法は2つある．</p>

<ul>
<li><code>ipython notebook --matplotlib inline</code>で起動する</li>
<li><code>%matplotlib inline</code>をiPython Notebookの冒頭で実行しておく</li>
</ul>


<p>こうすることによって，pylabのインポートを回避しつつiPythonのノート内でグラフを描写することができる．1つ目のiPythonのフラグで指定するほうが簡単だとは思うのだが，ぐぐってもこのコマンドで実行している例があまり出てこないのだけれども，たぶん問題無いと思う．</p>

<h3>注意</h3>

<p>ここまで読んだならわかるとは思うけれども，pylabの行儀悪いNumpyインポートを避けようということをしたわけだから，当然Numpyは別でインポートしないといけないし，そのへんのウェブページに載っているiPython Notebookの実行例とかのNumpyの関数の入ったコードはそのままでは実行できない．今回の方法を使っているなら，そのあたりは適宜読み替える必要がある．あんまり見たこと無い関数があったら，それがPythonの組み込み関数なのかNumpyやpylabの関数なのか疑ってかかろう．もしNumpyの関数なら，import numpy as npがされていることを確認したうえでnp.を関数の先頭につければ実行できる．なんかコードのサンプルをコピペしたけど動かないというときは，まあ大抵この問題だ．</p>

<h3>元ネタ</h3>

<ul>
<li><a href="http://carreau.github.io/posts/10-No-PyLab-Thanks.ipynb.html">No Pylab Thanks | Random Thoughts</a></li>
</ul>


<h3>参考</h3>

<ul>
<li><a href="http://docs.python.jp/2/tutorial/modules.html">6. モジュール — Python 2.7ja1 documentation</a></li>
<li><a href="http://hennohito.cocolog-nifty.com/blog/2014/07/pythonpylab-21a.html">今から始めるPython　その４　pylabネームスペースの解説: YATTSUKE BLOG</a></li>
<li><a href="http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%203%20-%20Plotting%20with%20Matplotlib.ipynb">http://nbviewer.ipython.org/github/ipython/ipython/blob/1.x/examples/notebooks/Part%203%20-%20Plotting%20with%20Matplotlib.ipynb</a>

<ul>
<li>%matplotlib inlineを使っている例</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Homebrew/scienceでバイオインフォマティクスのソフトウェアを入れる]]></title>
    <link href="http://yagays.github.io/blog/2014/07/23/homebrew-science-bioinformatics/"/>
    <updated>2014-07-23T00:38:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/07/23/homebrew-science-bioinformatics</id>
    <content type="html"><![CDATA[<p><a href="https://github.com/Homebrew/homebrew-science">Homebrew/homebrew-science</a></p>

<p>Homebrewにはtapというコマンドがあって，例えばHomebrew/dupesのようにMacOSXに標準で入っているソフトウェア/パッケージを個別に入れられたりと，公式以外のフォーミュラからbrewコマンドで入れられるシステムがある．</p>

<h3>Homebrew/science</h3>

<p>その中でHomebrew/scienceという科学系のリポジトリがあり，バイオインフォマティクスに関するソフトウェアも多数登録されている．例えば，</p>

<ul>
<li>blast</li>
<li>blat</li>
<li>hmmer</li>
<li>clustal-w</li>
</ul>


<p>のような基本的なソフトウェアから，</p>

<ul>
<li>bowtie2</li>
<li>cufflinks</li>
<li>bwa</li>
<li>fastqc</li>
<li>igv</li>
<li>samtools</li>
<li>bedtools</li>
<li>&#8230;</li>
</ul>


<p>のようなNGSまわりの解析ツールもひと通りHomebrewから入れることができる．ここに挙げている以外にも多数のバイオインフォマティクス関連のソフトウェアが登録されているので，詳しくは<a href="https://github.com/Homebrew/homebrew-science">homebrew-scienceのGitHubページ</a>を参考．</p>

<p>ひとつ注意点としては，Homebrew/sicenceで入れたソフトウェアが常に最新のものかどうかは保証されない．Homebrew/scienceの中にあるフォーミュラで記述されているものがインストールされるので，フォーミュラの管理状態によっては最新ではないバージョンを指している可能性がある．もし最新バージョンを入れたい/バージョンに気をつけるといった場合には，公式ページで配布されているソフトウェアのバージョンを確認したほうが良いだろう．</p>

<h3>使い方</h3>

<p>Homebrewをセットアップした上で，以下のコマンドでtapを追加することができる．</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nv">$ </span>brew tap homebrew/science
</span></code></pre></td></tr></table></div></figure>


<p>あとは好きなソフトウェアをbrew installすれば良い．</p>

<h3>恒例のアレ</h3>

<p>このxkcdのマンガには，Homebrew/scienceのページに載っているコマ以外にちゃんとした前振りがある．詳しくは<a href="http://xkcd.com/585/">http://xkcd.com/585/</a>にて．</p>

<p><img src="https://camo.githubusercontent.com/3409f4a35fcb0bf160c8c9bb153bb133d8f83b4f/687474703a2f2f692e696d6775722e636f6d2f42737770312e706e67" alt="" /></p>

<h4>参考</h4>

<ul>
<li><a href="https://github.com/Homebrew/homebrew/wiki/brew-tap">brew tap · Homebrew/homebrew Wiki</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GollumでCtrl-bのキーボードショートカットを無効にする]]></title>
    <link href="http://yagays.github.io/blog/2014/07/18/gollum-disable-ctrl-b-hotkey/"/>
    <updated>2014-07-18T04:12:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/07/18/gollum-disable-ctrl-b-hotkey</id>
    <content type="html"><![CDATA[<p>Gollumで記事を編集していると，Ctrl-bで「****」というmarkdownのbold記法が挿入されるキーボードショートカットがあって邪魔だったので，無効にした．</p>

<h3>方法</h3>

<p>Gollumのgollum.editor.jsの中の該当部分をコメントアウトする．</p>

<p><a href="https://github.com/gollum/gollum/blob/master/lib/gollum/public/gollum/javascript/editor/gollum.editor.js#L215">https://github.com/gollum/gollum/blob/master/lib/gollum/public/gollum/javascript/editor/gollum.editor.js#L215</a></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'>      <span class="nx">Mousetrap</span><span class="p">.</span><span class="nx">bind</span><span class="p">([</span><span class="s1">&#39;command+3&#39;</span><span class="p">,</span> <span class="s1">&#39;ctrl+3&#39;</span><span class="p">],</span> <span class="kd">function</span><span class="p">(</span> <span class="nx">e</span> <span class="p">){</span> <span class="nx">hotkey</span><span class="p">(</span> <span class="nx">e</span><span class="p">,</span> <span class="s1">&#39;function-h3&#39;</span> <span class="p">);</span> <span class="p">});</span>
</span><span class='line'><span class="c1">//           Mousetrap.bind([&#39;command+b&#39;, &#39;ctrl+b&#39;], function( e ){ hotkey( e, &#39;function-bold&#39; ); });</span>
</span><span class='line'>      <span class="nx">Mousetrap</span><span class="p">.</span><span class="nx">bind</span><span class="p">([</span><span class="s1">&#39;command+i&#39;</span><span class="p">,</span> <span class="s1">&#39;ctrl+i&#39;</span><span class="p">],</span> <span class="kd">function</span><span class="p">(</span> <span class="nx">e</span> <span class="p">){</span> <span class="nx">hotkey</span><span class="p">(</span> <span class="nx">e</span><span class="p">,</span> <span class="s1">&#39;function-italic&#39;</span> <span class="p">);</span> <span class="p">});</span>
</span></code></pre></td></tr></table></div></figure>


<p>gollum.editor.jsは，rbenvで入れた自分の環境の場合$HOME/.rbenv/versions/1.9.3-p547/lib/ruby/gems/1.9.1/gems/gollum-3.0.0/lib/gollum/public/gollum/javascript/editorに入っている．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[論文紹介:Recommending Investors for Crowdfunding Projects]]></title>
    <link href="http://yagays.github.io/blog/2014/07/09/www2014review-kickstarter/"/>
    <updated>2014-07-09T16:08:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/07/09/www2014review-kickstarter</id>
    <content type="html"><![CDATA[<p>某所で発表を予定していたんだけど，台風のせいで飛びそうなので先に公開しておきます．読んだのはWWW2014のMatchingセクションに採択されたKickstarterに関する論文．</p>

<script async class="speakerdeck-embed" data-id="1b6dec40e95b01313be5762c67c15dde" data-ratio="1.77777777777778" src="http://yagays.github.io//speakerdeck.com/assets/embed.js"></script>


<h4>補足</h4>

<ul>
<li>まずFrequent InvestorsとOccasional Investorsの和訳について

<ul>
<li>スライド中では「常連投資家」と「気まぐれ投資家」と訳したが，あまり適切な訳語が思い浮かばなかった</li>
<li>無理に訳す必要もないんだけど，FIとOIとかにしてもぱっと見意味不明だし，スライドの都合上日本語にした</li>
</ul>
</li>
<li>KickstarterにはAPIがないから自力でクロールしたらしい

<ul>
<li>Twitterのアカウントとの紐付けなども考えると，かなり大変そう</li>
</ul>
</li>
<li>既存研究あんまり書かなかったんだけど，投資分野の予測なのでいろいろある

<ul>
<li>Kickstarterにおいて特定のフレーズプロジェクトの成功予測に役立つとか(<a href="http://dl.acm.org/citation.cfm?id=2531602.2531656">http://dl.acm.org/citation.cfm?id=2531602.2531656</a>)</li>
<li>Kickstarter以外にもCrowdfundingはいろいろあるので，その辺のレポートも引用されてる</li>
</ul>
</li>
<li>LDAのトピック数は書かれていないんだけど，これはKickstarterのカテゴリー数=13でいいんだろうか

<ul>
<li>なお，今ではCraftとJournalismというカテゴリが加わって15になっている</li>
</ul>
</li>
<li>マッチングの手法について

<ul>
<li>このあたり専門じゃないからあんまり分からないけど，手法的には普通な印象</li>
<li>RBFカーネルのSVMが最良だったのも納得

<ul>
<li>参考：<a href="http://d.hatena.ne.jp/sleepy_yoshi/20120624/p1">SVM実践ガイド (A Practical Guide to Support Vector Classification) - 睡眠不足？！</a></li>
</ul>
</li>
</ul>
</li>
</ul>


<h4>感想</h4>

<ul>
<li>マッチングについて

<ul>
<li>サービス提供側(ここではKickstarter)からすると，例えばこのようなマッチングを作ると考えた時にTwitterのような外部サービスを利用するとなると，ちょっと大変そう

<ul>
<li>外部サイト連携とかを付けないと，そもそも取ってこれないし正式に使えない(?)</li>
<li>一番使いやすいのはKickstarterで表示したプロジェクトのウェブページの履歴とかかな</li>
<li>いずれにせよ投資者の趣向をどう観測するかという感じ</li>
</ul>
</li>
<li>そもそもKickstarterの投資に参加している人のなかでマッチングが上手くいったとして，投資数が増えるのだろうか？

<ul>
<li>プロジェクトの成功率/投資額をあげようと思った時に，推薦に限界がある場合には，いかに他所から興味ある人を引っ張ってくるかになる</li>
<li>ソーシャルのちからに頼れなくなると，結局広告打ったりメディアに紹介してもらったりという従来の方法に頼らざるをえないかも</li>
</ul>
</li>
</ul>
</li>
<li>ウェブサービスに関わる人間にとって大事なこと

<ul>
<li>アカウント新規登録時の登録項目大事

<ul>
<li>ユーザが情報を入力してくれるタイミングなんてそうそう無い</li>
<li>たとえば本論文だとファウンダーのlocationがないとGeographic Dispersionが取れないわけだし</li>
<li>どのような情報が自サービスのレコメンドなどに効いてくるかをしっかり考えておいて布石を打つ必要がある</li>
</ul>
</li>
<li>外部サービス連携大事

<ul>
<li>TwitterとかFacebookとかの情報を一部取れるだけでも嬉しい

<ul>
<li>書き込みなどが取れれば万々歳，友達数とかだけでもFrequent/Occasionalは判別できそう</li>
</ul>
</li>
<li>外部サービスにポストするという機能以外にもユーザの特徴をつかむ意味で大事かと</li>
</ul>
</li>
</ul>
</li>
</ul>


<h4>参考</h4>

<ul>
<li><a href="http://dl.acm.org/citation.cfm?id=2568005">Recommending investors for crowdfunding projects</a></li>
<li><a href="http://www2014.kr/program/research-track-9-7/">Research Track |www2014</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「ドイツ流、日本流: 30年暮らして見えてきたもの」読了]]></title>
    <link href="http://yagays.github.io/blog/2014/06/28/review-germany-japan-essay/"/>
    <updated>2014-06-28T15:39:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/06/28/review-germany-japan-essay</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4794220456" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>本書は「<a href="http://www.amazon.co.jp/gp/product/479421796X/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=479421796X&linkCode=as2&tag=yagays-22">サービスできないドイツ人、主張できない日本人</a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=yagays-22&l=as2&o=9&a=479421796X" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />」を文庫化したものだ．ドイツ人の夫を持ち，ドイツで30年近く住んでいる日本生まれの著者のエッセイだが，旧題にあるようなサービスと主張というトピックはほんの一部で，他にも幅広い文化比較がなされている．異なる国の文化に挟まれて初めて互いの文化の良いところや悪いところが見えてくるように，読者からすると，知らないドイツを知るとともに自分たちの文化を振り返ることになる．</p>

<p>個人的には，ドイツの教育システムが一番気になった．以前読んだ<a href="http://yagays.github.io/blog/2012/09/05/review-critical-reading/">「外国語で発想するための日本語レッスン」</a>ではヨーロッパの教育の良い部分についてフォーカスしていただけに，本書で語られる負の部分，ドイツの義務教育のねじれのようなものが一層際立ってみえた．ランク分けされたギムナジウムや挽回のチャンスが限られた進学システム，マイスターに求められる質の変化など，一見して不合理だとわかっていながらも文化的な背景で縛られて身動きが取れなくなっているように感じる．こういった制度を是正する動きを既得権益を持ったエリートが妨害するといった，古くからある階級社会が見え隠れするところも興味深い．そして，そこから日本の教育に目を向けた時にどう感じるかも考えなくてはいけない．当然ながら日本の教育はドイツとは違うし，それらが成立する背景も違う．例えば，ドイツの教師は徹底的にビジネスライクなのに対して，日本の教師はまったく真逆で，人によっては人生の師ともなるほどに親密な関係を築く．そういう前提があるときに，日本の教育のいいところはどこか，一方でドイツの教育のいいところはどこか，教育を良くしていくにはどこを真似れば良いのかなど，考えなくてはいけないことは山ほどある．結局どっちが良いという問題ではないだけに，なかなか難しいところではある．</p>
]]></content>
  </entry>
  
</feed>
