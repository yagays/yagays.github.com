<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Assembly | Wolfeyes Bioinformatics beta]]></title>
  <link href="http://yagays.github.io/blog/categories/assembly/atom.xml" rel="self"/>
  <link href="http://yagays.github.io/"/>
  <updated>2014-02-12T15:39:27+09:00</updated>
  <id>http://yagays.github.io/</id>
  <author>
    <name><![CDATA[yag_ays]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ゲノムアセンブリにおいて最適なk-merを推定するKmerGenieを試してみた]]></title>
    <link href="http://yagays.github.io/blog/2013/07/07/genome-assembly-kmergenie/"/>
    <updated>2013-07-07T15:17:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/07/07/genome-assembly-kmergenie</id>
    <content type="html"><![CDATA[<p>KmerGenieという，シーケンスデータのみを用いてアセンブラに依存しない形でアセンブルに指定する最適なk-merの値を求めることができるソフトウェアが最近出てきたので，ちょっと使ってみた．</p>

<p><a href="http://kmergenie.bx.psu.edu/">KmerGenie</a></p>

<p>そういえば以前<a href="http://yagays.github.io/blog/2012/06/06/velvetk/">VelvetK</a>という，これも同じようにk-merパラメータをデータセットから推定するツールについて書いたが，これは名前の通りVelvetに特化したソフトウェアだった．2007年くらいに公開され使われ始めたVelvetは，NGSの普及と相まってかなり長い間ゲノムアセンブラとして広く使われてきた印象がある．その後ABySSやMIRA，ALLPATHS-LG，Rayなどの様々なゲノムアセンブラが出てきたが，それらに対してVelvetKのようなk-mer最適化のようなツールは無かったようで，そのあたりアセンブラに非依存というのがKmerGenieの売りのようだ．</p>

<h3>KmerGenieの仕組み</h3>

<p>KmerGenieがどういう仕組みで最適なk-merを推定しているかは，以下のスライドやarXiv.orgで公開されている論文に詳しく書かれている．</p>

<ul>
<li><a href="http://ged.msu.edu/angus/tutorials-2013/files/rayan-2013-june-18-msu.pdf">http://ged.msu.edu/angus/tutorials-2013/files/rayan-2013-june-18-msu.pdf</a></li>
<li><a href="http://arxiv.org/abs/1304.5665">[1304.5665] Informed and Automated k-Mer Size Selection for Genome Assembly</a></li>
<li>(追記:2013/07/23) <a href="http://perso.eleves.bretagne.ens-cachan.fr/~chikhi/2013-july-20-hitseq.pdf">http://perso.eleves.bretagne.ens-cachan.fr/~chikhi/2013-july-20-hitseq.pdf</a></li>
<li>(追記:2013/08/11) 論文：<a href="http://bioinformatics.oxfordjournals.org/content/early/2013/08/01/bioinformatics.btt310">Informed and automated k-mer size selection for genome assembly</a></li>
</ul>


<p>これによると，単純に言ってしまえば最適なk-merの出現頻度というものはきれいな正規分布に従うと仮定した上で，k-merの値を色々変えて出現頻度のヒストグラムを作成し，生成モデルを立ててフィッティングをして最適なk-merの値を推定しているようだ．実際には，正規分布を仮定したゲノム配列の分布とパレート分布を仮定したエラーの配列の分布が混ざった混合分布を考えて，その混合の重みなども考慮したパラメータ最適化をしているらしい．</p>

<h3>KmerGenieのインストール</h3>

<p>まずはKmerGenieをインストールする．ダウンロードしたファイルを展開すると既にディレクトリにkmergenieという実行ファイルがあるが，makeをしないと利用することができないので注意．</p>

<p><code>
$ wget http://kmergenie.bx.psu.edu/kmergenie-1.5397.tar.gz
$ cd kmergenie-1.5397
$ make
</code></p>

<h3>KmerGenieの実行</h3>

<p>それでは実際にfastqファイルに対してKmerGenieを実行してみる．</p>

<h4>1. ゲノムアセンブリのチュートリアルで使用されたE. coliのゲノムシーケンス</h4>

<p>まずは2013年の6月に行われた<a href="http://bioinformatics.msu.edu/ngs-summer-course-2013">MSU NGS Summer Course 2013</a>のチュートリアルで使用されたサンプルデータを使ってみる．これはE. coliのゲノムシーケンスで，元は<a href="http://www.ncbi.nlm.nih.gov/pubmed/21926975">Chitsaz et al.</a>が出したデータの一部のようだ．中身は約4.7Mの70bpのシングルリード．</p>

<p><a href="http://ged.msu.edu/angus/tutorials-2013/assembling-ecoli-with-velvet.html">Assembling E. coli sequences with Velvet — ANGUS 2.0 documentation</a></p>

<p><code>
$ curl -O https://s3.amazonaws.com/public.ged.msu.edu/ecoli_ref-5m-trim.fastq.gz
$ gunzip ecoli_ref-5m-trim.fastq.gz
</code></p>

<p>それではecoli_ref-5m-trim.fastqに対してKmerGenieを実行する．実行後に作られる各k-merでのカウントデータや分布をプロットしたpdfはカレントディレクトリにそのまま出力されるので，もし必要ならディレクトリを別途作ってそこで実行したほうが良いだろう．</p>

<p><code>
$ kmergenie ecoli_ref-5m-trim.fastq
running histogram estimation
Linear estimation: ~130 M distinct 41-mers are in the reads
K-mer sampling: 1/100
| processing                                                                                         |
[going to estimate histograms for values of k: 61 51 41 31 21
-----------------------------------------------------------------------------------------------------------------------------Total time Wallclock  77.7066 s
fitting model to histograms to estimate best k
fitting histogram for k = 21
fitting histogram for k = 31
fitting histogram for k = 41
fitting histogram for k = 51
fitting histogram for k = 61
estimation of the best k so far: 51
refining estimation around [45; 57], with a step of 2
running histogram estimation
Linear estimation: ~139 M distinct 39-mers are in the reads
K-mer sampling: 1/100
| processing                                                                                         |
[going to estimate histograms for values of k: 57 55 53 51 49 47 45
-----------------------------------------------------------------------------------------------------------------------------Total time Wallclock  56.4315 s
fitting model to histograms to estimate best k
fitting histogram for k = 21
fitting histogram for k = 31
fitting histogram for k = 41
fitting histogram for k = 45
fitting histogram for k = 47
fitting histogram for k = 49
fitting histogram for k = 51
fitting histogram for k = 53
fitting histogram for k = 55
fitting histogram for k = 57
fitting histogram for k = 61
table of predicted num. of genomic k-mers: histograms.dat
best k: 55
</code></p>

<p>今回の場合，KmerGenieによる最適なk-merの値は55となった．出力結果で示されるk-mer頻度のプロットを並べて見ると，確かにkが小さいときは少しいびつになっており，k=55あたりで一番正規分布っぽくなっている…??ことがわかる．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/kmergenie1.png" alt="" /></p>

<p>ただ，このサンプルーデータを解析しているチュートリアルではk-merを31〜35にしてvelvetでアセンブルしていることから，今回の55という推定値は少し大きめのような気がする．</p>

<h3>2. Assemblathon2で使用されたセキセイインコのゲノムシーケンス</h3>

<p>次はもう少し大きいデータで試してみよう．Assemblathon2というアセンブリツールの性能を競うコンペで使用されたセキセイインコのゲノムシーケンスの中からDuke Illumina GAIIx runsというデータを使ってみる．中身は76bpのペアエンドで合計で126M readsある．</p>

<p><a href="http://bioshare.bioinformatics.ucdavis.edu/Data/hcbxz0i7kg/Parrot/illumina_duke_runs/">Index of /Data/hcbxz0i7kg/Parrot/illumina_duke_runs</a></p>

<p><code>
$ lftp -e "mirror" http://bioshare.bioinformatics.ucdavis.edu/Data/hcbxz0i7kg/Parrot/illumina_duke_runs/
$ cat *.fastq &gt; budgie.fastq
</code></p>

<p>Assemblathonのサイトによるとセキセイインコのゲノムは二倍体らしいので，今回はKmerGenieの「--diploid」のパラメータを付けて実行する．</p>

<p><code>
$ kmergenie --diploid budgie.fastq
running histogram estimation
Linear estimation: ~3721 M distinct 46-mers are in the reads
K-mer sampling: 1/1000
| processing                                                                                         |
[going to estimate histograms for values of k: 71 61 51 41 31 21
---------------------------------------------------------------------------------------------------------------------------Total time Wallclock  3035.49 s
fitting model to histograms to estimate best k
fitting histogram for k = 21
fitting histogram for k = 31
fitting histogram for k = 41
fitting histogram for k = 51
fitting histogram for k = 61
fitting histogram for k = 71
estimation of the best k so far: 21
refining estimation around [15; 27], with a step of 2
running histogram estimation
Linear estimation: ~6335 M distinct 24-mers are in the reads
K-mer sampling: 1/1000
| processing                                                                                         |
[going to estimate histograms for values of k: 27 25 23 21 19 17 15
---------------------------------------------------------------------------------------------------------------------------Total time Wallclock  2305.61 s
fitting model to histograms to estimate best k
fitting histogram for k = 15
fitting histogram for k = 17
fitting histogram for k = 19
fitting histogram for k = 21
fitting histogram for k = 23
fitting histogram for k = 25
fitting histogram for k = 27
fitting histogram for k = 31
fitting histogram for k = 41
fitting histogram for k = 51
fitting histogram for k = 61
fitting histogram for k = 71
table of predicted num. of genomic k-mers: histograms.dat
best k: 21
</code></p>

<p>データ量が多いと計算時間もかなり大きくなるようで，出力にも少し書かれている通り，今回は1時間半くらいかかった．</p>

<p>さて，今回の場合はKmerGenieによる最適なk-merの値は21となった．出力結果で示されるk-mer頻度のプロットを並べて見てみると，kが大きい値の時には確かに正規分布として近似できないくらいなだらかな曲線になっているものの，K=21の最適値付近でもその様子はあまり変わっていないような感じがする．そもそも可視化の都合もあって横幅が揃えられていなかったりと色々と問題はあるが，とりあえずは今回のデータから推定された最適値は21だった．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/kmergenie2.png" alt="" /></p>

<h3>KmerGenieで使用できるパラメータ</h3>

<p>以上のように，KmerGenieは幾つかのk-merの値で実行して最適と思われる値を自動で出力するが，他にも手動でパラメータを指定することでk-merの範囲や刻みを変更することができる．</p>

<p>```
$ kmergenie
KmerGenie</p>

<p>Usage:</p>

<pre><code>kmergenie &lt;read_file&gt; [options]
</code></pre>

<p>Options:</p>

<pre><code>--diploid    use the diploid model
--one-pass   skip the second pass
-k &lt;value&gt;   largest k-mer size to consider (default: 121)
-l &lt;value&gt;   smallest k-mer size to consider (default: 15)
-s &lt;value&gt;   interval between consecurive kmer sizes (default: 10)
-e &lt;value&gt;   k-mer sampling (default: auto-detected power of 10)"
-o &lt;prefix&gt;  prefix of the output files (default: histograms)"
</code></pre>

<p>```</p>

<h3>まとめ</h3>

<p>このように，KmerGenieはシーケンスデータのみを用いてアセンブラに依存しない形で，アセンブルに指定する最適なk-merの値を求めることができる．推定された値が最良のアセンブルに繋がるかは実際に確認してみないと判断できないが，大まかな目安であったりk-mer決定プロセスの理由付けなどに力を発揮するだろう．今回は結果に対してそれほど詳細な評価を行わなかったが，<a href="http://arxiv.org/abs/1304.5665">arXiv.orgで公開されている論文</a>の方では<a href="http://gage.cbcb.umd.edu/index.html">GAGE</a>のデータセットに対してアセンブル結果を含めた性能比較をしているので，そちらも参考にしていただきたい．</p>

<h3>参考</h3>

<ul>
<li><a href="http://kmergenie.bx.psu.edu/">KmerGenie</a></li>
<li><a href="http://ged.msu.edu/angus/tutorials-2013/files/rayan-2013-june-18-msu.pdf">http://ged.msu.edu/angus/tutorials-2013/files/rayan-2013-june-18-msu.pdf</a></li>
<li><a href="http://arxiv.org/abs/1304.5665">[1304.5665] Informed and Automated k-Mer Size Selection for Genome Assembly</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[スライドメモ："Differential expression analysis of de novo assembled transcriptomes - Nadia Davidson"]]></title>
    <link href="http://yagays.github.io/blog/2013/06/18/slide-diffexp-denovo-assembled-transcriptomes/"/>
    <updated>2013-06-18T13:43:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/06/18/slide-diffexp-denovo-assembled-transcriptomes</id>
    <content type="html"><![CDATA[<p>de novoトランスクリプトームアセンブリに関して配列クラスタリングを解説しているスライドがあったので，ちょっと読んで大まかな流れを追ってみた．ただし後半のクラスタリングの具体的な部分は少し割愛しているほか，内容の正確性は保証できないので注意．</p>

<h2>de novoトランスクリプトームアセンブリの発現差異解析</h2>

<iframe src="http://www.slideshare.net/slideshow/embed_code/18507979?rel=0" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://www.slideshare.net/AustralianBioinformatics/differential-expression-analysis-of-de-novo-assembled-transcriptomes" title="Differential expression analysis of de novo assembled transcriptomes - Nadia Davidson" target="_blank">Differential expression analysis of de novo assembled transcriptomes - Nadia Davidson</a> </strong> from <strong><a href="http://www.slideshare.net/AustralianBioinformatics" target="_blank">Australian Bioinformatics Network</a></strong> </div></p>

<h4>非モデル生物におけるRNA-Seq</h4>

<ul>
<li>非モデル生物におけるRNA-Seq；トランスクリプトームのde novoアセンブル

<ul>
<li>ゲノムアノテーションやゲノム配列が無い状態での解析</li>
</ul>
</li>
</ul>


<h4>トランスクリプトームアセンブラ</h4>

<p>ゲノムアセンブリにおいてはカバレッジに合わせてk-merの長さを最適化していたが，トランスクリプトームアセンブリでは遺伝子ごとに発現量が違うためカバレッジに大きな幅がある</p>

<ul>
<li>解決方法1：ゲノムアセンブラを使って異なるk-merのアセンブル結果を組み合わせる

<ul>
<li><a href="http://www.bcgsc.ca/platform/bioinfo/software/trans-abyss">Trans-ABySS</a>や<a href="http://www.ebi.ac.uk/~zerbino/oases/">Oases</a></li>
</ul>
</li>
<li>解決方法2：トランスクリプトームに特化したアセンブラで単一のk-merでアセンブルする

<ul>
<li><a href="http://trinityrnaseq.sourceforge.net/">Trinity</a></li>
</ul>
</li>
</ul>


<h4>リード数の増加によるアセンブル配列の増加</h4>

<p>横軸がNGSで得られたリード数，縦軸がアセンブルされた配列数を表しており，データ数が増加するにしたがってアセンブルされる配列数も線形に増加する．</p>

<p>スライドでは著者名が間違っているが，ここで引用している図は以下の論文のもの．</p>

<blockquote><p>Francis, W. R. et al. A comparison across non-model animals suggests an optimal sequencing depth for de novo transcriptome assembly. BMC Genomics 14, 167 (2013).</p>

<p><a href="http://www.biomedcentral.com/1471-2164/14/167">http://www.biomedcentral.com/1471-2164/14/167</a></p></blockquote>

<p>余談だが，この論文によるとデータ数が増加するとアセンブルされた配列数が増えるものの，アセンブルされた配列の平均長やN50は途中でサチることが確認されている．この論文の結論としてはデータ数は20M〜30M付近で十分だよねという感じらしい．</p>

<h4>De Bruijn Graphの複雑性</h4>

<p>シーケンスエラーやヘテロ接合箇所などの僅かな配列の違いも異なる配列として出力</p>

<h4>カバレッジの変動</h4>

<p>単一遺伝子内でNGSのショートリードのカバレッジに差があると，複数本の細切れの配列になってしまうことがある</p>

<h4>アイソフォーム単位で発現解析するか遺伝子単位で発現解析するか？</h4>

<ul>
<li>アイソフォーム単位

<ul>
<li>扱う配列が多くなるので大変</li>
<li>発現量解析のときに複数箇所にマッピングされる配列が生じるので発現量推定が大変</li>
<li>全ての転写物に関してアイソフォームがあるわけではない</li>
</ul>
</li>
<li>遺伝子単位

<ul>
<li>スプライシングなどを無視することになる</li>
<li>どうやって複数の転写物を幾つかの遺伝子にまとめるのか？</li>
</ul>
</li>
</ul>


<h4>どうやってアセンブルされた転写物を遺伝子単位にクラスタリングするのか</h4>

<p>アセンブルされた転写物のクラスタリングにおいて決定打は無いものの，幾つか方法はある（配列で共通している箇所を見つけてクラスタリングするとか）</p>

<h4>クラスタリングする際に使える情報</h4>

<ul>
<li>アセンブルする際に出力されるlocus/componentの情報</li>
<li>CD-HITやBlastclustなどの配列相同性によるクラスタリングツール</li>
</ul>


<h4>クラスタリングにはTP・TN・FP・FNを数えて適合率Precisionや再現率Recallを見る</h4>

<p>どうやらTrinityのクラスタリングは良くて，OasesとCD-HIT-ESTの組み合わせは良くないらしい（Trinity's clusteringはRSEMのこと？）</p>

<ul>
<li>CD-HIT-ESTは適合率は高いが再現率は低い

<ul>
<li>配列情報しか使用しないので精度が低い</li>
</ul>
</li>
<li>考えられる他の方法

<ul>
<li>発現量が低い領域は重みを軽くしたい</li>
<li>サンプル間で発現量の違う配列は区別したい</li>
<li>ペアエンドリードを考慮したい</li>
</ul>
</li>
</ul>


<h4>(クラスタリングの具体的な部分は省略)</h4>

<h4>どのようにしてリード数から発現量に変換するのか</h4>

<ul>
<li>TrinityやOasesが推奨する方法

<ul>
<li>アセンブルされた配列に対してマッピング（複数箇所にマップされてもいい）</li>
<li>複数箇所にマップされた配列も考慮して発現量を求めるプログラムを使う(RSEMとか)</li>
</ul>
</li>
</ul>


<p>実際に行われている方法としてよくあるのは，一番長くアセンブルされた配列に代表させてマッピングして発現量を推定するというもの</p>

<h4>まとめ</h4>

<ul>
<li><strong>Q1. なんでそんなにアセンブルされた転写物が出てくるの？</strong>

<ul>
<li>既にアノテーションされている転写物よりも多くアセンブルされるから</li>
<li>de novoトランスクリプトームアセンブリはそもそも難しいから（完全長のアセンブリは目指しているのだけれども）</li>
<li>インタージェニックやノンコーティングの転写物も多くでてくるから</li>
</ul>
</li>
<li><strong>Q2. アイソフォーム単位か遺伝子単位か</strong>

<ul>
<li>遺伝子単位の方がアイソフォーム単位より良さそう</li>
</ul>
</li>
<li><strong>Q3. どうやってアセンブルされた転写物から遺伝子にクラスタリングするか</strong>

<ul>
<li>Trinityのクラスタリングは良くて，OasesとCD-HIT-ESTの組み合わせは良くない</li>
</ul>
</li>
<li><strong>Q4. どのようにしてリード数から発現量に変換するのか</strong>

<ul>
<li>3つの異なる方法で検証したが似た結果を示した</li>
<li>正確なクラスタリングによる結果を得るほうが他のパイプラインを使って発現量差異を見るほうがインパクトがある（と主張している）</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[アセンブルの指標であるN50とNG50の違い]]></title>
    <link href="http://yagays.github.io/blog/2013/05/15/n50-ng50/"/>
    <updated>2013-05-15T09:42:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/05/15/n50-ng50</id>
    <content type="html"><![CDATA[<p>今回は配列をアセンブルするときの指標に使うN50とNG50について少しまとめてみようと思う．</p>

<h3>前置き</h3>

<p>アセンブリというのはシーケンサで得られる短い配列から元のゲノム配列を復元する作業のことで，例えるならば膨大な数のジグソーパズルを形を頼りに完成させるとか，シュレッダーに掛けられて短冊になった書類を元に戻す作業といえる．これだけ聞くと頑張ればできそうな気がするが，実際には使える情報はATGCの配列だけと非常に限られており，場所によっては同じ文字が延々と続く箇所があったり，時々文字が間違っていたりと，手作業では不可能に近いし何より計算機を使ったとしても非常に難しい．それに加えて，そもそも元あった状態である解答を誰も知らないので，結果が合っているかどうかも分からず，答え合わせ（評価）がしづらいということがある．</p>

<p>このアセンブリの評価に関しては，Assemblathonというゲノムアセンブラの精度を争うコンペティションで活発に議論されている．というのも，各研究室で開発されたアセンブラの性能に順位を付けるためという以前に，未知のゲノムに対して今までに誰もアセンブル結果の配列だけで評価してこなかったからだ．もう少し正確に言えば，今までのモデル生物のゲノム配列解読は，過去に実験で確かめられてきた膨大な知見のもとで大量の人材と資金を投入して一歩ずつ進められてきた研究であり，現在のスタイルであるNGSを使った非モデル生物のゲノム配列解読のアプローチとはほとんど別物だと言っても過言ではない．そういった経緯があり，現在のAssemblathonではこれからのゲノム配列解読の基準となるような評価手法について，コンペティションを通して試行錯誤が繰り返されている（この話題に関しては<a href="http://www.slideshare.net/kbradnam/assemblathon-2-talk">Assemblathon2のスライド</a>が詳しい）．</p>

<p>ちなみに，Assemblathonは現在，擬似データでアセンブルを競った第1回は終了し論文も出ており，実際の生物データを使った第2回が終了して論文が出るのを待つだけで（<a href="http://arxiv.org/abs/1301.5406">既にArXivに上がっている</a>），第3回も企画されている．</p>

<p>というわけで，ゲノムを読むといっても今までのようにはいかないし，新しい評価も考えつつやっていかないとねという話．その中でスタンダードな評価指標が今回紹介するN50とNG50になる．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/n50.png" align="right"></p>

<h3>N50</h3>

<p>N50とは一言でいえば配列長の加重平均なのだが，それでは誰も理解してくれないのでもうちょっと噛み砕こう．簡単に言えば，配列を長い順に並べて上から順に足していった時に，全体の長さの半分に達した時の配列の長さ(単位はbp)のことをN50という．イメージだと右図のように，半分の面積になるときの配列の長さがN50となる．得られた配列の分布を見つつ中間くらいの長さを表しているので，長い配列が多いとN50は大きくなるし，逆に長い配列が少なく短い配列が大量にあるとN50は小さくなる．アセンブルの際には復元したいゲノムに少しでも近づけるよう長い配列がたくさん得られると嬉しいので，N50はアセンブルの結果の良し悪しを判断する指標となっている．</p>

<h3>NG50</h3>

<p>とは言うものの，長けりゃそれでいいのかという疑問から出てきたのがNG50という指標だ．アセンブルで得られた配列全体の長さの代わりに，推定されるゲノム配列の長さを使って配列長の平均を計算している．つまり，予想では100Mbpだと推定された生物のゲノムならば，配列を長い順に並べて上から順に足していって100Mbpに達したときの配列の長さをNG50としている．考え方としては，理想となるゲノム配列の長さに近づけるために，長い配列だけじゃなくてある程度短い配列も評価しようということだろう．また，アセンブラの性能を異なるゲノムサイズの生物間で比較する際にも，NG50を用いることで公平に判断することができる．ただし，ゲノムサイズに関しては実験的に求めるかK-merから推定する必要があるので，必ずしも正確かどうかは難しいところがある．</p>

<h3>まとめ</h3>

<p>以上で，ざっとN50とNG50についてまとめてみた．実はこの議論にも続きがあって，NG50だけでは不十分でNG1からNG99までを検討しないといけないという話もある．今回はそこまでは踏み込まないが，気になる人はAssemblathon2の評価手法に関するページを見ていただきたい（<a href="http://assemblathon.org/post/44431933387/assemblathon-2-basic-assembly-metrics">The Assemblathon • Assemblathon 2 basic assembly metrics</a>）．結論としては一概にどの指標がいいかを決めるのは非常に難しいということで，色々と試してみる必要がある．</p>

<h3>参考</h3>

<ul>
<li>(pdf) <a href="http://korflab.ucdavis.edu/datasets/Assemblathon/Assemblathon1/assemblathon_talk.pdf">http://korflab.ucdavis.edu/datasets/Assemblathon/Assemblathon1/assemblathon_talk.pdf</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SOAPdenovo2のアセンブル情報を集計するスクリプト]]></title>
    <link href="http://yagays.github.io/blog/2012/10/11/soapdenovo2-stats/"/>
    <updated>2012-10-11T16:08:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/10/11/soapdenovo2-stats</id>
    <content type="html"><![CDATA[<p>SOAPdenovo2になって，アセンブリで得られた配列の統計情報がscafStatisticsというファイルに出力されるようになった．そのため，自分でアセンブリ結果を解析しなくとも，コンティグ数やN50などの基本情報をチェックすることができる……のだが，scafStatisticsは項目を並べただけのテキストファイルなので，複数のアセンブリ結果を比較しようと思った場合，いちいちファイルを開いて統計情報を集計するのが非常に面倒になる．</p>

<p>ということで，SOAPdenovo2のアセンブルで出力される情報を一つにまとめるスクリプトを簡単に書いてみた．タブ区切りテキストで出力されるので，Excelなどでも見やすいようにしてある．</p>

<br />


<h2>インストール</h2>

<ul>
<li><a href="https://gist.github.com/3870629">https://gist.github.com/3870629</a></li>
</ul>


<p>上記のgistに置いてあるソースコードをダウンロードするか，wgetでソースコードを落としてくる．</p>

<p><code>bash
$ wget --no-check-certificate https://raw.github.com/gist/3870629/6547d69e768e3d87a140d6405fdf19102ff525cb/soapdenovo2_stats.rb    
</code></p>

<p>動作確認はRuby 1.8.7および1.9.3で行っているが，まあ変なことはしてないのでどんな環境でもだいたい動くと思う．RubyのバージョンよりかはSOAPdenovo2の未知の部分や仕様変更などが怖いわけで，そもそも以下のデータセットで出てきたscafStatisticsを参考にしているため，SOAPdenovo2のパラメータなどによっては期待通りの動きをしないかもしれない．あと，例外処理などをあまり真面目に書いていないので，入力ファイルが見つからない場合にエラーを吐かなかったりするが，そこらへんは後々修正するかも．</p>

<br />


<h2>使い方</h2>

<h3>基本的な使い方</h3>

<p><strong><code>ruby soapdenovo2_stats.rb</code></strong>のあとにscafStatisticsのファイルを並べるだけ．標準出力に表示される情報は，scafStatistics内のInformation for assembly Scaffoldのうち，重要な統計量のみとなっている．</p>

<p><code>
$ ruby soapdenovo2_stats.rb path/to/k23.scafStatistics path/to/k25.scafStatistics
Filename        Size_includeN   Size_withoutN   Scaffold_Num    Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Singleton_Num   N50
k23.scafStatistics      4533843 4533843 845     5365    2919    55290   100     845     11457
k25.scafStatistics      4536449 4536449 654     6936    3609    71235   100     654     14798
</code></p>

<h3>その他の詳細な統計量を出力する</h3>

<p><strong><code>-a</code></strong>または<strong><code>--all</code></strong>オプションをつけることでscafStatistics内のすべての統計量を出力するようにしている．また，<strong><code>-c</code></strong>または<strong><code>--contig</code></strong>オプションをつけることによって，ScaffoldではなくContigの情報（scafStatistics内のInformation for assembly Contig より下側の情報）を出力できる．</p>

<p><code>bash
$ ruby soapdenovo2_stats.rb -a -c path/to/k23.scafStatistics
Size_includeN   Size_withoutN   Contig_Num      Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Contig&gt;100      Contig&gt;100 (%)  Contig&gt;500      Contig&gt;500 (%)  Contig&gt;1K       Contig&gt;1K (%)   Contig&gt;10K      Contig&gt;10K (%)  Contig&gt;100K     Contig&gt;100K (%) Contig&gt;1M       Contig&gt;1M (%)   Nucleotide_A    Nucleotide_A (%)        Nucleotide_C    Nucleotide_C (%)    Nucleotide_G    Nucleotide_G (%)        Nucleotide_T    Nucleotide_T (%)        GapContent_N    GapContent_N (%)        Non_ACGTN       Non_ACGTN (%)   GC_Content      N10     Contigs &gt;0 in N10       N20     Contigs &gt;0 in N20       N30     Contigs &gt;0 in N30       N40     Contigs &gt;0 in N40       N50     Contigs &gt;0 in N50       N60     Contigs &gt;0 in N60   N70     Contigs &gt;0 in N70       N80     Contigs &gt;0 in N80       N90     Contigs &gt;0 in N90       NG50    Contigs &gt;0 in NG50      N50_contig-NG50_contig_length_difference        Number_of_contigs_in_scaffolds  Number_of_contigs_not_in_scaffolds(Singleton)   Average_number_of_contigs_per_scaffold
4533843 4533843 845     5365    2919    55290   100     840     99.41   646     76.45   589     69.7    147     17.4    0       0.0     0       0.0     1122311 24.75   1154274 25.46   1146494 25.29   1110764 24.5    0       0.0     0       0.0     50.75   29554   13      21527   31      17094   55      13748   85      11457   121     9180    165     7136    2225257     296     3315    403     NaN     NaN     NaN     0       845     0
</code></p>

<h3>ワイルドカードを使って入力ファイルを複数指定する</h3>

<p>Zshなどのシェルコマンドと同様に，入力ファイルの指定には<strong><code>*</code></strong>や<strong><code>?</code></strong>などのワイルドカードなどが使用できる．</p>

<p><code>bash
$ ruby soapdenovo2_stats.rb  path/to/*.scafStatistics
Filename        Size_includeN   Size_withoutN   Scaffold_Num    Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Singleton_Num   N50
k23.scafStatistics      4533843 4533843 845     5365    2919    55290   100     845     11457
k25.scafStatistics      4536449 4536449 654     6936    3609    71235   100     654     14798
k27.scafStatistics      4539473 4539473 578     7853    3781    79498   100     578     18157
k29.scafStatistics      4544164 4544164 570     7972    3672    103369  100     570     17945
k31.scafStatistics      4550461 4550461 621     7327    3306    77302   100     621     17052
k33.scafStatistics      4582773 4582773 1655    2769    1688    22953   100     1655    5435
k35.scafStatistics      2393501 2393501 16300   146     132     1345    105     16300   142
</code></p>

<h3>特定のカラムでソートする</h3>

<p><strong><code>-s</code></strong>オプションを使うことで，特定のカラムで値をソートした結果を出力することができる．ここではN50を降順で並び替えており，一番右端の列を見るとN50が一番大きいものはk=27であったことがわかる．</p>

<p><code>bash
$ ruby soapdenovo2_stats.rb -s N50 path/to/*.scafStatistics
Filename        Size_includeN   Size_withoutN   Scaffold_Num    Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Singleton_Num   N50
k27.scafStatistics      4539473 4539473 578     7853    3781    79498   100     578     18157
k29.scafStatistics      4544164 4544164 570     7972    3672    103369  100     570     17945
k31.scafStatistics      4550461 4550461 621     7327    3306    77302   100     621     17052
k25.scafStatistics      4536449 4536449 654     6936    3609    71235   100     654     14798
k23.scafStatistics      4533843 4533843 845     5365    2919    55290   100     845     11457
k33.scafStatistics      4582773 4582773 1655    2769    1688    22953   100     1655    5435
k35.scafStatistics      2393501 2393501 16300   146     132     1345    105     16300   142
</code></p>

<h2>今回用いたサンプルデータ</h2>

<p>なお，今回上記で示したデータは，E.coliのSRR001665のデータを用いてSOAPdenovo2_revision210でアセンブルしたものを使用している．アセンブルのコマンドとconfigファイルは以下のとおり．SEQanswersのWikiにあったExampleをそのまま使わせてもらっている（ <a href="http://seqanswers.com/wiki/How-to/de_novo_assembly#SOAP_denovo">http://seqanswers.com/wiki/How-to/de_novo_assembly#SOAP_denovo</a>）．</p>

<p><code>bash
$ SOAPdenovo-63mer all -K 25 -R -s cont.config -o output/k25
</code></p>

<ul>
<li>cont.config</li>
</ul>


<p>```</p>

<h1>maximal read length</h1>

<p>max_rd_len=36
[LIB]</p>

<h1>average insert size</h1>

<p>avg_ins=200</p>

<h1>if sequence needs to be reversed</h1>

<p>reverse_seq=0</p>

<h1>use for contig building only</h1>

<p>asm_flags=1</p>

<h1>in which order the reads are used while scaffolding</h1>

<p>rank=1</p>

<h1>fastq files</h1>

<p>q1=/home/yag_ays/tmp/soapdenovo2_testrun/SRR001665_1.fastq
q2=/home/yag_ays/tmp/soapdenovo2_testrun/SRR001665_2.fastq
```</p>

<h3>参考</h3>

<ul>
<li><a href="http://sourceforge.net/projects/soapdenovo2/">http://sourceforge.net/projects/soapdenovo2/</a></li>
<li><a href="http://www.homolog.us/blogs/2012/07/10/testing-soapdenovo2-prerelease-v-map-and-scaff/">http://www.homolog.us/blogs/2012/07/10/testing-soapdenovo2-prerelease-v-map-and-scaff/</a></li>
</ul>


<h3>ソースコード</h3>

<!-- more -->


<p><div><script src='https://gist.github.com/3870629.js'></script>
<noscript><pre><code>#/usr/bin/env ruby

require &quot;optparse&quot;

def v(s)
  if s == &quot;NaN&quot;
    return s
  elsif s.include?(&quot;%&quot;)
    return s.gsub(&quot;%&quot;,&quot;&quot;).to_f
  else
    return s.to_i
  end
end

def parse_scafstatistics(file)
  stats = []
  header = []
  open(file) { |f|
    header &lt;&lt; &quot;Filename&quot;
    stats &lt;&lt; File.basename(file)
    f.each_line do |line|
      if !line.include?(&quot;&lt;--&quot;) &amp;&amp; line != &quot;\n&quot;
        l = line.chomp.split(&quot;\t&quot;)
        if l[0] == &quot;GC_Content&quot;
          header &lt;&lt; l[0]
          stats &lt;&lt; v(l[1])
        elsif l.length == 3
          if l[2].include?(&quot;%&quot;)
            header &lt;&lt; l[0].strip
            header &lt;&lt; l[0].strip + &quot; (%)&quot;
            stats &lt;&lt; v(l[1])
            stats &lt;&lt; v(l[2])
          else
            header &lt;&lt; l[0]
            header &lt;&lt; &quot;Contigs &gt;0 in &quot; + l[0]
            stats &lt;&lt; v(l[1])
            stats &lt;&lt; v(l[2])
          end
        else
          header &lt;&lt; l[0]
          stats &lt;&lt; v(l[1])
        end
      end
    end
  }
  return header, stats
end

def print_tsv(header, stats, print_all, print_scaffold)
  h = []
  s = []
  if print_scaffold
    if print_all
      h = header[0..57]
      s = stats.map{|a| a[0..57]}
    else
      h = [header[0..8],header[45]]
      s = stats.map{|a| [a[0..8],a[45]]}
    end
  else
    if print_all
      h = header[58..header.length]
      s = stats.map{|a| a[58..a.length]}
    else
      h = [header[58..65].flatten,header[98]]
      s = stats.map{|a| [a[58..65].flatten,a[98]]}
    end
  end
  puts h.join(&quot;\t&quot;)
  s.each do |f|
    puts f.join(&quot;\t&quot;)
  end
end


if __FILE__ == $PROGRAM_NAME
  header = []
  stats = []

  sort_column = nil
  print_all = false
  print_scaffold = true

  ARGV.options do |opt|
    opt.on( &quot;-a&quot;,&quot;--all&quot;) { print_all = true }
    opt.on( &quot;-s VAL&quot;,&quot;--sort&quot;) { |a| sort_column = a }
    opt.on( &quot;-c&quot;, &quot;--contig&quot;) { print_scaffold = false }
    opt.on( &quot;-h&quot;,&quot;--help&quot;) { puts opt ;exit }
    opt.parse!
  end

  Dir.glob(ARGV).each do |f|
    h, s = parse_scafstatistics(f)
    header = h
    stats &lt;&lt; s
  end

  if sort_column
    i = header.index(sort_column)
    if i == nil
      puts &quot;ERROR : unknown column name '#{sort_column}' &quot;
      exit 1
    end
    stats = stats.sort{|a,b| b[i] &lt;=&gt; a[i] }
  end

  print_tsv(header, stats, print_all, print_scaffold)
end
</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VelvetKを使ってVelvetを用いたアセンブルに最適なk-merサイズを推定する]]></title>
    <link href="http://yagays.github.io/blog/2012/06/06/velvetk/"/>
    <updated>2012-06-06T17:12:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/06/06/velvetk</id>
    <content type="html"><![CDATA[<p>(追記, 2013/07/18,  Velvetに依らないk-mer推定の記事：<a href="http://yagays.github.io/blog/2013/07/07/genome-assembly-kmergenie/">ゲノムアセンブリにおいて最適なk-merを推定するKmerGenieを試してみた - Wolfeyes Bioinformatics beta</a>)</p>

<p>VelvetKというスクリプトが公開されたらしい．これはVelvetのアセンブルの際にユーザが指定する必要のあるk-merのkの値を，ゲノムサイズとショートリードのサイズから自動推定するスクリプトのようだ．普通ならばkの値を細かく変えてVelvetを大量に走らせてアセンブル結果を評価するというのが定石だと思うが，もしkの値が自動推定できるなら，そのkの値付近だけを重点的に調べるといったことが出来るので大幅に労力を削減できる．私自身あまりVelvet/Oasesを使った経験が無いのだが，取り敢えず一通り使ってみた．</p>

<!-- more -->


<h3>インストール</h3>

<p>インストールは簡単で，Perlスクリプトを落としてくるだけで実行出来る．外部ライブラリの依存が無いのでお手軽．</p>

<p><code>
$ wget http://bioinformatics.net.au/velvetk.pl
</code></p>

<h3>使い方</h3>

<p>VelvetKでkの推定値を算出するには，</p>

<ul>
<li><strong>ゲノム配列</strong> または <strong>ゲノムサイズ</strong></li>
<li><strong>アセンブルの元になるショートリード</strong></li>
</ul>


<p>の2つの入力が必要になる．ゲノム配列が既知の場合には<code>--genome</code>オプションを使って，fasta形式のゲノム配列のファイルを指定する．ショートリードはfastq形式などのファイルを指定することになるが，gzやbz2などの圧縮形式にも対応している．ゲノム配列を指定してVelvetKを実行するには，以下のようにコマンドを実行する．</p>

<p><code>
$ perl velvetk.pl --genome chr.fasta R1.fastq R2.fastq
</code></p>

<p>一方でde novoのようなゲノム配列が無い場合には，対象種のおおまかなゲノムサイズを入力することになる．ゲノムサイズの指定の場合には，k/M/Gといった接頭辞を使う事ができる．ゲノムサイズを数値で指定してVelvetKを実行するには，以下のようにコマンドを実行する．</p>

<p><code>
$ perl velvetk.pl --size=1M chr.fasta R1.fastq R2.fastq
</code>
とする．</p>

<h3>擬似データで試してみる</h3>

<p>今回はお手製の擬似データで試してみることにする．</p>

<p>擬似データの作り方は簡単で，乱数を使って擬似的に作ったゲノム配列からこれまた乱数を使って擬似的にショートリードを作成するというもの．ゲノムの長さを1Mbとして，100bpのペアエンドの配列を500,000本用意して，カバレッジ100xくらいのゲノムシーケンスを想定した．</p>

<p>その擬似データセットで実行してみると以下のような出力が得られた．実際にはショートリードの長さや本数も不均一になるので，以下のように各値が綺麗な感じにはならないと思う．</p>

<p><code>
$ perl velvetk.pl --genome chr.fasta R1.fastq R2.fastq
Estimating target genome size from 'chr.fasta'
Target genome size is 1000000 bp
Desire k-mer coverage of 25
Using cat for R1.fastq
Read 500000 sequences from R1.fastq
Using cat for R2.fastq
Read 500000 sequences from R2.fastq
Considered 1000000 reads with lengths 100..100 bp
K       #Kmers  Kmer-Cov
1       100000000       100.0
3       98000000        98.0
5       96000000        96.0
7       94000000        94.0
9       92000000        92.0
〜〜〜中略〜〜〜
71      30000000        30.0
73      28000000        28.0
75      26000000        26.0
77      24000000        24.0
79      22000000        22.0
81      20000000        20.0
83      18000000        18.0
85      16000000        16.0
87      14000000        14.0
89      12000000        12.0
91      10000000        10.0
93      8000000 8.0
95      6000000 6.0
97      4000000 4.0
99      2000000 2.0
</code></p>

<p>入力ファイルをそれぞれ読み込んだ後，それぞれのkの値に対して#kmersとKmer-Covが表示される．#kmersはショートリードのデータからカウントできるk-merの本数で，例えばK=99の場合では100bpから抜き出せる99merは2つあるので，今回の場合リード数500,000*2の合計2,000,000という感じだろう．次のKmer-Covは，いわゆるK-mer Coverageと呼ばれるもので，実際のカバレッジとk-merで見た時のカバレッジの割合，もしくは変換するときの係数に当たる．</p>

<p>ではどうやってこのリストからVelvetに最適なkの値を推定するかというと，出力の始めの方に書かれている</p>

<p><code>
Desire k-mer coverage of 25
</code></p>

<p>のところを見て，Kmer-Covが25を下回った時のkの値が最適なkの値とする．今回の場合だとk=77でKmer-Covが24.0になるので，k=77が最適なk-merのサイズとなる．</p>

<p>それではなぜ25なのかというと，このスクリプトの場合だとデフォルトだからということになってしまうのだが，どうやらk-mer Coverageにはだいたい10~20あれば十分という知見(多分経験則)があるらしい．一般的にはkの値が小さいとコンティグが繋がりにくく，kの値が大きいと細かな違いをコンティグに反映出来無いといったsensitivityとspecificityのトレードオフがある．それらのいい具合の中間点ということで，k-mer Coverageを見て判断しようということらしい．</p>

<p>また，このスクリプトでは閾値となるk-mer Coverageを変更するオプション<code>--cov</code>や，リストの出力を抜きにして最適なKの値だけを出力するオプション<code>--best</code>なども用意されている．</p>

<p>```
$ perl velvetk.pl --best --cov=20 --size=1M R1.fastq R2.fastq
Target genome size is 1000000 bp
Desire k-mer coverage of 20
Using cat for R1.fastq
Read 500000 sequences from R1.fastq
Using cat for R2.fastq
Read 500000 sequences from R2.fastq
Considered 1000000 reads with lengths 100..100 bp
81</p>

<p>```
 上の場合では，k=81が最適とおもわれるkの推定結果となる．</p>

<h3>実はWeb版もある</h3>

<p>ちなみに，ここまで書いておいて難だが，実はVelvetKと同作者が作った簡易版「Velvet Advisor」がWebアプリケーションとして既に存在している．ただ，この簡易版は複数の入力ファイルに対応していないので，使えるケースが制限されている．普通は複数のライブラリを読んでアセンブルするとと思うので，まあ今回のVelvetKで使いやすくなったという感じだろうか．</p>

<p><a href="http://dna.med.monash.edu.au/~torsten/velvet_advisor/">http://dna.med.monash.edu.au/~torsten/velvet_advisor/</a></p>

<h3>まとめ</h3>

<p>今回は擬似データを使ってVelvetKを動かしてみたが，これからアセンブルをするという人にとってはパラメータの大雑把な目安となって良いと思う．どれだけの精度で当たるのか不安なところもあるので，実際にVelvetを使ったアセンブルのプロジェクトでVelvetKの推定値がどれだけ当たっているかが知りたいところだけれども，結局目安としてしか使わないのだから，まあ適当でいいんだろう．</p>

<h3>参考資料</h3>

<ul>
<li><a href="http://bioinformatics.net.au/software.velvetk.shtml">http://bioinformatics.net.au/software.velvetk.shtml</a></li>
<li><a href="http://kevin-gattaca.blogspot.jp/2012/06/fwd-velvet-users-velvetkpl-choose-good.html">http://kevin-gattaca.blogspot.jp/2012/06/fwd-velvet-users-velvetkpl-choose-good.html</a></li>
<li><a href="http://dna.med.monash.edu.au/~torsten/velvet_advisor/">http://dna.med.monash.edu.au/~torsten/velvet_advisor/</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
