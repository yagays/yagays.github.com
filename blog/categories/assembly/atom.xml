<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Assembly | Wolfeyes Bioinformatics beta]]></title>
  <link href="http://yagays.github.io/blog/categories/assembly/atom.xml" rel="self"/>
  <link href="http://yagays.github.io/"/>
  <updated>2013-06-19T08:03:46+09:00</updated>
  <id>http://yagays.github.io/</id>
  <author>
    <name><![CDATA[yag_ays]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[スライドメモ："Differential expression analysis of de novo assembled transcriptomes - Nadia Davidson"]]></title>
    <link href="http://yagays.github.io/blog/2013/06/18/slide-diffexp-denovo-assembled-transcriptomes/"/>
    <updated>2013-06-18T13:43:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/06/18/slide-diffexp-denovo-assembled-transcriptomes</id>
    <content type="html"><![CDATA[<p>de novoトランスクリプトームアセンブリに関して配列クラスタリングを解説しているスライドがあったので，ちょっと読んで大まかな流れを追ってみた．ただし後半のクラスタリングの具体的な部分は少し割愛しているほか，内容の正確性は保証できないので注意．</p>

<h2>de novoトランスクリプトームの発現差異解析</h2>

<iframe src="http://www.slideshare.net/slideshow/embed_code/18507979?rel=0" width="427" height="356" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen webkitallowfullscreen mozallowfullscreen> </iframe>


<p> <div style="margin-bottom:5px"> <strong> <a href="http://www.slideshare.net/AustralianBioinformatics/differential-expression-analysis-of-de-novo-assembled-transcriptomes" title="Differential expression analysis of de novo assembled transcriptomes - Nadia Davidson" target="_blank">Differential expression analysis of de novo assembled transcriptomes - Nadia Davidson</a> </strong> from <strong><a href="http://www.slideshare.net/AustralianBioinformatics" target="_blank">Australian Bioinformatics Network</a></strong> </div></p>

<h4>非モデル生物におけるRNA-Seq</h4>

<ul>
<li>非モデル生物におけるRNA-Seq；トランスクリプトームのde novoアセンブル

<ul>
<li>ゲノムアノテーションやゲノム配列が無い状態での解析</li>
</ul>
</li>
</ul>


<h4>トランスクリプトームアセンブラ</h4>

<p>ゲノムアセンブリにおいてはカバレッジに合わせてk-merの長さを最適化していたが，トランスクリプトームアセンブルでは遺伝子ごとに発現量が違うためカバレッジに大きな幅がある</p>

<ul>
<li>解決方法1：ゲノムアセンブラを使って異なるk-merのアセンブル結果を組み合わせる

<ul>
<li><a href="http://www.bcgsc.ca/platform/bioinfo/software/trans-abyss">Trans-abyss</a>や<a href="http://www.ebi.ac.uk/~zerbino/oases/">Oases</a></li>
</ul>
</li>
<li>解決方法2：トランスクリプトームに特化したアセンブラで単一のk-merでアセンブルする

<ul>
<li><a href="http://trinityrnaseq.sourceforge.net/">Trinity</a></li>
</ul>
</li>
</ul>


<h4>リード数の増加によるアセンブル配列の増加</h4>

<p>横軸がNGSで得られたリード数，縦軸がアセンブルされた配列数を表しており，データ数が増加するにしたがってアセンブルされる配列数も線形に増加する．</p>

<p>スライドでは著者名が間違っているが，ここで引用している図は以下の論文のもの．</p>

<blockquote><p>Francis, W. R. et al. A comparison across non-model animals suggests an optimal sequencing depth for de novo transcriptome assembly. BMC Genomics 14, 167 (2013).</p>

<p><a href="http://www.biomedcentral.com/1471-2164/14/167">http://www.biomedcentral.com/1471-2164/14/167</a></p></blockquote>

<p>余談だが，この論文によるとデータ数が増加するとアセンブルされた配列数が増えるものの，アセンブルされた配列の平均長やN50は途中でサチることが確認されている．この論文の結論としてはデータ数は20M〜30M付近で十分だよねという感じらしい．</p>

<h4>De Bruijn Graphの複雑性</h4>

<p>シーケンスエラーやヘテロ接合箇所などの僅かな配列の違いも異なる配列として出力</p>

<h4>カバレッジの変動</h4>

<p>単一遺伝子内でNGSのショートリードのカバレッジに差があると，複数本の細切れの配列になってしまうことがある</p>

<h4>アイソフォーム単位で発現解析するか遺伝子単位で発現解析するか？</h4>

<ul>
<li>アイソフォーム単位

<ul>
<li>扱う配列が多くなるので大変</li>
<li>発現量解析のときに複数箇所にマッピングされる配列が生じるので発現量推定が大変</li>
<li>全ての転写物に関してアイソフォームがあるわけではない</li>
</ul>
</li>
<li>遺伝子単位

<ul>
<li>スプライシングなどを無視することになる</li>
<li>どうやって複数の転写物を幾つかの遺伝子にまとめるのか？</li>
</ul>
</li>
</ul>


<h4>どうやってアセンブルされた転写物を遺伝子単位にクラスタリングするのか</h4>

<p>アセンブルされた転写物のクラスタリングにおいて決定打は無いものの，幾つか方法はある（配列で共通している箇所を見つけてクラスタリングするとか）</p>

<h4>クラスタリングする際に使える情報</h4>

<ul>
<li>アセンブルする際に出力されるlocus/componentの情報</li>
<li>CD-HITやBlastclustなどの配列相同性によるクラスタリングツール</li>
</ul>


<h4>クラスタリングにはTP・TN・FP・FNを数えて適合率Precisionや再現率Recallを見る</h4>

<p>どうやらTrinityのクラスタリングは良くて，OasesとCD-HIT-ESTの組み合わせは良くないらしい（Trinity's clusteringはRSEMのこと？）</p>

<ul>
<li>CD-HIT-ESTは適合率は高いが再現率は低い

<ul>
<li>配列情報しか使用しないので精度が低い</li>
</ul>
</li>
<li>考えられる他の方法

<ul>
<li>発現量が低い領域は重みを軽くしたい</li>
<li>サンプル間で発現量の違う配列は区別したい</li>
<li>ペアエンドリードを考慮したい</li>
</ul>
</li>
</ul>


<h4>(クラスタリングの具体的な部分は省略)</h4>

<h4>どのようにしてリード数から発現量に変換するのか</h4>

<ul>
<li>TrinityやOasesが推奨する方法

<ul>
<li>アセンブルされた配列に対してマッピング（複数箇所にマップされてもいい）</li>
<li>複数箇所にマップされた配列も考慮して発現量を求めるプログラムを使う(RSEMとか)</li>
</ul>
</li>
</ul>


<p>実際に行われている方法としてよくあるのは，一番長くアセンブルされた配列に代表させてマッピングして発現量を推定するというもの</p>

<h4>まとめ</h4>

<ul>
<li><strong>Q1. なんでそんなにアセンブルされた転写物が出てくるの？</strong>

<ul>
<li>既にアノテーションされている転写物よりも多くアセンブルされるから</li>
<li>de novoトランスクリプトームアセンブリはそもそも難しいから（完全長のアセンブリは目指しているのだけれども）</li>
<li>インタージェニックやノンコーティングの転写物も多くでてくるから</li>
</ul>
</li>
<li><strong>Q2. アイソフォーム単位か遺伝子単位か</strong>

<ul>
<li>遺伝子単位の方がアイソフォーム単位より良さそう</li>
</ul>
</li>
<li><strong>Q3. どうやってアセンブルされた転写物から遺伝子にクラスタリングするか</strong>

<ul>
<li>Trinityのクラスタリングは良くて，OasesとCD-HIT-ESTの組み合わせは良くない</li>
</ul>
</li>
<li><strong>Q4. どのようにしてリード数から発現量に変換するのか</strong>

<ul>
<li>3つの異なる方法で検証したが似た結果を示した</li>
<li>正確なクラスタリングによる結果を得るほうが他のパイプラインを使って発現量差異を見るほうがインパクトがある（と主張している）</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[アセンブルの指標であるN50とNG50の違い]]></title>
    <link href="http://yagays.github.io/blog/2013/05/15/n50-ng50/"/>
    <updated>2013-05-15T09:42:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/05/15/n50-ng50</id>
    <content type="html"><![CDATA[<p>今回は配列をアセンブルするときの指標に使うN50とNG50について少しまとめてみようと思う．</p>

<h3>前置き</h3>

<p>アセンブリというのはシーケンサで得られる短い配列から元のゲノム配列を復元する作業のことで，例えるならば膨大な数のジグソーパズルを形を頼りに完成させるとか，シュレッダーに掛けられて短冊になった書類を元に戻す作業といえる．これだけ聞くと頑張ればできそうな気がするが，実際には使える情報はATGCの配列だけと非常に限られており，場所によっては同じ文字が延々と続く箇所があったり，時々文字が間違っていたりと，手作業では不可能に近いし何より計算機を使ったとしても非常に難しい．それに加えて，そもそも元あった状態である解答を誰も知らないので，結果が合っているかどうかも分からず，答え合わせ（評価）がしづらいということがある．</p>

<p>このアセンブリの評価に関しては，Assemblathonというゲノムアセンブラの精度を争うコンペティションで活発に議論されている．というのも，各研究室で開発されたアセンブラの性能に順位を付けるためという以前に，未知のゲノムに対して今までに誰もアセンブル結果の配列だけで評価してこなかったからだ．もう少し正確に言えば，今までのモデル生物のゲノム配列解読は，過去に実験で確かめられてきた膨大な知見のもとで大量の人材と資金を投入して一歩ずつ進められてきた研究であり，現在のスタイルであるNGSを使った非モデル生物のゲノム配列解読のアプローチとはほとんど別物だと言っても過言ではない．そういった経緯があり，現在のAssemblathonではこれからのゲノム配列解読の基準となるような評価手法について，コンペティションを通して試行錯誤が繰り返されている（この話題に関しては<a href="http://www.slideshare.net/kbradnam/assemblathon-2-talk">Assemblathon2のスライド</a>が詳しい）．</p>

<p>ちなみに，Assemblathonは現在，擬似データでアセンブルを競った第1回は終了し論文も出ており，実際の生物データを使った第2回が終了して論文が出るのを待つだけで（<a href="http://arxiv.org/abs/1301.5406">既にArXivに上がっている</a>），第3回も企画されている．</p>

<p>というわけで，ゲノムを読むといっても今までのようにはいかないし，新しい評価も考えつつやっていかないとねという話．その中でスタンダードな評価指標が今回紹介するN50とNG50になる．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/n50.png" align="right"></p>

<h3>N50</h3>

<p>N50とは一言でいえば配列長の加重平均なのだが，それでは誰も理解してくれないのでもうちょっと噛み砕こう．簡単に言えば，配列を長い順に並べて上から順に足していった時に，全体の長さの半分に達した時の配列の長さ(単位はbp)のことをN50という．イメージだと右図のように，半分の面積になるときの配列の長さがN50となる．得られた配列の分布を見つつ中間くらいの長さを表しているので，長い配列が多いとN50は大きくなるし，逆に長い配列が少なく短い配列が大量にあるとN50は小さくなる．アセンブルの際には復元したいゲノムに少しでも近づけるよう長い配列がたくさん得られると嬉しいので，N50はアセンブルの結果の良し悪しを判断する指標となっている．</p>

<h3>NG50</h3>

<p>とは言うものの，長けりゃそれでいいのかという疑問から出てきたのがNG50という指標だ．アセンブルで得られた配列全体の長さの代わりに，推定されるゲノム配列の長さを使って配列長の平均を計算している．つまり，予想では100Mbpだと推定された生物のゲノムならば，配列を長い順に並べて上から順に足していって100Mbpに達したときの配列の長さをNG50としている．考え方としては，理想となるゲノム配列の長さに近づけるために，長い配列だけじゃなくてある程度短い配列も評価しようということだろう．また，アセンブラの性能を異なるゲノムサイズの生物間で比較する際にも，NG50を用いることで公平に判断することができる．ただし，ゲノムサイズに関しては実験的に求めるかK-merから推定する必要があるので，必ずしも正確かどうかは難しいところがある．</p>

<h3>まとめ</h3>

<p>以上で，ざっとN50とNG50についてまとめてみた．実はこの議論にも続きがあって，NG50だけでは不十分でNG1からNG99までを検討しないといけないという話もある．今回はそこまでは踏み込まないが，気になる人はAssemblathon2の評価手法に関するページを見ていただきたい（<a href="http://assemblathon.org/post/44431933387/assemblathon-2-basic-assembly-metrics">The Assemblathon • Assemblathon 2 basic assembly metrics</a>）．結論としては一概にどの指標がいいかを決めるのは非常に難しいということで，色々と試して見る必要がある．</p>

<h3>参考</h3>

<ul>
<li>(pdf) <a href="http://korflab.ucdavis.edu/datasets/Assemblathon/Assemblathon1/assemblathon_talk.pdf">http://korflab.ucdavis.edu/datasets/Assemblathon/Assemblathon1/assemblathon_talk.pdf</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SOAPdenovo2のアセンブル情報を集計するスクリプト]]></title>
    <link href="http://yagays.github.io/blog/2012/10/11/soapdenovo2-stats/"/>
    <updated>2012-10-11T16:08:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/10/11/soapdenovo2-stats</id>
    <content type="html"><![CDATA[<p>SOAPdenovo2になって，アセンブリで得られた配列の統計情報がscafStatisticsというファイルに出力されるようになった．そのため，自分でアセンブリ結果を解析しなくとも，コンティグ数やN50などの基本情報をチェックすることができる……のだが，scafStatisticsは項目を並べただけのテキストファイルなので，複数のアセンブリ結果を比較しようと思った場合，いちいちファイルを開いて統計情報を集計するのが非常に面倒になる．</p>

<p>ということで，SOAPdenovo2のアセンブルで出力される情報を一つにまとめるスクリプトを簡単に書いてみた．タブ区切りテキストで出力されるので，Excelなどでも見やすいようにしてある．</p>

<br />


<h2>インストール</h2>

<ul>
<li><a href="https://gist.github.com/3870629">https://gist.github.com/3870629</a></li>
</ul>


<p>上記のgistに置いてあるソースコードをダウンロードするか，wgetでソースコードを落としてくる．</p>

<p><code>bash
$ wget --no-check-certificate https://raw.github.com/gist/3870629/6547d69e768e3d87a140d6405fdf19102ff525cb/soapdenovo2_stats.rb    
</code></p>

<p>動作確認はRuby 1.8.7および1.9.3で行っているが，まあ変なことはしてないのでどんな環境でもだいたい動くと思う．RubyのバージョンよりかはSOAPdenovo2の未知の部分や仕様変更などが怖いわけで，そもそも以下のデータセットで出てきたscafStatisticsを参考にしているため，SOAPdenovo2のパラメータなどによっては期待通りの動きをしないかもしれない．あと，例外処理などをあまり真面目に書いていないので，入力ファイルが見つからない場合にエラーを吐かなかったりするが，そこらへんは後々修正するかも．</p>

<br />


<h2>使い方</h2>

<h3>基本的な使い方</h3>

<p><strong><code>ruby soapdenovo2_stats.rb</code></strong>のあとにscafStatisticsのファイルを並べるだけ．標準出力に表示される情報は，scafStatistics内のInformation for assembly Scaffoldのうち，重要な統計量のみとなっている．</p>

<p><code>
$ ruby soapdenovo2_stats.rb path/to/k23.scafStatistics path/to/k25.scafStatistics
Filename        Size_includeN   Size_withoutN   Scaffold_Num    Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Singleton_Num   N50
k23.scafStatistics      4533843 4533843 845     5365    2919    55290   100     845     11457
k25.scafStatistics      4536449 4536449 654     6936    3609    71235   100     654     14798
</code></p>

<h3>その他の詳細な統計量を出力する</h3>

<p><strong><code>-a</code></strong>または<strong><code>--all</code></strong>オプションをつけることでscafStatistics内のすべての統計量を出力するようにしている．また，<strong><code>-c</code></strong>または<strong><code>--contig</code></strong>オプションをつけることによって，ScaffoldではなくContigの情報（scafStatistics内のInformation for assembly Contig より下側の情報）を出力できる．</p>

<p><code>bash
$ ruby soapdenovo2_stats.rb -a -c path/to/k23.scafStatistics
Size_includeN   Size_withoutN   Contig_Num      Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Contig&gt;100      Contig&gt;100 (%)  Contig&gt;500      Contig&gt;500 (%)  Contig&gt;1K       Contig&gt;1K (%)   Contig&gt;10K      Contig&gt;10K (%)  Contig&gt;100K     Contig&gt;100K (%) Contig&gt;1M       Contig&gt;1M (%)   Nucleotide_A    Nucleotide_A (%)        Nucleotide_C    Nucleotide_C (%)    Nucleotide_G    Nucleotide_G (%)        Nucleotide_T    Nucleotide_T (%)        GapContent_N    GapContent_N (%)        Non_ACGTN       Non_ACGTN (%)   GC_Content      N10     Contigs &gt;0 in N10       N20     Contigs &gt;0 in N20       N30     Contigs &gt;0 in N30       N40     Contigs &gt;0 in N40       N50     Contigs &gt;0 in N50       N60     Contigs &gt;0 in N60   N70     Contigs &gt;0 in N70       N80     Contigs &gt;0 in N80       N90     Contigs &gt;0 in N90       NG50    Contigs &gt;0 in NG50      N50_contig-NG50_contig_length_difference        Number_of_contigs_in_scaffolds  Number_of_contigs_not_in_scaffolds(Singleton)   Average_number_of_contigs_per_scaffold
4533843 4533843 845     5365    2919    55290   100     840     99.41   646     76.45   589     69.7    147     17.4    0       0.0     0       0.0     1122311 24.75   1154274 25.46   1146494 25.29   1110764 24.5    0       0.0     0       0.0     50.75   29554   13      21527   31      17094   55      13748   85      11457   121     9180    165     7136    2225257     296     3315    403     NaN     NaN     NaN     0       845     0
</code></p>

<h3>ワイルドカードを使って入力ファイルを複数指定する</h3>

<p>Zshなどのシェルコマンドと同様に，入力ファイルの指定には<strong><code>*</code></strong>や<strong><code>?</code></strong>などのワイルドカードなどが使用できる．</p>

<p><code>bash
$ ruby soapdenovo2_stats.rb  path/to/*.scafStatistics
Filename        Size_includeN   Size_withoutN   Scaffold_Num    Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Singleton_Num   N50
k23.scafStatistics      4533843 4533843 845     5365    2919    55290   100     845     11457
k25.scafStatistics      4536449 4536449 654     6936    3609    71235   100     654     14798
k27.scafStatistics      4539473 4539473 578     7853    3781    79498   100     578     18157
k29.scafStatistics      4544164 4544164 570     7972    3672    103369  100     570     17945
k31.scafStatistics      4550461 4550461 621     7327    3306    77302   100     621     17052
k33.scafStatistics      4582773 4582773 1655    2769    1688    22953   100     1655    5435
k35.scafStatistics      2393501 2393501 16300   146     132     1345    105     16300   142
</code></p>

<h3>特定のカラムでソートする</h3>

<p><strong><code>-s</code></strong>オプションを使うことで，特定のカラムで値をソートした結果を出力することができる．ここではN50を降順で並び替えており，一番右端の列を見るとN50が一番大きいものはk=27であったことがわかる．</p>

<p><code>bash
$ ruby soapdenovo2_stats.rb -s N50 path/to/*.scafStatistics
Filename        Size_includeN   Size_withoutN   Scaffold_Num    Mean_Size       Median_Size     Longest_Seq     Shortest_Seq    Singleton_Num   N50
k27.scafStatistics      4539473 4539473 578     7853    3781    79498   100     578     18157
k29.scafStatistics      4544164 4544164 570     7972    3672    103369  100     570     17945
k31.scafStatistics      4550461 4550461 621     7327    3306    77302   100     621     17052
k25.scafStatistics      4536449 4536449 654     6936    3609    71235   100     654     14798
k23.scafStatistics      4533843 4533843 845     5365    2919    55290   100     845     11457
k33.scafStatistics      4582773 4582773 1655    2769    1688    22953   100     1655    5435
k35.scafStatistics      2393501 2393501 16300   146     132     1345    105     16300   142
</code></p>

<h2>今回用いたサンプルデータ</h2>

<p>なお，今回上記で示したデータは，E.coliのSRR001665のデータを用いてSOAPdenovo2_revision210でアセンブルしたものを使用している．アセンブルのコマンドとconfigファイルは以下のとおり．SEQanswersのWikiにあったExampleをそのまま使わせてもらっている（ <a href="http://seqanswers.com/wiki/How-to/de_novo_assembly#SOAP_denovo">http://seqanswers.com/wiki/How-to/de_novo_assembly#SOAP_denovo</a>）．</p>

<p><code>bash
$ SOAPdenovo-63mer all -K 25 -R -s cont.config -o output/k25
</code></p>

<ul>
<li>cont.config</li>
</ul>


<p>```</p>

<h1>maximal read length</h1>

<p>max_rd_len=36
[LIB]</p>

<h1>average insert size</h1>

<p>avg_ins=200</p>

<h1>if sequence needs to be reversed</h1>

<p>reverse_seq=0</p>

<h1>use for contig building only</h1>

<p>asm_flags=1</p>

<h1>in which order the reads are used while scaffolding</h1>

<p>rank=1</p>

<h1>fastq files</h1>

<p>q1=/home/yag_ays/tmp/soapdenovo2_testrun/SRR001665_1.fastq
q2=/home/yag_ays/tmp/soapdenovo2_testrun/SRR001665_2.fastq
```</p>

<h3>参考</h3>

<ul>
<li><a href="http://sourceforge.net/projects/soapdenovo2/">http://sourceforge.net/projects/soapdenovo2/</a></li>
<li><a href="http://www.homolog.us/blogs/2012/07/10/testing-soapdenovo2-prerelease-v-map-and-scaff/">http://www.homolog.us/blogs/2012/07/10/testing-soapdenovo2-prerelease-v-map-and-scaff/</a></li>
</ul>


<h3>ソースコード</h3>

<!-- more -->


<p><div><script src='https://gist.github.com/3870629.js'></script>
<noscript><pre><code>#/usr/bin/env ruby

require &quot;optparse&quot;

def v(s)
  if s == &quot;NaN&quot;
    return s
  elsif s.include?(&quot;%&quot;)
    return s.gsub(&quot;%&quot;,&quot;&quot;).to_f
  else
    return s.to_i
  end
end

def parse_scafstatistics(file)
  stats = []
  header = []
  open(file) { |f|
    header &lt;&lt; &quot;Filename&quot;
    stats &lt;&lt; File.basename(file)
    f.each_line do |line|
      if !line.include?(&quot;&lt;--&quot;) &amp;&amp; line != &quot;\n&quot;
        l = line.chomp.split(&quot;\t&quot;)
        if l[0] == &quot;GC_Content&quot;
          header &lt;&lt; l[0]
          stats &lt;&lt; v(l[1])
        elsif l.length == 3
          if l[2].include?(&quot;%&quot;)
            header &lt;&lt; l[0].strip
            header &lt;&lt; l[0].strip + &quot; (%)&quot;
            stats &lt;&lt; v(l[1])
            stats &lt;&lt; v(l[2])
          else
            header &lt;&lt; l[0]
            header &lt;&lt; &quot;Contigs &gt;0 in &quot; + l[0]
            stats &lt;&lt; v(l[1])
            stats &lt;&lt; v(l[2])
          end
        else
          header &lt;&lt; l[0]
          stats &lt;&lt; v(l[1])
        end
      end
    end
  }
  return header, stats
end

def print_tsv(header, stats, print_all, print_scaffold)
  h = []
  s = []
  if print_scaffold
    if print_all
      h = header[0..57]
      s = stats.map{|a| a[0..57]}
    else
      h = [header[0..8],header[45]]
      s = stats.map{|a| [a[0..8],a[45]]}
    end
  else
    if print_all
      h = header[58..header.length]
      s = stats.map{|a| a[58..a.length]}
    else
      h = [header[58..65].flatten,header[98]]
      s = stats.map{|a| [a[58..65].flatten,a[98]]}
    end
  end
  puts h.join(&quot;\t&quot;)
  s.each do |f|
    puts f.join(&quot;\t&quot;)
  end
end


if __FILE__ == $PROGRAM_NAME
  header = []
  stats = []

  sort_column = nil
  print_all = false
  print_scaffold = true

  ARGV.options do |opt|
    opt.on( &quot;-a&quot;,&quot;--all&quot;) { print_all = true }
    opt.on( &quot;-s VAL&quot;,&quot;--sort&quot;) { |a| sort_column = a }
    opt.on( &quot;-c&quot;, &quot;--contig&quot;) { print_scaffold = false }
    opt.on( &quot;-h&quot;,&quot;--help&quot;) { puts opt ;exit }
    opt.parse!
  end

  Dir.glob(ARGV).each do |f|
    h, s = parse_scafstatistics(f)
    header = h
    stats &lt;&lt; s
  end

  if sort_column
    i = header.index(sort_column)
    if i == nil
      puts &quot;ERROR : unknown column name '#{sort_column}' &quot;
      exit 1
    end
    stats = stats.sort{|a,b| b[i] &lt;=&gt; a[i] }
  end

  print_tsv(header, stats, print_all, print_scaffold)
end
</code></pre></noscript></div>
</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[VelvetKを使ってVelvetを用いたアセンブルに最適なk-merサイズを推定する]]></title>
    <link href="http://yagays.github.io/blog/2012/06/06/velvetk/"/>
    <updated>2012-06-06T17:12:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/06/06/velvetk</id>
    <content type="html"><![CDATA[<p>VelvetKというスクリプトが公開されたらしい．これはVelvetのアセンブルの際にユーザが指定する必要のあるk-merのkの値を，ゲノムサイズとショートリードのサイズから自動推定するスクリプトのようだ．普通ならばkの値を細かく変えてVelvetを大量に走らせてアセンブル結果を評価するというのが定石だと思うが，もしkの値が自動推定できるなら，そのkの値付近だけを重点的に調べるといったことが出来るので大幅に労力を削減できる．私自身あまりVelvet/Oasesを使った経験が無いのだが，取り敢えず一通り使ってみた．</p>

<!-- more -->


<h2>インストール</h2>

<p>インストールは簡単で，Perlスクリプトを落としてくるだけで実行出来る．外部ライブラリの依存が無いのでお手軽．</p>

<p><code>
$ wget http://bioinformatics.net.au/velvetk.pl
</code></p>

<h2>使い方</h2>

<p>VelvetKでkの推定値を算出するには，</p>

<ul>
<li><strong>ゲノム配列</strong> または <strong>ゲノムサイズ</strong></li>
<li><strong>アセンブルの元になるショートリード</strong></li>
</ul>


<p>の2つの入力が必要になる．ゲノム配列が既知の場合には<code>--genome</code>オプションを使って，fasta形式のゲノム配列のファイルを指定する．ショートリードはfastq形式などのファイルを指定することになるが，gzやbz2などの圧縮形式にも対応している．ゲノム配列を指定してVelvetKを実行するには，以下のようにコマンドを実行する．</p>

<p><code>
$ perl velvetk.pl --genome chr.fasta R1.fastq R2.fastq
</code></p>

<p>一方でde novoのようなゲノム配列が無い場合には，対象種のおおまかなゲノムサイズを入力することになる．ゲノムサイズの指定の場合には，k/M/Gといった接頭辞を使う事ができる．ゲノムサイズを数値で指定してVelvetKを実行するには，以下のようにコマンドを実行する．</p>

<p><code>
$ perl velvetk.pl --size=1M chr.fasta R1.fastq R2.fastq
</code>
とする．</p>

<h2>擬似データで試してみる</h2>

<p>今回はお手製の擬似データで試してみることにする．</p>

<p>擬似データの作り方は簡単で，乱数を使って擬似的に作ったゲノム配列からこれまた乱数を使って擬似的にショートリードを作成するというもの．ゲノムの長さを1Mbとして，100bpのペアエンドの配列を500,000本用意して，カバレッジ100xくらいのゲノムシーケンスを想定した．</p>

<p>その擬似データセットで実行してみると以下のような出力が得られた．実際にはショートリードの長さや本数も不均一になるので，以下のように各値が綺麗な感じにはならないと思う．</p>

<p><code>
$ perl velvetk.pl --genome chr.fasta R1.fastq R2.fastq
Estimating target genome size from 'chr.fasta'
Target genome size is 1000000 bp
Desire k-mer coverage of 25
Using cat for R1.fastq
Read 500000 sequences from R1.fastq
Using cat for R2.fastq
Read 500000 sequences from R2.fastq
Considered 1000000 reads with lengths 100..100 bp
K       #Kmers  Kmer-Cov
1       100000000       100.0
3       98000000        98.0
5       96000000        96.0
7       94000000        94.0
9       92000000        92.0
〜〜〜中略〜〜〜
71      30000000        30.0
73      28000000        28.0
75      26000000        26.0
77      24000000        24.0
79      22000000        22.0
81      20000000        20.0
83      18000000        18.0
85      16000000        16.0
87      14000000        14.0
89      12000000        12.0
91      10000000        10.0
93      8000000 8.0
95      6000000 6.0
97      4000000 4.0
99      2000000 2.0
</code></p>

<p>入力ファイルをそれぞれ読み込んだ後，それぞれのkの値に対して#kmersとKmer-Covが表示される．#kmersはショートリードのデータからカウントできるk-merの本数で，例えばK=99の場合では100bpから抜き出せる99merは2つあるので，今回の場合リード数500,000*2の合計2,000,000という感じだろう．次のKmer-Covは，いわゆるK-mer Coverageと呼ばれるもので，実際のカバレッジとk-merで見た時のカバレッジの割合，もしくは変換するときの係数に当たる．</p>

<p>ではどうやってこのリストからVelvetに最適なkの値を推定するかというと，出力の始めの方に書かれている</p>

<p><code>
Desire k-mer coverage of 25
</code></p>

<p>のところを見て，Kmer-Covが25を下回った時のkの値が最適なkの値とする．今回の場合だとk=77でKmer-Covが24.0になるので，k=77が最適なk-merのサイズとなる．</p>

<p>それではなぜ25なのかというと，このスクリプトの場合だとデフォルトだからということになってしまうのだが，どうやらk-mer Coverageにはだいたい10~20あれば十分という知見(多分経験則)があるらしい．一般的にはkの値が小さいとコンティグが繋がりにくく，kの値が大きいと細かな違いをコンティグに反映出来無いといったsensitivityとspecificityのトレードオフがある．それらのいい具合の中間点ということで，k-mer Coverageを見て判断しようということらしい．</p>

<p>また，このスクリプトでは閾値となるk-mer Coverageを変更するオプション<code>--cov</code>や，リストの出力を抜きにして最適なKの値だけを出力するオプション<code>--best</code>なども用意されている．</p>

<p>```
$ perl velvetk.pl --best --cov=20 --size=1M R1.fastq R2.fastq
Target genome size is 1000000 bp
Desire k-mer coverage of 20
Using cat for R1.fastq
Read 500000 sequences from R1.fastq
Using cat for R2.fastq
Read 500000 sequences from R2.fastq
Considered 1000000 reads with lengths 100..100 bp
81</p>

<p>```
 上の場合では，k=81が最適とおもわれるkの推定結果となる．</p>

<h2>実はWeb版もある</h2>

<p>ちなみに，ここまで書いておいて難だが，実はVelvetKと同作者が作った簡易版「Velvet Advisor」がWebアプリケーションとして既に存在している．ただ，この簡易版は複数の入力ファイルに対応していないので，使えるケースが制限されている．普通は複数のライブラリを読んでアセンブルするとと思うので，まあ今回のVelvetKで使いやすくなったという感じだろうか．</p>

<p><a href="http://dna.med.monash.edu.au/~torsten/velvet_advisor/">http://dna.med.monash.edu.au/~torsten/velvet_advisor/</a></p>

<h2>まとめ</h2>

<p>今回は擬似データを使ってVelvetKを動かしてみたが，これからアセンブルをするという人にとってはパラメータの大雑把な目安となって良いと思う．どれだけの精度で当たるのか不安なところもあるので，実際にVelvetを使ったアセンブルのプロジェクトでVelvetKの推定値がどれだけ当たっているかが知りたいところだけれども，結局目安としてしか使わないのだから，まあ適当でいいんだろう．</p>

<h2>参考資料</h2>

<ul>
<li><a href="http://bioinformatics.net.au/software.velvetk.shtml">http://bioinformatics.net.au/software.velvetk.shtml</a></li>
<li><a href="http://kevin-gattaca.blogspot.jp/2012/06/fwd-velvet-users-velvetkpl-choose-good.html">http://kevin-gattaca.blogspot.jp/2012/06/fwd-velvet-users-velvetkpl-choose-good.html</a></li>
<li><a href="http://dna.med.monash.edu.au/~torsten/velvet_advisor/">http://dna.med.monash.edu.au/~torsten/velvet_advisor/</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ALLPATHS-LGを最小構成で実行する]]></title>
    <link href="http://yagays.github.io/blog/2012/06/04/allpaths-lg-introduction/"/>
    <updated>2012-06-04T13:08:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/06/04/allpaths-lg-introduction</id>
    <content type="html"><![CDATA[<p><a href="http://yagays.github.com/blog/2012/06/02/allpaths-lg-dataset/">前回</a>は，ALLPATHS-LGの入力データの制約についてFragment LibraryとJumping Libraryの2つが最低でも必要ということを書いたが，今回は実際にALLPATHS-LGを動かすところを見ていく．ただし，複雑で込み入った細かい部分は分からないので，最小構成でとにかくアセンブル結果を得るということだけを解説していこうと思う．</p>

<!-- more -->


<p>今回はALLPATHS-LGのexampleを使って解説していく．このexampleにはprepare.shとassemble.shという2つのシェル・スクリプトが付属しており，これらを動かせばアセンブルは実行できるのだが，今回は最小構成で実行するということで，これらの用意されたスクリプトを使わず直にコマンドを叩いて動かしていこうと思う．ALLPATHS-LGパイプラインの特徴である美しいディレクトリ構成などは一切無視して進むので，もし上手に実験を組んでディレクトリ構成を管理したい場合はマニュアルを熟読していただきたい．</p>

<h3>概要</h3>

<p>まず，ALLPATHS-LGを動かすために必要なステップが3つある．</p>

<ol>
<li><strong>in_groups.csvとin_libs.csvを作る</strong></li>
<li><strong>PrepareAllPathsInputs.plを実行する</strong></li>
<li><strong>RunAllPathsLGを実行する</strong></li>
</ol>


<p>最低限この3つを実行すれば，アセンブル結果が出てくる．では個別に見てこう．</p>

<h3>in_groups.csvとin_libs.csvを作る</h3>

<p>ALLPATHS-LGでは，入力となるNGSデータの情報をin_groups.csvとin_libs.csvの2つに記述する必要がある．</p>

<p>in_groups.csvでは，アセンブルの元データとなるNGS入力データの場所と種類，そしてライブラリの名前をコンマ区切りのテキストとして保存する．exampleのin_groups.csvは以下のようになっている．</p>

<p>```
$ cat in_groups.csv</p>

<pre><code>    file_name, library_name, group_name
</code></pre>

<p>seq/frags.?.fastq, Solexa-25396,      frags
seq/jumps.?.fastq, Solexa-11542,      jumps
```</p>

<p>file_nameは入力データのパスを指定する．相対パスでも絶対パスでも問題ない．入力ファイルがペアエンドなどで対になっている場合は<strong><code>?</code></strong>や<strong><code>*</code></strong>のワイルドカードを使う必要があり，例えばR1.fastqとR2.fastqなら"R?.fastq"とすれば2つのファイルをひとまとまりとして認識できる．次にlibrary_nameとgroup_nameだが，これらは入力データを区別するためにユーザが指定する項目で，自由に名前を付けることができる．library_nameは後述のin_libs.csvでも共通して使われるので，そちらの配列情報の項目と名前を合わせる必要がある．また，group_nameはそれぞれの配列データにユニークな名前を付ける必要がある．上の例ではfragsとjumpsとなっているが，これはライブラリの種類を指定しているわけではなく，ただ名前を付けているだけなので勘違いしないように注意が必要である．</p>

<p>次に，in_libs.csvでは，アセンブルの元データとなるNGS入力データのライブラリの種類とインサートサイズなどの各情報をコンマ区切りのテキストとして保存する．exampleのin_libs.csvは以下のようになっている．</p>

<p><code>
$ cat in_libs.csv
library_name, project_name, organism_name,     type, paired, frag_size, frag_stddev, insert_size, insert_stddev, read_orientation, genomic_start, genomic_end
Solexa-25396,         test,   test.genome, fragment,      1,       180,          10,            ,              ,           inward,             0,           0
Solexa-11542,         test,   test.genome,  jumping,      1,          ,            ,        3000,           500,          outward,             0,           0
</code>
まず一番左のカラムには，先ほどのin_groups.csvで指定したlibrary_nameと同じものを入力する．そして，それ以降の行で詳しいライブラリの情報を指定していく．project_nameやorganism_nameなどはユーザが自由に名前を付ける事ができる．それ以降のtypeやpaired，frag_sizeなどではライブラリの情報を入力していくが，関係ない項目は空白にしておいて良い．このあたりの入力情報の詳細はマニュアルに詳しく記載されているので，そちらを参照されたい．</p>

<p>さて，in_groups.csvとin_libs.csvが揃ったところで，次からいよいよALLPATHS-LGを動かしていく．</p>

<h3>PrepareAllPathsInputs.plを実行する</h3>

<p>さて，ここから実際にALLPATHS-LGを動かしていくわけだが，まずはPrepareAllPathsInputs.plというスクリプトを動かして，パイプラインのディレクトリ作成や入力データの変換などを行う．</p>

<p>それでは実際にPrepareAllPathsInputs.plを動かしてみよう．先ほどのin_groups.csvとin_libs.csvがあるディレクトリで，以下のコマンドを実行する．</p>

<p><code>
PrepareAllPathsInputs.pl DATA_DIR=$PWD PLOIDY=2  
</code></p>

<p>最低限必要なのはDATA_DIRとPLOIDYの2つだけである．DATA_DIRはアセンブル結果を保存するディレクトリを指定するオプションで，今回は最小構成ということで，このスクリプトを動かしたディレクトリ以下に結果を置くようにする．PLOIDYではゲノムアセンブリの対象種における倍数を指定する．1倍体なら1，2倍体なら2という具合だが，現在のところALLPATHS-LGは2倍体以上の倍数体には対応していないようだ．なお，マニュアルには他にもオプションが指定されているが，PICARD_TOOLS_DIRは入力ファイルがbamファイルでなければ必要ない．</p>

<h3>RunAllPathsLGを実行する</h3>

<p>入念な下準備が終わったところで，いよいよALLPATHS-LGの本体を動かす．まずは実行コマンドを見てみよう．</p>

<p><code>
RunAllPathsLG PRE=. REFERENCE_NAME=. DATA_SUBDIR=. RUN=allpaths SUBDIR=run  
</code></p>

<p>色々とオプションが指定されているが，これらは全てディレクトリに関するものである．PREやREFERENCE_NAME，DATA_SUBDIRで指定されているドットは「現在のディレクトリ」を表している．RUNやSUBDIRは出力結果のが置かれるディレクトリの名前になり，上のコマンドの場合には，final.assembly.fastaなどのアセンブル結果はallpaths/ASSEMBLIES/runのディレクトリ以下に置かれることになる．マニュアルではTARGETSというオプションがあるが，これは既にゲノムが読まれていたりする場合に，それをリファレンスとして使うことでALLPATHS-LGのアセンブル結果と比較してまとめて評価してくれるというものである．今回は使用していないので関係無いが，exampleではリファレンスゲノムもきちんと用意されているので，試すことはできる．</p>

<h3>まとめ</h3>

<p>ということで，足早にALLPATHS-LGの使い方を最小構成で見てきた．こうやって並べてみると，実際にアセンブルに必要な項目というのは非常に少なく，in_groups.csvとin_libs.csv，そしてPLOIDYさえ指定すればアセンブルすることはできる事がわかる．まあ実際に動かすとアセンブルが上手くいかない部分は多々出てくると思うが，最小構成で一度実行できてさえいれば次からはパラメータチューニングをしていくだけなので，アセンブル結果の評価と並行して進めることができる．ALLPATHS-LGでは他にも様々な種やデータに対応できるよう色々とオプションが用意されているので，色々試してみると面白かもしれない．</p>

<h3>参考サイト</h3>

<ul>
<li><a href="http://www.broadinstitute.org/software/allpaths-lg/blog/">http://www.broadinstitute.org/software/allpaths-lg/blog/</a></li>
<li><a href="http://evomics.org/wp-content/uploads/2012/01/Allpaths_exercises.pdf">http://evomics.org/wp-content/uploads/2012/01/Allpaths_exercises.pdf</a></li>
<li><a href="http://evomics.org/learning/assembly-and-alignment/allpaths-lg/">http://evomics.org/learning/assembly-and-alignment/allpaths-lg/</a></li>
<li>(pdf) <a href="http://evomics.org/wp-content/uploads/2012/01/Allpaths_exercises.pdf">http://evomics.org/wp-content/uploads/2012/01/Allpaths_exercises.pdf</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
