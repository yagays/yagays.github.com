<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MachineLearning | Wolfeyes Bioinformatics beta]]></title>
  <link href="http://yagays.github.io/blog/categories/machinelearning/atom.xml" rel="self"/>
  <link href="http://yagays.github.io/"/>
  <updated>2014-08-18T21:20:30+09:00</updated>
  <id>http://yagays.github.io/</id>
  <author>
    <name><![CDATA[yag_ays]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MLAC2013 数式を使わずイメージで理解するEMアルゴリズム]]></title>
    <link href="http://yagays.github.io/blog/2013/12/15/mlac-2013-em-algorithm/"/>
    <updated>2013-12-15T19:16:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/12/15/mlac-2013-em-algorithm</id>
    <content type="html"><![CDATA[<h3>はじめに</h3>

<p><a href="http://qiita.com/advent-calendar/2013/machinelearning">Machine Learning Advent Calendar 2013</a>の15日目を担当する<a href="https://twitter.com/yag_ays">@yag_ays</a>です．専門はバイオインフォマティクスという計算機を使って生物学をする分野で，生モノではなく遺伝子の文字列相手に格闘している大学院生です．今回は初心者の人を対象に，なるべく数式を使わずにEMアルゴリズムについて解説してみたいと思います．</p>

<p>EMアルゴリズムは，SVMやニューラルネットワークといった華々しい機械学習の手法の一つではなく，機械学習の中で使われる尤度最大化という一部分を担当するアルゴリズムです．そのため多くの人にとってEMアルゴリズムは，それ単体を使ってみたりだとか独自に改良をしたりするような対象ではないでしょう．でも，EMアルゴリズムなんて仰々しい名前が付けられているだけあって，いざ自分の仕事に組み込む場合には中身を理解していないと「なぜEMアルゴリズムを使ったの？」であったり「それを使うと何が嬉しいの？」といった質問が来たときに困るし，とりあえず概念だけでも一通り理解しておきたいと思う人もいると思います．そこで今回は，大雑把にEMアルゴリズムを理解することを目的に，細かい定義やら数式は抜きにしてイメージで覚えられるような解説を書いてみました．まあ結局PRMLの受け売りなのですが，紙の上で見るよりかは分かりやすくしたと思うので勘弁してください．</p>

<ul>
<li><strong>この記事の対象となる人</strong>

<ul>
<li>EMアルゴリズムについて聞いたことはあるけどよく分かっていない人</li>
<li>例えば「これEMアルゴリズム使ってるけど，局所解に落ちてるんじゃない」って言われたとして，？？？ってなる人</li>
</ul>
</li>
<li><strong>この記事の対象ではない人</strong>

<ul>
<li>「パターン認識と機械学習」(PRML)下巻9章を読み通した人</li>
<li>イメージと聞いて情報幾何の話だと思った人</li>
</ul>
</li>
</ul>


<h3>EMアルゴリズムとは</h3>

<p>EMアルゴリズムは，潜在変数が存在する時の尤度関数を最大化するアルゴリズムです．機械学習の文脈では，よく混合ガウス分布（GMM）などの潜在変数を用いたモデリングの際に用いられます．PRMLで言うところの下巻9章「混合モデルとEM」ですね．また，今回のMLAC 2013では<a href="https://github.com/masakazu-ishihata/advent2013">m_ishihataさんの記事</a>でも出てきますので，何に使うのかピンと来ない人はそちらも参照してもらえればと思います．</p>

<p>ここで覚えておいて欲しいのは，<strong>尤度関数を最大化する</strong>ということです．確率的な機械学習の手法を使っていると，ときどき尤度関数というものが出てきます．特にEMアルゴリズムのような潜在変数が存在する時には，尤度関数は数式には書くことができても，実際にそれがどういう形をしていてどの値で最大になるのかといったことは全く予想ができません．尤度関数に適当に数字を入れれば値が帰ってきますが，それをパラメータすべてについて計算することは現実的には不可能です．そういった条件でどうにか上手いこと計算して効率よく最大値を求めたいといったときに，EMアルゴリズムは使われます．</p>

<h3>イメージで理解するEMアルゴリズム</h3>

<p>前置きはこのくらいにして，では実際にEMアルゴリズムが何をしているのかをスライドで見てもらいましょう．なお，これはあくまでイメージですので，実際にはデータ数に依存する高次元の空間ですし，EMアルゴリズムの計算途中で対数尤度関数がこのように図示できるわけでもありません．その点は注意してください．なお，以下の解説はPRML下巻9章の図9.14 (P.169)を参考にしています．</p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/29219489" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>


<p>さて，PRMLの図を動かしてみたという感じですが，どうだったでしょうか？途中に少し記号を書いてしまいましたが，あまり気にしないでください．EMアルゴリズムの各ステップを更新していくことで，対数尤度の山を徐々に登っていく様子が何となくつかめたと思います．初期値<script type="math/tex">\theta</script>だったパラメータも，<script type="math/tex">\theta'</script>，<script type="math/tex">\theta''</script>と更新されて，尤度関数を最大化するパラメータが求められたことがわかります．</p>

<h3>EMアルゴリズムにおける下界</h3>

<p>とは言うものの，下界って何だとかどうやって計算するんだとか色々あやふやなところがあるので，その辺を少し補足しておきましょう．下界（Lower Bound）とは，その名の通り対数尤度がここよりも小さくならないということを表しています．EMアルゴリズムでは，この下界というものを使ってだんだん底上げしていくことで対数尤度を増加させていくという感じです．Eステップでパラメータを固定したときの下界というものを求めて，Mステップで潜在変数の分布を固定したときの下界と対数尤度の値が同じになるように下界を押し上げます．あとはこれの繰り返しになるのですが，必ず下界よりも対数尤度は上にあるので，決して対数尤度が小さくはなりません．こうやってEMアルゴリズムは対数尤度を最大化していきます．</p>

<p>下界の求め方も今回は数式を使わずに説明するということで，対数尤度式からアレコレ計算すると出てくる程度に捉えておいてもらえればと思います．例えば混合ガウス分布にEMアルゴリズムを適用する場合だと，Jensenの不等式を使って数式の変形することにより下界は求めることができます．下界と対数尤度の差が実はKLダイバージェンスになっているという話もあるのですが，潜在変数の分布について話してないのでここでは割愛します．詳しくはPRMLの数式を追ってみてください．</p>

<h3>イメージで分かるEMアルゴリズムの性質</h3>

<p>ここからは，EMアルゴリズムで注意しなければいけない点を解説します．先ほど紹介したイメージを持っていれば，数式を使わずともEMアルゴリズムの持つ問題点を指摘できるはずです．</p>

<h4>各ステップを繰り返す必要がある</h4>

<p>当然ですが，EMアルゴリズムはEステップとMステップを繰り返す必要があります．EMアルゴリズムが適用できる問題ならば各ステップの計算自体は簡単ですが，パラメータや対数尤度値がある程度収束するまでは，計算し続けなければいけません．</p>

<h4>初期値に依存し，局所最適解に落ちることもある</h4>

<p>先ほど示したイメージでは，下界を引き上げていく際に二次関数のようなものの頂点と対数尤度関数を行ったり来たりしていました．ということは，きちんと勾配にしたがって最大化してくれるという保証がある一方で，それらがある程度一致したところでパラメータは更新しようがないということになります．そのため，EMアルゴリズムは初期値によっては局所最適解に落ちる可能性があります．</p>

<h3>まとめ</h3>

<p>いかがだったでしょうか？この記事で少しでもEMアルゴリズムのイメージがつかめてもらえれば幸いです．そうすれば，PRMLなどの数式の出てくる参考書を読んでも，EMアルゴリズムというものが一体何がしたいのかといったことが理解しやすくなるんじゃないかと思います．</p>

<p>少し個人的な話になりますが，私自身はこうやって模式図やイメージを実際に頭のなかで組み立てると，とても理解が捗ります．私が機械学習の勉強をするときにこういうことを意識しはじめたのは，PRML復々習レーンで第3章の線形回帰モデルの冒頭を発表したときでした．そのときには3.1.2の「最小二乗法の幾何学」という項が一体何を言っているのか全く分からず，発表の際に堂々と「分かりませんでした！」と言ったことをよく覚えています．その時に発表の際に参加者の皆さんに教えていただいたおかげで，最小二乗法の理解が一気に深まったように思えました．よくわからない数式の最小化という漠然とした状態から，数式の各項が何を表していて，何を最小化するのかということまで具体的に理解できたのはこのときでした．こういった感覚はPRMLを読むうちに何度もあり，自分の中できちんと理解に落としこむことの重要性を実感しています．今回の記事では，その一つとしてEMアルゴリズムをイメージでつかんでもらえるような紹介の仕方をしてみました．勿論のことながら，自分で自由自在に使いこなすくらい理解するにはきちんと数式を追わなければいけないですし，図式としてイメージできないことも多々あります．しかしながら，どんな難しいアルゴリズムや手法でも，やってることは絵にかけるほど単純なのだというリラックスした感覚で臨めば，意外と理解につながるものだと思います．機械学習の勉強で壁にぶち当たったときは，ぜひ図を書いたり具体的な絵にして考えなおしてみると上手くいくかもしれません．</p>

<h4>参考</h4>

<ul>
<li><a href="http://qiita.com/advent-calendar/2013/machinelearning">Machine Learning Advent Calendar 2013 - Qiita [キータ]</a></li>
</ul>


<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4621061224" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>


<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4621061240" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pythonで遺伝的アルゴリズムを動かすPyevolveを試してみた]]></title>
    <link href="http://yagays.github.io/blog/2013/12/01/pyevolve-genetic-algorithm/"/>
    <updated>2013-12-01T09:00:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/12/01/pyevolve-genetic-algorithm</id>
    <content type="html"><![CDATA[<p>課題のために遺伝的アルゴリズムを使う必要があったので，Pythonで遺伝的アルゴリズムを動かすことのできるライブラリPyevolveを試してみた．</p>

<h3>始めの一歩</h3>

<p>動かし方はとてもシンプルなので，公式ドキュメントのGet Startedをざっと見たあとにExampleでどういう使い方ができるのかを個別に見ていけばいいと思う．</p>

<ul>
<li><a href="http://pyevolve.sourceforge.net/getstarted.html">Get Started - Tutorial — Pyevolve v0.5 documentation</a></li>
<li><a href="http://pyevolve.sourceforge.net/examples.html">Examples — Pyevolve v0.5 documentation</a></li>
</ul>


<p>日本語資料なら，自分が確認した限りでは以下のサイトが一番詳しい．</p>

<ul>
<li><a href="http://d.hatena.ne.jp/mFumi/20100917/1284724566">Pyevolveで学ぶ遺伝的アルゴリズム - mfumiの日記</a></li>
</ul>


<h3>Pyevolveの基本的な使い方</h3>

<h4>ゲノムインスタンスの生成</h4>

<p>ゲノムの構造はバイナリや1次元配列，2次元配列，木構造などを取ることができ，初期値が取りうる値の幅なども決めることができる．以下のコードでは，値が15個あって最小値0，最大値100というゲノムを作成している．</p>

<p><code>python
genome = G1DList.G1DList(15)
genome.setParams(rangemin=0, rangemax=100)
</code></p>

<h4>ゲノムの初期化，突然変異の設定</h4>

<p>次に，ゲノムインスタンスを初期化して突然変異の分布などを指定する．最初に指定したゲノムの構造に従って指定する必要があるが，パラメータはだいたい読んだ通り．</p>

<p><code>python
genome.initializator.set(Initializators.G1DListInitializatorReal)
genome.mutator.set(Mutators.G1DListMutatorRealGaussian)
</code></p>

<p>値が整数の場合は"G1DListInitializatorInteger"や"G1DListMutatorIntegerGaussian"が用意されている．</p>

<ul>
<li><a href="http://pyevolve.sourceforge.net/module_mutators.html">Mutators – mutation methods module — Pyevolve v0.5 documentation</a></li>
</ul>


<h4>評価関数をセット</h4>

<p>評価関数eval_funcを作って，ゲノムインスタンスに指定する．</p>

<p>```python
def eval_func(chromosome):</p>

<p>[...]
```</p>

<p><code>python
genome.evaluator.set(eval_func)
</code></p>

<h4>GA Engineを作成する</h4>

<p><code>python
ga = GSimpleGA.GSimpleGA(genome)
</code></p>

<h4>選択方式などのパラメータを指定する</h4>

<p>デフォルトでGA Engineを動かした場合，世代数や集団数は以下のようになる．</p>

<ul>
<li>100 世代</li>
<li>集団サイズ：80個体</li>
<li>ランキング選択</li>
</ul>


<p>これらを変更するには，以下のようにパラメータをセットする．</p>

<p><code>python
ga.selector.set(Selectors.GRouletteWheel)
ga.setGenerations(5000)
ga.setMutationRate(0.1)
ga.setPopulationSize(100)
</code></p>

<p>選択方法は，その他にもランキング方式やトーナメント方式などが用意されている．</p>

<ul>
<li><a href="http://pyevolve.sourceforge.net/module_selectors.html">Selectors – selection methods module — Pyevolve v0.5 documentation</a></li>
</ul>


<h4>GA Engineの実行</h4>

<p><code>python
ga.evolve(freq_stats=250)
</code></p>

<p>実行中はfreq_statsで指定した世代ごとに以下のようなログが出力される．</p>

<p><code>
Gen. 1 (0.02%): Max/Min/Avg Fitness(Raw) [23104.07(27490.00)/15107.82(10386.00)/19253.39(19253.39)]
Gen. 250 (5.00%): Max/Min/Avg Fitness(Raw) [9486.89(15212.00)/6883.91(3184.00)/7905.74(7905.74)]
Gen. 500 (10.00%): Max/Min/Avg Fitness(Raw) [8749.57(15233.00)/6518.94(3085.00)/7291.31(7291.31)]
Gen. 750 (15.00%): Max/Min/Avg Fitness(Raw) [8259.84(14274.00)/6173.50(3073.00)/6883.20(6883.20)]
[…]
</code></p>

<br/>


<h3>pyevolve_graph.pyの使い方</h3>

<p>Pyevolveには，イテレーションの変化を可視化する便利なスクリプトがある．</p>

<ul>
<li><a href="http://pyevolve.sourceforge.net/graphs.html">Graphical Analysis - Plots — Pyevolve v0.5 documentation</a></li>
</ul>


<h4>1. DBAdaptersをインポートする</h4>

<p><code>python
from pyevolve import DBAdapters
</code></p>

<h4>2. 以下のスクリプトを追記する</h4>

<p>挿入する場所はGSimpleGA.GSimpleGA() のすぐ後．</p>

<p><code>python
ga = GSimpleGA.GSimpleGA(genome)
sqlite_adapter = DBAdapters.DBSQLite(identify="ex1")
ga.setDBAdapter(sqlite_adapter)
</code></p>

<p>これで，GAの実行後にpyevolve.dbというファイルが作成される．</p>

<h4>3. pyevolve_graph.pyを実行する</h4>

<p>あとはpyevolve_graph.pyを実行する．可視化するグラフのタイプなどが選べるようになっているので，その辺りのパラメータは<a href="http://pyevolve.sourceforge.net/graphs.html">マニュアル</a>を参考．</p>

<p>例えば，以下のようなグラフを出力することができる．</p>

<p><code>
$ pyevolve_graph.py -i ex1 -3 -g 1:500 -o pyevolve_graph
</code></p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/pyevolve_graph.png" alt="" /></p>

<h3>最後に：Pythonで遺伝的アルゴリズムをするなら</h3>

<p>最後に残念なお知らせだが，Pyevolveは少なくとも2年前から開発が止まっている．Pyevolve安定版0.5で公式に対応しているPythonのVersionも2.6となっている（2.7では動いた．3.x系は不明）．</p>

<ul>
<li><a href="https://github.com/perone/Pyevolve">perone/Pyevolve</a></li>
<li><a href="https://pypi.python.org/pypi/Pyevolve">Pyevolve 0.5 : Python Package Index</a></li>
</ul>


<p>どうやら現在ではDEAPというライブラリが精力的に開発されているようだ．まだオンラインの資料は少ないものの，3.x系などの対応を考えるならこちらを使うのも手だろう．</p>

<ul>
<li><a href="http://stackoverflow.com/questions/16739118/genetic-algorithms-and-multi-objectives-optimization-on-python-libraries-tools">Genetic Algorithms and multi-objectives optimization on PYTHON : libraries/tools to use? - Stack Overflow</a></li>
<li><a href="https://code.google.com/p/deap/">deap - Distributed Evolutionary Algorithms in Python - Google Project Hosting</a></li>
</ul>


<p>もし遺伝的アルゴリズムをPythonを使って自分で実装したい場合は，<a href="http://www.amazon.co.jp/gp/product/4873113644/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=4873113644&linkCode=as2&tag=yagays-22">集合知プログラミング</a><img src="http://ir-jp.amazon-adsystem.com/e/ir?t=yagays-22&l=as2&o=9&a=4873113644" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />11章「進化する知性」がお薦めできる．基本的なアルゴリズムに加えて，交叉や突然変異の書き方であったり様々なデータタイプに対応したりと，実装も丁寧に解説されている．</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4873113644" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>


<h3>動作環境</h3>

<ul>
<li>Mac OS X 10.8.5</li>
<li>Python 2.7.6</li>
<li>Pyevolve 0.5</li>
</ul>


<h3>参考</h3>

<ul>
<li><a href="http://pyevolve.sourceforge.net/index.html">Welcome to Pyevolve documentation ! — Pyevolve v0.5 documentation</a></li>
<li><a href="http://pyevolve.sourceforge.net/0_6rc1/index.html">Welcome to Pyevolve documentation ! — Pyevolve v0.6rc1 documentation</a></li>
<li><a href="http://d.hatena.ne.jp/mFumi/20100917/1284724566">Pyevolveで学ぶ遺伝的アルゴリズム - mfumiの日記</a></li>
<li><a href="http://d.hatena.ne.jp/gepuro/20120102/1325515592">pyevolveの使い方メモ - gepuroの日記</a></li>
<li><a href="http://d.hatena.ne.jp/pashango_p/20090601/1243850103">pyevolveによる遺伝的アルゴリズム(1) - Pashango’s Blog</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[matplotlibで混合ガウス分布の確率密度関数をプロットする]]></title>
    <link href="http://yagays.github.io/blog/2013/10/20/gmm-matplotlib/"/>
    <updated>2013-10-20T11:22:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/10/20/gmm-matplotlib</id>
    <content type="html"><![CDATA[<p>PythonとNumpy/Scipyの練習．前回は<a href="http://yagays.github.io/blog/2013/10/18/gmm-em-numpy/">Numpyを使って混合ガウス分布のEMアルゴリズムを実装</a>で混合ガウス分布について取り扱ったので，今回は混合ガウス分布についての数式をおさらいしつつ，確率密度関数をプロットしようと思う．</p>

<h3>混合ガウス分布の概要</h3>

<p>混合ガウス分布は，複数のガウス分布の線形結合で表すことができる．</p>

<p>![p(\bold{x})=\sum_{k=1}<sup>{K}\pi_k\mathcal{N}(\bold{x}|\bold{\mu}<em>k,\bold{\Sigma}</em>k)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=p%28%5Cbold%7Bx%7D%29%3D%5Csum_%7Bk%3D1%7D%3Csup%3E%7BK%7D%5Cpi_k%5Cmathcal%7BN%7D%28%5Cbold%7Bx%7D%7C%5Cbold%7B%5Cmu%7D%3Cem%3Ek%2C%5Cbold%7B%5CSigma%7D%3C%2Fem%3Ek%29%3C%2Fsup%3E+)</p>

<p>ここで，![\pi_k](http://chart.apis.google.com/chart?cht=tx&chl=%5Cpi_k)を混合係数，![\mathcal{N}(\bold{x}|\bold{\mu}<em>k,\bold{\Sigma}</em>k)](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BN%7D%28%5Cbold%7Bx%7D%7C%5Cbold%7B%5Cmu%7D%3Cem%3Ek%2C%5Cbold%7B%5CSigma%7D%3C%2Fem%3Ek%29)を混合要素と呼ぶ．混合系数は確率の条件![\sum_{k=1}<sup>{K}\pi_k</sup> = 1 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Csum_%7Bk%3D1%7D%3Csup%3E%7BK%7D%5Cpi_k%3C%2Fsup%3E+%3D+1+)および![0 \le \pi_k &lt; 1 ](http://chart.apis.google.com/chart?cht=tx&chl=0+%5Cle+%5Cpi_k+%26lt%3B+1+)を満たす．</p>

<p>また，混合要素![\pi_k = p(k)](http://chart.apis.google.com/chart?cht=tx&chl=%5Cpi_k+%3D+p%28k%29)を![k](http://chart.apis.google.com/chart?cht=tx&chl=k)番目の混合要素が選ばれる事前確率とし，![\mathcal{N}(\bold{x}|\bold{\mu}<em>k,\bold{\Sigma}</em>k) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BN%7D%28%5Cbold%7Bx%7D%7C%5Cbold%7B%5Cmu%7D%3Cem%3Ek%2C%5Cbold%7B%5CSigma%7D%3C%2Fem%3Ek%29+)を![k](http://chart.apis.google.com/chart?cht=tx&chl=k)が与えられた時の![x ](http://chart.apis.google.com/chart?cht=tx&chl=x+)の条件付き密度とすると，![x ](http://chart.apis.google.com/chart?cht=tx&chl=x+)の周辺分布は</p>

<p>![p(\bold{x})=\sum_{k=1}<sup>{K}p(k)p(\bold{x}|k)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=p%28%5Cbold%7Bx%7D%29%3D%5Csum_%7Bk%3D1%7D%3Csup%3E%7BK%7Dp%28k%29p%28%5Cbold%7Bx%7D%7Ck%29%3C%2Fsup%3E+)</p>

<p>で表すことができる．この![k ](http://chart.apis.google.com/chart?cht=tx&chl=k+)の選択が，EMを用いたGMMでの隠れ変数に対応している．</p>

<h4>一次元の混合ガウス分布</h4>

<p>```python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.mlab as mlab</p>

<p>x = np.linspace(-5, 5,200)
pi_k = np.array([0.3,0.7])
norm1 = mlab.normpdf(x, -1, 1)
norm2 = mlab.normpdf(x, 2, 1)</p>

<p>plt.plot(x,pi_k[0]<em>norm1,color="blue")
plt.plot(x,pi_k[1]</em>norm2,color="blue")
plt.plot(x,pi_k[0]<em>norm1+pi_k[1]</em>norm2, color="red")
plt.show()
```</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/gmm_1.png" alt="gmm_1.png" /></p>

<p>今回は正規分布の確率密度関数にmatplotlibのmlab.normpdfを使ったが，scipy.statsのnorm.pdfを使うこともできる．</p>

<p><code>python
import numpy as np
rom scipy import stats
norm1 = stats.norm.pdf(x, loc=-1, scale=1)
norm2 = stats.norm.pdf(x, loc=2, scale=1)
</code></p>

<h3>二次元の混合ガウス分布</h3>

<p>```python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.mlab as mlab</p>

<p>pi_k = np.array([0.3,0.7])
x = np.linspace(-3.0, 3.0,200)
y = np.linspace(-2.0, 2.0,200)
X, Y = np.meshgrid(x, y)
Z1 = mlab.bivariate_normal(X, Y, 0.5, 1.0, -1, -1)
Z2 = mlab.bivariate_normal(X, Y, 1.0, 1.0, 1, 1)
Z = pi/k[0]<em>Z1 + pi_k[1]</em>Z2</p>

<p>CS = plt.contour(X, Y, Z)
plt.clabel(CS, inline=1, fontsize=10)
plt.show()
```</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/gmm_2.png" alt="gmm_2.png" /></p>

<h4>参考</h4>

<ul>
<li><a href="http://d.hatena.ne.jp/y_n_c/20091122/1258904025">matplotlibで等高線やら何やらのプロット - たこ焼き食べた.net</a></li>
<li><a href="http://w.livedoor.jp/met-python/d/matplotlib/plot">matplotlib/plot - memoring - Seesaa Wiki（ウィキ）</a></li>
<li><a href="http://d.hatena.ne.jp/teramonagi/20120930/1348982608">レプリカ交換モンテカルロ法（パラレル・テンパリング）による混合ガウス分布に従う乱数の生成 - My Life as a Mock Quant</a></li>
<li><a href="http://oneau.wordpress.com/2011/02/28/simple-statistics-with-scipy/">Simple statistics with SciPy | Comfort at 1 AU</a></li>
<li><a href="http://matplotlib.org/examples/pylab_examples/contour_demo.html">pylab_examples example code: contour_demo.py — Matplotlib 1.3.1 documentation</a></li>
<li><a href="http://matplotlib.org/api/mlab_api.html">mlab — Matplotlib 1.3.1 documentation</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Numpyを使って混合ガウス分布のEMアルゴリズムを実装]]></title>
    <link href="http://yagays.github.io/blog/2013/10/18/gmm-em-numpy/"/>
    <updated>2013-10-18T13:21:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/10/18/gmm-em-numpy</id>
    <content type="html"><![CDATA[<p>Pythonの練習ということで，Numpyを使って混合ガウス分布のEMアルゴリズムによる最尤推定を実装してみた．そもそもPythonを書いた経験があまり無いうえに，全く知らないNumpyを使って行列演算や確率計算をしようということで，手探りでかなり苦戦してしまったが，何とか形にはなったと思う．ということで，次の勉強に活かすためにもここでコードを振り返ってみる．</p>

<p><strong>注意：以下のコードはテストデータでしか確かめてないので多分どこかバグってる．あと確率値に対数を取ってないので，値が限りなく小さくなってゼロ除算になることがある．</strong></p>

<script src="https://gist.github.com/yagays/7036127.js"></script>


<h3>実装</h3>

<h4>とっかかり</h4>

<ul>
<li>まずscipyあたりで多変量正規分布が無いか探す

<ul>
<li>普通の正規分布scipy.stats.normはあるが多変量は無いっぽい</li>
<li>自分で関数を書く</li>
</ul>
</li>
<li>逆行列とか転置とか書き方が複数あって混乱する

<ul>
<li>今回はとりあえず動いたらいいので適当に使う</li>
<li>np.matrixとnp.arrayが混ざってるの良くないっぽい</li>
</ul>
</li>
</ul>


<h4>EMアルゴリズムの作り始め</h4>

<ul>
<li>Numpyの行列の表し方を一通り見る

<ul>
<li>Rっぽい</li>
<li>0 originか1 originかで混乱する</li>
</ul>
</li>
<li>更新するパラメータは基本的に入れ物となる変数を作っておいてそれに代入していく

<ul>
<li>最初はappendでリストに突っ込もうかと考えたけど，ndarrayとかになる場合もあるので面倒でやめた</li>
</ul>
</li>
<li>Numpyの簡潔な書き方がわからない

<ul>
<li>Rのapplyみたいに列指向で計算する方法がわからない</li>
<li>最初はリスト内包使ったりmap,zipつかったりしたけど，行列計算ぽく書けばそれなりに動くことに気付く</li>
<li>それでもだめならfor文で直感的に計算する</li>
</ul>
</li>
</ul>


<h4>終わりかけ</h4>

<ul>
<li>共分散行列の更新で意図した結果にならずにだいぶ悩む

<ul>
<li>とりあえず人のを真似て書いてみる</li>
</ul>
</li>
<li>対数尤度の収束規準をどうするかで悩む

<ul>
<li>今回は適当に更新したときの対数尤度の差を見るようにした</li>
<li>収束度合いの検出を改善するか，単調増加する対数尤度をプロットして適当なところで切るみたいなことをしたほうがいいかも</li>
</ul>
</li>
</ul>


<h4>一通り書き終えて</h4>

<ul>
<li>まずはNumpyのスタイルを一通り身につけないといけない

<ul>
<li>Numpyの流儀を学ぶ</li>
<li>パッケージや方法が混在しているので，書き方を統一することが必要</li>
</ul>
</li>
<li>実装の途中で数式の添字とかで混乱した

<ul>
<li>EMアルゴリズムの資料としてPRMLともう一つ別のスライドを参考にしたのが原因</li>
<li>実装前にしっかりと頭のなかを整理しとくことが必要</li>
</ul>
</li>
<li>全体的に対数尤度で計算する

<ul>
<li>いわゆるlogsumexpでアンダフローに対処する</li>
</ul>
</li>
</ul>


<h4>参考</h4>

<ul>
<li><a href="http://d.hatena.ne.jp/n_shuyo/20100304/em_algorithm">EM アルゴリズム実装(勉強用) - Mi manca qualche giovedi`?</a></li>
<li><a href="http://d.hatena.ne.jp/nishiohirokazu/20111109/1320829189">EMアルゴリズム答え合わせ - 西尾泰和のはてなダイアリー</a></li>
<li><a href="http://d.hatena.ne.jp/teramonagi/20120909/1347194703">EMアルゴリズムによる混合分布のパラメーター推定の解析計算＆実装例 from 「Rによるモンテカルロ法入門」 - My Life as a Mock Quant</a></li>
<li><a href="http://convexbrain.sourceforge.jp/cgi-bin/wifky.pl?p=EM%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">Intelligence Architecture けんきうノート - EMアルゴリズム</a></li>
</ul>


<h4>Numpy/Scipy資料まとめ</h4>

<p><strong>英語</strong></p>

<ul>
<li><a href="http://wiki.scipy.org/Cookbook">Cookbook -</a></li>
<li><a href="http://www.python-course.eu/numpy.php">Python Advanced: Introduction into NumPy</a></li>
<li><a href="http://mentat.za.net/numpy/numpy_advanced_slides/">NumPy MedKit</a></li>
<li><a href="http://pages.physics.cornell.edu/~myers/teaching/ComputationalMethods/python/arrays.html">scipy array tip sheet</a></li>
<li><a href="http://www.kevinsheppard.com/wiki/Python_for_Econometrics">Python for Econometrics - Kevin Sheppard</a></li>
</ul>


<p><strong>日本語</strong></p>

<ul>
<li><a href="http://ibisforest.org/index.php?python%2Fnumpy#ic069832">python/numpy - 機械学習の「朱鷺の杜Wiki」</a></li>
<li><a href="http://daemon.ice.uec.ac.jp/~shouno/2012.Programming/index.html">2012 年度プログラミング言語演習 Python — 2012.ProgramingLanguage 0.1 documentation</a></li>
<li><a href="http://www.slideshare.net/shuyo/numpy-9704562">数式をnumpyに落としこむコツ</a></li>
<li><a href="http://rest-term.com/archives/2999/">Pythonの数値計算ライブラリ NumPy入門 « Rest Term</a></li>
<li><a href="http://qiita.com/wellflat/items/284ecc4116208d155e01">Pythonの数値計算ライブラリ NumPy入門 - Qiita [キータ]</a></li>
<li><a href="http://www.slideshare.net/shima__shima/python-13349162">機械学習のPythonとの出会い（１）：単純ベイズ基礎編</a></li>
<li><a href="http://sucrose.hatenablog.com/entry/2013/05/25/133021">pythonの機械学習ライブラリscikit-learnの紹介 - 唯物是真 @Scaled_Wurm</a></li>
</ul>


<p><strong>書籍</strong></p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=1449305466" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>




<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=1449319793" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA["The Elements of Statistical Learning"のpdfの余白を削る]]></title>
    <link href="http://yagays.github.io/blog/2013/05/22/esl-pdf-trimming/"/>
    <updated>2013-05-22T09:22:00+09:00</updated>
    <id>http://yagays.github.io/blog/2013/05/22/esl-pdf-trimming</id>
    <content type="html"><![CDATA[<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=0387848576" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<p>機械学習系の教科書としてはそこそこの知名度のある「The Elements of Statistical Learning」（通称ESLまたはHastie）は，全ページのPDFが公式で配布されている．</p>

<p><a href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/">Elements of Statistical Learning: data mining, inference, and prediction. 2nd Edition.</a></p>

<p>これは輪講に使えそうだということで色々と準備をしているのだが，このpdfには一つ気になるところがあって，それはページの余白が大きいということだ．右上にトンボの一部と「Printer: Opaque this」という文字が書かれているように，おそらく印刷所に出す前のpdfをそのまま配布しているらしい．pdfが配布されているだけ有難いというものではあるものの，このままでは少し読みづらい．ということで，余白を良い感じに自動で削れるツールを探して，文字だけの部分を抜き出してみた．</p>

<h3>brissで余白をトリミングする</h3>

<p>今回は「briss」というJavaアプリケーションを使ってみる．</p>

<p><a href="http://appdrill.net/61580/briss.html">[Mac] 自炊に！PDFのページを重ねて一発で余白を切り取る「briss」 « Appdrill</a></p>

<p>使い方は上のリンクを参考にしていただくとして，pdfを読み込んだ画面が以下のようになる．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/briss1.png" alt="" /></p>

<p>これは1ページ目だけを除いた残りのページを全て重ねあわせたたもので，右ページ中央に表示されているグチャッとした部分がpdfのテキスト部分となる．水色の透過の部分がトリミング後に残る箇所を表しており，読み込んだ際に自動で設定される．左上と右下の四角をドラッグすると範囲を手動で選択できるが，下手にやると右ページと左ページでpdfサイズがズレることがあるので，今回のESLのpdfの場合は自動で設定されたものをそのまま使った方がいいだろう．</p>

<p>トリミングを実行して出力されたpdfを開くと，このような感じになる．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/briss2.png" alt="" /></p>

<p>今回の場合は本当に文字ぎりぎりという感じだが，iPadで眺めたり印刷する際にはちょうどくらいだ．これでストレス無くESLを読む事ができる．</p>
]]></content>
  </entry>
  
</feed>
