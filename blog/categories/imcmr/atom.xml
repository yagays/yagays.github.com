<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: imcmr | Wolfeyes Bioinformatics beta]]></title>
  <link href="http://yagays.github.io/blog/categories/imcmr/atom.xml" rel="self"/>
  <link href="http://yagays.github.io/"/>
  <updated>2013-12-10T20:49:00+09:00</updated>
  <id>http://yagays.github.io/</id>
  <author>
    <name><![CDATA[yag_ays]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[「Rによるモンテカルロ法入門」読書ノート：6章 メトロポリス・ヘイスティング・アルゴリズムを用いたモデル選択]]></title>
    <link href="http://yagays.github.io/blog/2012/12/11/imcmr-6-6/"/>
    <updated>2012-12-11T15:34:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/12/11/imcmr-6-6</id>
    <content type="html"><![CDATA[<ul>
<li>読書ノート アーカイブ：<a href="http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/">http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/</a></li>
</ul>


<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4621065270" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<h3>例 6.8 モデル選択</h3>

<h4>この問題の目的とデータセットの説明</h4>

<p>線形回帰のモデル選択について考える．data(swiss)はスイスの47地域における出生率と社会経済指標のデータである．社会経済指標には，農業従事率や教育の度合い，特定の宗教の割合，幼児の死亡率など，合計で5つの標準化された観測値が含まれている．今回は，線形回帰によって出生率と社会経済指標の関係を調べることを目標としている．つまり，社会経済指標の中で何が出生率に効いているかを知りたいということだ．そのような線形回帰において一番重要なのが，5つある説明変数をどうやって組み合わせてモデルを作るかという問題である．5つの説明変数から作ることの出来るモデルは2<sup>5</sup> 個なので，今回の場合のモデルの総数はたかだか32個程度だが，たとえば説明変数が20個になると，モデルの総数は2<sup>20</sup> = 1048576個となり，全部のモデルをそれぞれ計算するのは現実的ではなくなってしまう．そこで，モデルの全パターンを試すことなく，もっとも出生率に効いてる社会経済指標だけを選んでモデルを作りたい．そのために，今回は周辺分布の最大化によるモデル選択をランダム・ウォーク・メトロポリス・ヘイスティング・アルゴリズムを使って算出してみる．</p>

<h4>数式の説明</h4>

<p>通常の線形回帰を考えるということで，出生率yと社会経済指標xは以下の式で表される．</p>

<p>![\bold{y} = \beta X + \varepsilon ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbold%7By%7D+%3D+%5Cbeta+X+%2B+%5Cvarepsilon+)，![\varepsilon \sim \mathcal{N}_n(0,\sigma<sup>2</sup> I_n) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon+%5Csim+%5Cmathcal%7BN%7D_n%280%2C%5Csigma%3Csup%3E2%3C%2Fsup%3E+I_n%29+)</p>

<p>このときの![\bold{y}|\beta,\sigma<sup>2,X</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbold%7By%7D%7C%5Cbeta%2C%5Csigma%3Csup%3E2%2CX%3C%2Fsup%3E+)は
![\bold{y}|\beta,\sigma<sup>2,X</sup> \sim \mathcal{N}_n(X\beta,\sigma<sup>2I_n)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbold%7By%7D%7C%5Cbeta%2C%5Csigma%3Csup%3E2%2CX%3C%2Fsup%3E+%5Csim+%5Cmathcal%7BN%7D_n%28X%5Cbeta%2C%5Csigma%3Csup%3E2I_n%29%3C%2Fsup%3E+)となる．</p>

<p>ここで，出生率yは47の地域でそれぞれ観測されているため，観測数n=47のベクトルy={y_1..yn}として表される．</p>

<p>そして，このときの尤度関数は</p>

<p>![l(\beta,\sigma<sup>2|\bold{y},X)=\big(\frac{1}{\sqrt{2\pi\sigma<sup>2}}\big)<sup>n</sup></sup></sup> \exp\big[-\frac{1}{2\sigma<sup>2}(\bold{y}-X\beta)<sup>{\mathrm{T}}(\bold{y}-X\beta)\big]</sup></sup> ](http://chart.apis.google.com/chart?cht=tx&chl=l%28%5Cbeta%2C%5Csigma%3Csup%3E2%7C%5Cbold%7By%7D%2CX%29%3D%5Cbig%28%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%5Csigma%3Csup%3E2%7D%7D%5Cbig%29%3Csup%3En%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E+%5Cexp%5Cbig%5B-%5Cfrac%7B1%7D%7B2%5Csigma%3Csup%3E2%7D%28%5Cbold%7By%7D-X%5Cbeta%29%3Csup%3E%7B%5Cmathrm%7BT%7D%7D%28%5Cbold%7By%7D-X%5Cbeta%29%5Cbig%5D%3C%2Fsup%3E%3C%2Fsup%3E+)</p>

<p>である．</p>

<p>このあたりの式変形は練習問題6.5を参照．</p>

<h3>データセットの準備</h3>

<p>swissデータセットを読み込んだあと，応答変数yとして出生率の対数，説明変数Xとして5つの社会経済指標を代入している．説明変数には</p>

<p>```r
data(swiss)</p>

<p>y &lt;- log(as.vector(swiss[,1]))
X &lt;- as.matrix(swiss[,2:6])
```</p>

<p>説明変数である社会経済指標の詳細は以下の通りである．</p>

<p>```r</p>

<blockquote><p>names(swiss)
[1] "Fertility"        "Agriculture"      "Examination"      "Education"        "Catholic"         "Infant.Mortality"
```</p></blockquote>

<h4>関数の定義</h4>

<p>```r
inv &lt;- function(X){
  EV &lt;- eigen(X)
  EV$vector %<em>% diag(1/EV$values) %</em>% t(EV$vector)
}</p>

<p>lpostw &lt;- function(gam, y, X, beta){
  n &lt;- length(y)
  qgam &lt;- sum(gam)
  Xt1 &lt;- cbind(rep(1,n), X[,which(gam==1)])
  if(qgam != 0){</p>

<pre><code>P1 &lt;- Xt1 %*% inv(t(Xt1) %*% Xt1) %*% t(Xt1)
</code></pre>

<p>  }else{</p>

<pre><code>P1 &lt;- matrix(0, n, n)
</code></pre>

<p>  }
  -(qgam+1)/2 * log(n+1) - n/2 *</p>

<pre><code>log(t(y) %*% y
    - n/(n+1)
    * t(y) %*% P1 %*% y-1/(n+1) * t(beta)
    %*% t(cbind(rep(1,n), X)) %*% P1
    %*% cbind(rep(1,n), X) %*% beta
)
</code></pre>

<p>}</p>

<p>gocho &lt;- function(niter, y, X){
  lga &lt;- dim(X)[2]
  beta &lt;- lm(y ~ X)$coeff
  gamma &lt;- matrix(0, nrow=niter, ncol=lga)
  gamma[1,] &lt;- sample(c(0,1), lga, rep=T)
  for(t in 1:(niter-1)){</p>

<pre><code>j &lt;- sample(1:lga,1)
gam0 &lt;- gamma[t,]
gam1 &lt;- gamma[t,]
gam1[j] &lt;- 1 - gam0[j]
pr &lt;- lpostw(gam0, y, X, beta)
pr &lt;- c(pr, lpostw(gam1, y, X, beta))
pr &lt;- exp(pr - max(pr))
gamma[t+1,] &lt;- gam0
if(sample(c(0,1), 1, prob=pr)){
  gamma[t+1,] &lt;- gam1
}
</code></pre>

<p>  }
  gamma
}</p>

<p>```</p>

<h3>練習問題 6.5</h3>

<h4>a. ![\beta|\sigma<sup>2,X</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbeta%7C%5Csigma%3Csup%3E2%2CX%3C%2Fsup%3E+)から![X\beta|\sigma<sup>2,X</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X%5Cbeta%7C%5Csigma%3Csup%3E2%2CX%3C%2Fsup%3E+)と![\bold{y}|\sigma<sup>2,X</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbold%7By%7D%7C%5Csigma%3Csup%3E2%2CX%3C%2Fsup%3E+)を導出する</h4>

<p>1つ目は，正規分布の線形変換を使う．これは，![X \sim \mathcal{N}(\mu,\sigma<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X+%5Csim+%5Cmathcal%7BN%7D%28%5Cmu%2C%5Csigma%3Csup%3E2%29%3C%2Fsup%3E+)のとき![Y = AX + b ](http://chart.apis.google.com/chart?cht=tx&chl=Y+%3D+AX+%2B+b+)とすると![Y \sim \mathcal{N}(A\mu+b,A\sigma<sup>2</sup> A<sup>\mathrm{T})</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=Y+%5Csim+%5Cmathcal%7BN%7D%28A%5Cmu%2Bb%2CA%5Csigma%3Csup%3E2%3C%2Fsup%3E+A%3Csup%3E%5Cmathrm%7BT%7D%29%3C%2Fsup%3E+)となる．
この性質により，</p>

<p>![X\beta|\sigma<sup>2,X\sim\mathcal{N}_n(X\tilde{\beta},n\sigma<sup>2X(X<sup>\mathrm{T}X)<sup>{-1}X<sup>\mathrm{T})</sup></sup></sup></sup></sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X%5Cbeta%7C%5Csigma%3Csup%3E2%2CX%5Csim%5Cmathcal%7BN%7D_n%28X%5Ctilde%7B%5Cbeta%7D%2Cn%5Csigma%3Csup%3E2X%28X%3Csup%3E%5Cmathrm%7BT%7DX%29%3Csup%3E%7B-1%7DX%3Csup%3E%5Cmathrm%7BT%7D%29%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E+)</p>

<p>となる．</p>

<p>2つ目は，正規分布の再生性を使う．これは，![X \sim \mathcal{N}(\mu_X,\sigma_X<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X+%5Csim+%5Cmathcal%7BN%7D%28%5Cmu_X%2C%5Csigma_X%3Csup%3E2%29%3C%2Fsup%3E+)と![Y \sim \mathcal{N}(\mu_Y,\sigma_Y<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=Y+%5Csim+%5Cmathcal%7BN%7D%28%5Cmu_Y%2C%5Csigma_Y%3Csup%3E2%29%3C%2Fsup%3E+)が独立ならば![X+Y \sim \mathcal{N}(\mu_X+\mu_Y,\sigma_X<sup>2+\sigma_Y<sup>2)</sup></sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X%2BY+%5Csim+%5Cmathcal%7BN%7D%28%5Cmu_X%2B%5Cmu_Y%2C%5Csigma_X%3Csup%3E2%2B%5Csigma_Y%3Csup%3E2%29%3C%2Fsup%3E%3C%2Fsup%3E+)が成り立つというものである．いま，![\bold{y}=\beta X+\varepsilon ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbold%7By%7D%3D%5Cbeta+X%2B%5Cvarepsilon+)における![\beta X ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbeta+X+)と![\varepsilon ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon+)はともに独立の正規分布なので，1つ目で求めた式と合わせて</p>

<p>![\bold{y}|\sigma<sup>2,X</sup> \sim \mathcal{N}_n(X\tilde{\beta},\sigma<sup>2(I_n+n\sigma<sup>2X(X<sup>\mathrm{T}X)<sup>{-1}X<sup>\mathrm{T}))</sup></sup></sup></sup></sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cbold%7By%7D%7C%5Csigma%3Csup%3E2%2CX%3C%2Fsup%3E+%5Csim+%5Cmathcal%7BN%7D_n%28X%5Ctilde%7B%5Cbeta%7D%2C%5Csigma%3Csup%3E2%28I_n%2Bn%5Csigma%3Csup%3E2X%28X%3Csup%3E%5Cmathrm%7BT%7DX%29%3Csup%3E%7B-1%7DX%3Csup%3E%5Cmathrm%7BT%7D%29%29%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E+)</p>

<p>となる．</p>

<h4>b. &amp; c.</h4>

<p>まだよく分かっていないので後回し．設問b.に関しては，どうやら「<a href="http://www.amazon.co.jp/gp/product/0387389792/ref=as_li_ss_tl?ie=UTF8&camp=247&creative=7399&creativeASIN=0387389792&linkCode=as2&tag=yagays-22">Bayesian Core: A Practical Approach to Computational Bayesian Statistics (Springer Texts in Statistics)</a><img src="http://www.assoc-amazon.jp/e/ir?t=yagays-22&l=as2&o=9&a=0387389792" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" />」に詳しく書いてある(らしい)．該当部分をざっと読んでみたけど，よく分からなかった…．</p>

<h3>参考</h3>

<ul>
<li><a href="http://www.is.titech.ac.jp/~mase/mase/html.jp/temp/swiss.jp.170.html">R: スイスの出生率と社会経済指標データ (1888)</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「Rによるモンテカルロ法入門」読書ノート：6章 ランダム・ウォーク・メトロポリス・ヘイスティング・アルゴリズム]]></title>
    <link href="http://yagays.github.io/blog/2012/11/27/imcmr-6-4/"/>
    <updated>2012-11-27T06:18:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/11/27/imcmr-6-4</id>
    <content type="html"><![CDATA[<ul>
<li>読書ノート アーカイブ：<a href="http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/">http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/</a></li>
</ul>


<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4621065270" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<h3>例 6.4 ランダム・ウォークのパラメータ設定によるサンプリングへの影響を，正規分布の乱数生成を例に確かめる</h3>

<p>摂動が![\varepsilon_t \sim \mathcal{U}_{[-\delta,\delta]} ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon_t+%5Csim+%5Cmathcal%7BU%7D_%7B%5B-%5Cdelta%2C%5Cdelta%5D%7D+)となるようなランダム・ウォークにおいて，正規分布![\mathcal{N}(0,1) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BN%7D%280%2C1%29+)をサンプリングするときのメトロポリス・ヘイスティング・アルゴリズムの受理確率は</p>

<p>![\rho(x<sup>{(t)},y_t)</sup> = \min \big[1, \exp{\frac{x<sup>{(t)2}-y_t<sup>2}{2}</sup></sup> } \big] ](http://chart.apis.google.com/chart?cht=tx&chl=%5Crho%28x%3Csup%3E%7B%28t%29%7D%2Cy_t%29%3C%2Fsup%3E+%3D+%5Cmin+%5Cbig%5B1%2C+%5Cexp%7B%5Cfrac%7Bx%3Csup%3E%7B%28t%292%7D-y_t%3Csup%3E2%7D%7B2%7D%3C%2Fsup%3E%3C%2Fsup%3E+%7D+%5Cbig%5D+)</p>

<p>で表される．</p>

<p>今回は，一様候補のパラメータを![\delta = 0.1, 1, 10 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cdelta+%3D+0.1%2C+1%2C+10+)と変更して，メトロポリス・ヘイスティング・アルゴリズムによるローカルな探索がどういう挙動を示すのかを調べる．</p>

<p>```r
par(mfcol=c(3,3))
for(d in c(0.1,1,10)){
  Niter &lt;- 2500
  x &lt;- 0
  for(i in 2:Niter){</p>

<pre><code>y &lt;- x[i-1] + runif(1, min=-d, max=d)
if (runif(1) &lt; min(1, exp(-(1/2)*(y^2 - x[i-1]^2)) )){
  x[i] &lt;- y
}else{
  x[i] &lt;- x[i-1]
}
</code></pre>

<p>  }
  plot(1:Niter, x, type="l", xlab="Iterations", ylab="",main=paste("d = ",d))
  hist(x, nclass=150, freq=F, xlim=c(-4,4), main="")
  curve(dnorm(x), lwd=2, add=T, col="red")
  acf(x)
}<br/>
```</p>

<p>それぞれのパラメータにおける系列の変動，分布，自己相関プロットを示したのが以下の図である．それぞれのサンプリング結果を見比べてみると，</p>

<ul>
<li>一様候補のパラメータが小さい場合（![\delta = 0.1 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cdelta+%3D+0.1+)）

<ul>
<li>ランダム・ウォークで移動する幅が狭い</li>
<li>分布が偏っている</li>
<li>自己相関が高い（前の値からあまり変わらない）</li>
</ul>
</li>
<li>一様候補のパラメータが大きい場合（![\delta = 10 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cdelta+%3D+10+)）

<ul>
<li>ランダム・ウォークで移動する幅が大きい</li>
<li>これも同様に分布が安定しない</li>
</ul>
</li>
</ul>


<p>という結果となり，ランダム・ウォーク・メトロポリス・ヘイスティング・アルゴリズムにおいては摂動（![\varepsilon_t ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon_t+)）のパラメータ設定が重要であることがわかる．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-4.png" alt="" /></p>

<h3>例 6.10 ランダム・ウォーク・メトロポリス・ヘイスティング・アルゴリズムの受理率を調べる</h3>

<p>メトロポリス・ヘイスティング・アルゴリズムにおけるアルゴリズム効率化の調整は，本書の2章で扱った受理・棄却アルゴリズムの時の最大受理率に基づいた調整の場合とは異なる．まず，上の例 6.4で示した正規分布からのサンプリングにおける受理率を見てみる．パラメータごとの受理率は以下のようになった（Rのコードは省略）．</p>

<ul>
<li>![\delta = 0.1 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cdelta+%3D+0.1+)：![r = 0.9792 ](http://chart.apis.google.com/chart?cht=tx&chl=r+%3D+0.9792+)</li>
<li>![\delta = 1 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cdelta+%3D+1+)：![r = 0.8132 ](http://chart.apis.google.com/chart?cht=tx&chl=r+%3D+0.8132+)</li>
<li>![\delta = 10 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cdelta+%3D+10+)：![r = 0.1716 ](http://chart.apis.google.com/chart?cht=tx&chl=r+%3D+0.1716+)</li>
</ul>


<p>この結果から，受理率が高ければサンプリングの結果も良くなるわけではないことがわかる．このことから，ランダム・ウォーク・メトロポリス・ヘイスティング・アルゴリズムにおいては，受理率を高めるようにアルゴリズムを調節してはいけないと判断できる．このアルゴリズムにおいて，どのような受理率を取ればよいかといった疑問に関しては，以下の練習問題6.14のc.で詳しく見ていく．</p>

<br />


<h3>練習問題 6.14 ランダム・ウォーク候補がサンプリング結果に与える影響について，複数の候補分布を用いてより詳細に調べる</h3>

<h4>a. P.205の図6.7を再現する</h4>

<p>図6.7の再現と![\delta ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cdelta+)の解釈は，上の例6.4の解答を参考．</p>

<h4>b. コーシー候補とラプラス候補を検討する</h4>

<p>今度は，一様分布の代わりにコーシー分布やラプラス分布を候補分布として使った場合の，ランダム・ウォーク・メトロポリス・ヘイスティング・アルゴリズムの挙動を調べる．</p>

<h4>コーシー候補</h4>

<p>ランダム・ウォーク候補は![\varepsilon_t \sim \mathcal{C}(x_0,\gamma) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon_t+%5Csim+%5Cmathcal%7BC%7D%28x_0%2C%5Cgamma%29+)とし，コーシー分布のパラメータは![x_0 = 0 ](http://chart.apis.google.com/chart?cht=tx&chl=x_0+%3D+0+)，![\gamma = 0.01,\ 1,\ 10 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cgamma+%3D+0.01%2C%5C+1%2C%5C+10+)を考える．</p>

<p>```r</p>

<h1>Cauchy candidate</h1>

<p>par(mfcol=c(3,3))
for(g in c(0.01,1,10)){
  Niter &lt;- 2500
  x &lt;- 0
  for(i in 2:Niter){</p>

<pre><code>y &lt;- x[i-1] + rcauchy(1, location=0, scale=g)
if (runif(1) &lt; min(1, exp(-(1/2)*(y^2 - x[i-1]^2)) )){
  x[i] &lt;- y
}else{
  x[i] &lt;- x[i-1]
}
</code></pre>

<p>  }
  plot(1:Niter, x, type="l", xlab="Iterations", ylab="",main=paste("Cauchy candidate,","gamma=",g))
  hist(x, nclass=150, freq=F, xlim=c(-4,4), main="")
  curve(dnorm(x), lwd=2, add=T, col="red")
  acf(x)
}
```</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-14_1.png" alt="" /></p>

<h4>ラプラス候補</h4>

<p>ランダム・ウォーク候補は![\varepsilon_t \sim \mathcal{L}(\mu,b) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon_t+%5Csim+%5Cmathcal%7BL%7D%28%5Cmu%2Cb%29+)とし，ラプラス分布のパラメータは![\mu=0 ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmu%3D0+)，![b = 0.1,\ 1,\ 10 ](http://chart.apis.google.com/chart?cht=tx&chl=b+%3D+0.1%2C%5C+1%2C%5C+10+)を考える．</p>

<p>```r</p>

<h1>Laplace candidate</h1>

<p>par(mfcol=c(3,3))
for(a in c(0.1,1,10)){
  Niter &lt;- 2500
  x &lt;- 0
  for(i in 2:Niter){</p>

<pre><code>y &lt;- x[i-1] + ifelse(runif(1)&gt;0.5, 1, -1)*rexp(1)/a
if (runif(1) &lt; min(1, exp(-(1/2)*(y^2 - x[i-1]^2)) )){
  x[i] &lt;- y
}else{
  x[i] &lt;- x[i-1]
}
</code></pre>

<p>  }
  plot(1:Niter, x, type="l", xlab="Iterations", ylab="",main=paste("Laplace candidate,","b=",a))
  hist(x, nclass=150, freq=F, xlim=c(-4,4), main="")
  curve(dnorm(x), lwd=2, add=T, col="red")
  acf(x)
}
```</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-14_2.png" alt="" /></p>

<p>以上の結果から，コーシー候補やラプラス候補においても，ランダム・ウォークの値の取り方によって適切なサンプリングができるかどうかが決まってくることがわかる．また，どちらも自己相関が低い値の時にサンプリング結果が一番良いことが見て取れる．これは例6.4の一様候補の場合とは違う結果となったが，恐らくコーシー分布やラプラス分布はともに一峰型の正規分布のような形であることが効いていて，ランダム・ウォークの移動が適度に調節されているからだろう．</p>

<h4>c. パラメータの調節により受理確率を0.25に近づける</h4>

<p>さて，例6.10で述べたように，ランダム・ウォークを使ったメトロポリス・ヘイスティング・アルゴリズムにおいては，受理率の最大化がアルゴリズムの効率化に繋がらないことがわかった．受理率はどれくらいを目安にすればよいかという疑問に関しては，本書では「高次元では0.25，低次元では0.5程度」というRoberts et al.(2007)の提案を引用している．そこで，先ほどの3つのランダム・ウォーク候補について受理率を0.25に近づけるために，パラメータの値を0から10まで0.1刻みで設定したときの，一様候補・コーシー候補・ラプラス候補を用いたアルゴリズムにおける受理率の変化を以下の図でプロットした．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-14_3.png" alt="" /></p>

<p>赤の点線は受理率0.25を表している．この図を見ると，一様候補とコーシー候補はパラメータの値が大きくなるにつれて受理率も小さくなり，逆にラプラス候補の場合ではパラメータの値が大きくなるにつれて受理率は大きくなることがわかる．いずれの場合においても，受理率を0.25に近づけることは可能である．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「Rによるモンテカルロ法入門」読書ノート：6章 メトロポリス・ヘイスティング・アルゴリズム その2]]></title>
    <link href="http://yagays.github.io/blog/2012/11/25/imcmr-6-3/"/>
    <updated>2012-11-25T01:28:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/11/25/imcmr-6-3</id>
    <content type="html"><![CDATA[<ul>
<li>読書ノート アーカイブ：<a href="http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/">http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/</a></li>
</ul>


<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4621065270" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<h3>例 6.3 二次モデルの線形回帰におけるパラメータの事後分布から，メトロポリス・ヘイスティング・アルゴリズムを用いてサンプリングする</h3>

<p>この例題では，carsのデータセットにおいて線形回帰による二次曲線のあてはめをおこない，最尤法で推定したパラメータによる事後分布から複数のサンプリングを行うことを目標にする．今回使用するデータセットは車の速度とその時の制動距離に関するデータで，Rの入門書でよく例に使われるものである．carsのデータセットに関するHelpのExampleには，本問題と似たようなプロットを描写するコード例が載っている．</p>

<p>この問題では，車のスピード![x ](http://chart.apis.google.com/chart?cht=tx&chl=x+)と制動距離![y ](http://chart.apis.google.com/chart?cht=tx&chl=y+)の関係について，以下式で表される二次モデルで線形回帰をおこなう．</p>

<p>![y_{ij}=a+bx_i+cx_i<sup>2+\varepsilon_{ij}</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=y_%7Bij%7D%3Da%2Bbx_i%2Bcx_i%3Csup%3E2%2B%5Cvarepsilon_%7Bij%7D%3C%2Fsup%3E+)</p>

<p>```r
data(cars)</p>

<p>y &lt;- cars$dist
x &lt;- cars$speed
x2 &lt;- x<sup>2</sup>
fit &lt;- lm(y ~ x + x2)
s &lt;- seq(4,25,by=0.1)
yhat &lt;- fit$coef[1] + fit$coef[2]<em>s + fit$coef[3]</em>s<sup>2</sup></p>

<p>plot(x,y, ylim=c(0,120), xlab="speed", ylab="dist", main="data(cars)")
lines(s, yhat, lwd=4, col="red")
```</p>

<p>以下の図は，車のスピードをx軸に，制動距離をy軸に取って，carsに含まれる50個のデータをプロットし，オレンジの線で回帰直線を表示している．また，この時の線形回帰で求められた各パラメータの推定値をsummary()関数を用いて表示している．この情報から，それぞれのパラメータの推定値は</p>

<ul>
<li>![a = 2.47014 ](http://chart.apis.google.com/chart?cht=tx&chl=a+%3D+2.47014+)</li>
<li>![b = 0.91329 ](http://chart.apis.google.com/chart?cht=tx&chl=b+%3D+0.91329+)</li>
<li>![c = 0.09996 ](http://chart.apis.google.com/chart?cht=tx&chl=c+%3D+0.09996+)</li>
</ul>


<p>ということがわかる．次の練習問題 6.11では，この推定値を元に，事後分布のサンプリングをメトロポリス・ヘイスティング・アルゴリズムで行う．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-11_1.png" alt="" /></p>

<p>```r</p>

<blockquote><p>summary(fit)</p></blockquote>

<p>Call:
lm(formula = y ~ x + x2)</p>

<p>Residuals:</p>

<pre><code>Min      1Q  Median      3Q     Max 
</code></pre>

<p>-28.720  -9.184  -3.188   4.628  45.152</p>

<p>Coefficients:</p>

<pre><code>        Estimate Std. Error t value Pr(&gt;|t|)
</code></pre>

<p>(Intercept)  2.47014   14.81716   0.167    0.868
x            0.91329    2.03422   0.449    0.656
x2           0.09996    0.06597   1.515    0.136</p>

<p>Residual standard error: 15.18 on 47 degrees of freedom
Multiple R-squared: 0.6673, Adjusted R-squared: 0.6532
F-statistic: 47.14 on 2 and 47 DF,  p-value: 5.852e-12
```</p>

<h3>練習問題 6.11 メトロポリス・ヘイスティング・アルゴリズムを用いて事後分布からのサンプリングをする（例6.3の続き）</h3>

<h4>a. P.202の図6.6を描写する</h4>

<p>ここで![\varepsilon_{ij} \sim \mathcal{N}(0,\sigma<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon_%7Bij%7D+%5Csim+%5Cmathcal%7BN%7D%280%2C%5Csigma%3Csup%3E2%29%3C%2Fsup%3E+)とすると，この時の尤度関数は以下式のように表される．</p>

<p>![p(y<em>{ij}|x_i,a,b,c,\sigma<sup>2)</sup> = \prod</em>{ij} \frac{1}{\sqrt{2\pi\sigma<sup>2}}\exp(-\frac{(y_{ij}-a-bx_i-cx_i<sup>2)<sup>2}{2\sigma<sup>2})</sup></sup></sup></sup> ](http://chart.apis.google.com/chart?cht=tx&chl=p%28y%3Cem%3E%7Bij%7D%7Cx_i%2Ca%2Cb%2Cc%2C%5Csigma%3Csup%3E2%29%3C%2Fsup%3E+%3D+%5Cprod%3C%2Fem%3E%7Bij%7D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%5Csigma%3Csup%3E2%7D%7D%5Cexp%28-%5Cfrac%7B%28y_%7Bij%7D-a-bx_i-cx_i%3Csup%3E2%29%3Csup%3E2%7D%7B2%5Csigma%3Csup%3E2%7D%29%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E%3C%2Fsup%3E+)</p>

<p>これを整理すると．</p>

<p>![p(y<em>{ij}|x_i,a,b,c,\sigma<sup>2)</sup> \sim \bigg( \frac{1}{\sqrt{\sigma<sup>2}}</sup> \bigg)<sup>N</sup> \exp{(-\frac{-1}{2\sigma<sup>2}</sup> \sum</em>{ij}(y<em>{ij}-a-bx_i-cx</em>{ij})<sup>2</sup> )} ](http://chart.apis.google.com/chart?cht=tx&chl=p%28y%3Cem%3E%7Bij%7D%7Cx_i%2Ca%2Cb%2Cc%2C%5Csigma%3Csup%3E2%29%3C%2Fsup%3E+%5Csim+%5Cbigg%28+%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Csigma%3Csup%3E2%7D%7D%3C%2Fsup%3E+%5Cbigg%29%3Csup%3EN%3C%2Fsup%3E+%5Cexp%7B%28-%5Cfrac%7B-1%7D%7B2%5Csigma%3Csup%3E2%7D%3C%2Fsup%3E+%5Csum%3C%2Fem%3E%7Bij%7D%28y%3Cem%3E%7Bij%7D-a-bx_i-cx%3C%2Fem%3E%7Bij%7D%29%3Csup%3E2%3C%2Fsup%3E+%29%7D+)</p>

<p>となる．この尤度関数を![x_i,a,b,c,\sigma<sup>2</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=x_i%2Ca%2Cb%2Cc%2C%5Csigma%3Csup%3E2%3C%2Fsup%3E+)による事後分布とみなす．それぞれのパラメータの分布は，先ほどの線形回帰で求めた推定値と標準誤差を用いる．</p>

<ul>
<li>![a \sim \mathcal{N}(2.47, (14.8)<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=a+%5Csim+%5Cmathcal%7BN%7D%282.47%2C+%2814.8%29%3Csup%3E2%29%3C%2Fsup%3E+)</li>
<li>![b \sim \mathcal{N}(0.913, (2.03)<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=b+%5Csim+%5Cmathcal%7BN%7D%280.913%2C+%282.03%29%3Csup%3E2%29%3C%2Fsup%3E+)</li>
<li>![c \sim \mathcal{N}(0.100, (1.52)<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=c+%5Csim+%5Cmathcal%7BN%7D%280.100%2C+%281.52%29%3Csup%3E2%29%3C%2Fsup%3E+)</li>
<li>![\sigma<sup>{-2}</sup> \sim \mathcal{G}(n/2, (n-3)(15.18)<sup>2)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Csigma%3Csup%3E%7B-2%7D%3C%2Fsup%3E+%5Csim+%5Cmathcal%7BG%7D%28n%2F2%2C+%28n-3%29%2815.18%29%3Csup%3E2%29%3C%2Fsup%3E+)</li>
</ul>


<p>なお，上の推定値や標準誤差は本書に例示されている値と若干異なっているが，今回は自分の計算環境で計算した推定値を用いることにした．</p>

<p>```r</p>

<h1>例6.3での線形回帰</h1>

<p>data(cars)
y &lt;- cars$dist
x &lt;- cars$speed
x2 &lt;- x<sup>2</sup>
fit &lt;- lm(y ~ x + x2)</p>

<p>loglik &lt;- function(a,b,c,sigma){-(n/2)<em>log(sigma)-sum((y-a-b</em>x-c<em>x2)<sup>2)/(2*sigma)}</sup>
logq &lt;- function(a,b,c,sigma){
  dnorm(a,mean=a.est[1],sd=a.std,log=T)
  + dnorm(b,mean=b.est[1],sd=b.std,log=T)
  + dnorm(c,mean=c.est[1],sd=c.std,log=T)
  - (n/2)</em>log(sigma) - (n-3)*(15.18)<sup>2/(2*sigma)</sup>
}</p>

<p>Niter &lt;- 4000
n &lt;- length(x)
fit.param &lt;- summary(fit)$coef
a.est &lt;- fit.param[1,1]
a.std &lt;- fit.param[1,2]
b.est &lt;- fit.param[2,1]
b.std &lt;- fit.param[2,2]
c.est &lt;- fit.param[3,1]
c.std &lt;- fit.param[3,2]
sig &lt;- 1/rgamma(1, n/2, rate=(n-3)*(15.18)<sup>2/2)</sup></p>

<p>for(i in 2:Niter){
  candidate &lt;- c(rnorm(1, mean=a.est[1], sd=a.std),</p>

<pre><code>             rnorm(1, mean=b.est[1], sd=b.std),
             rnorm(1, mean=c.est[1], sd=c.std),
             1/rgamma(1, n/2, rate=(n-3)*(15.18)^2/2)
             )
</code></pre>

<p>  fy &lt;- loglik(candidate[1], candidate[2], candidate[3], candidate[4])
  fx &lt;- loglik(a.est[i-1], b.est[i-1], c.est[i-1], sig[i-1])
  qxy &lt;- logq(a.est[i-1], b.est[i-1], c.est[i-1], sig[i-1])
  qyx &lt;- logq(candidate[1], candidate[2], candidate[3], candidate[4])
  rho &lt;- min(1, exp(fy-fx+qxy-qyx))</p>

<p>  if (runif(1)&lt;rho){</p>

<pre><code>a.est[i] &lt;- candidate[1]
b.est[i] &lt;- candidate[2]
c.est[i] &lt;- candidate[3]
sig[i] &lt;- candidate[4]
</code></pre>

<p>  }else{</p>

<pre><code>a.est[i] &lt;- a.est[i-1]
b.est[i] &lt;- b.est[i-1]
c.est[i] &lt;- c.est[i-1]
sig[i] &lt;- sig[i-1]
</code></pre>

<p>  }
}</p>

<p>s &lt;- seq(4,25,by=0.1)
yhat &lt;- fit$coef[1] + fit$coef[2]<em>s + fit$coef[3]</em>s<sup>2</sup></p>

<p>plot(x,y, ylim=c(0,120), xlab="speed", ylab="dist", main="data(cars)", type="n")
for(i in (Niter-500):Niter){
  lines(x, a.est[i]+b.est[i]<em>x+c.est[i]</em>x2, lwd=2, col="grey")
}
lines(s, yhat, lwd=4, col="orange")
points(x, y, pch=19)
```</p>

<p>以下の図は，先ほどの線形回帰のプロットに加えて，サンプリングから得られた値を用いて回帰曲線を灰色の曲線として描写したものである．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-11_3.png" alt="" /></p>

<h4>b. 各パラメータの収束をモニタリングする</h4>

<p>先ほどのサンプリング結果を，![a,b,c,\sigma<sup>2</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=a%2Cb%2Cc%2C%5Csigma%3Csup%3E2%3C%2Fsup%3E+)について，4000回のシミュレーションで生成された系列と，そのときの自己相関プロット，そして系列の分布をプロットした．</p>

<p><code>r
par(mfrow=c(4,3))
plot(1:Niter, a.est, type="l", xlab="Iterations", main="a")
acf(a.est)
plot(density(a.est), main="")
plot(1:Niter, b.est, type="l", xlab="Iterations", main="b")
acf(b.est)
plot(density(b.est), main="")
plot(1:Niter, c.est, type="l", xlab="Iterations", main="c")
acf(c.est)
plot(density(c.est), main="")
plot(1:Niter, sig, type="l", xlab="Iterations", main=expression(sigma^2))
acf(sig)
plot(density(sig), main="")
</code></p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-11_2.png" alt="" /></p>

<h4>c. 95%信用区間を求める</h4>

<p>```r</p>

<blockquote><p>quantile(a.est, c(0.025,0.975))</p>

<pre><code> 2.5%     97.5% 
</code></pre>

<p>-14.90933  18.98784
```</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「Rによるモンテカルロ法入門」読書ノート：6章 マルコフ連鎖とランダム・ウォーク]]></title>
    <link href="http://yagays.github.io/blog/2012/11/22/imcmr-6-2/"/>
    <updated>2012-11-22T12:14:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/11/22/imcmr-6-2</id>
    <content type="html"><![CDATA[<ul>
<li>読書ノート アーカイブ：<a href="http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/">http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/</a></li>
</ul>


<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4621065270" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<h3>練習問題 6.1 自己回帰モデルAR(1)が定常分布を持つことを実験的に示す</h3>

<p>この問題はいわゆるAR(1)というもので，本書の1章 P.34に同様のコードおよび作図が載っている．なお，本問題の詳細は<a href="http://www.stat.ufl.edu/~casella/ShortCourse/MCMC-UseR.pdf">MCMC-UseR.pdf</a>のP.130を参照．</p>

<p>![X<sup>{(t+1)}</sup> = \rho X<sup>{(t)}+\varepsilon_t</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X%3Csup%3E%7B%28t%2B1%29%7D%3C%2Fsup%3E+%3D+%5Crho+X%3Csup%3E%7B%28t%29%7D%2B%5Cvarepsilon_t%3C%2Fsup%3E+)，![\varepsilon_t \sim \mathcal{N}(0,1) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cvarepsilon_t+%5Csim+%5Cmathcal%7BN%7D%280%2C1%29+)で定義されるマルコフ連鎖において，系列![{X<sup>{(t)}}</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%7BX%3Csup%3E%7B%28t%29%7D%7D%3C%2Fsup%3E+)の定常分布は![\mathcal{N}(0, \frac{\sigma<sup>2}{1-\rho<sup>2})</sup></sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BN%7D%280%2C+%5Cfrac%7B%5Csigma%3Csup%3E2%7D%7B1-%5Crho%3Csup%3E2%7D%29%3C%2Fsup%3E%3C%2Fsup%3E+)で表される．今回は![t=10<sup>4</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=t%3D10%3Csup%3E4%3C%2Fsup%3E+)までのシミュレーション結果をヒストグラムとしてプロットし，定常分布を赤い曲線で示した．</p>

<p>```r
rho &lt;- 0.9
x &lt;- rnorm(1)
for(t in 2:10<sup>4){</sup>
  x[t] &lt;- x[t-1]*rho + rnorm(1)
}</p>

<p>hist(x, nclass=150, freq=F)
curve(dnorm(x, mean=0, sd=(1/sqrt(1-rho<sup>2))),</sup> add=T, col="red")
```</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6_1.png" alt="" /></p>

<h3>練習問題 6.2 ランダム・ウォークが定常分布を持たないことを実験的に示す</h3>

<p>![X<sup>{(t+1)}=X<sup>{(t)}+\varepsilon_t</sup></sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X%3Csup%3E%7B%28t%2B1%29%7D%3DX%3Csup%3E%7B%28t%29%7D%2B%5Cvarepsilon_t%3C%2Fsup%3E%3C%2Fsup%3E+)で表されるランダム・ウォークが，シミュレーション回数を増やしても定常分布に収束しないことを実験的に確かめる．今回は初期値![X<sup>{(0)}=0</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=X%3Csup%3E%7B%280%29%7D%3D0%3C%2Fsup%3E+)として，![t=10<sup>4</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=t%3D10%3Csup%3E4%3C%2Fsup%3E+)と![t=10<sup>6</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=t%3D10%3Csup%3E6%3C%2Fsup%3E+)までマルコフ連鎖をシミュレートする．
この問題は練習問題6.1における![\rho = 1](http://chart.apis.google.com/chart?cht=tx&chl=%5Crho+%3D+1)の場合と同じになるので，上で書いたコードのパラメータを変更するだけで再現できる．ただ，今回は別の書き方としてcumsum()関数を用いてランダム・ウォークの系列を計算している．</p>

<p>```r
init &lt;- 0
x1 &lt;- cumsum(rnorm(10<sup>4-1))</sup>
x2 &lt;- cumsum(rnorm(10<sup>6-1))</sup></p>

<p>par(mfrow=c(2,2))
hist(x1, nclass=150, main="t=10<sup>4")</sup>
plot(1:10<sup>4,</sup> c(init,x1), type="l", xlab="t", main="t=10<sup>4")</sup>
hist(x2, nclass=150, main="t=10<sup>6")</sup>
plot(1:10<sup>6,</sup> c(init,x2), type="l", xlab="t", main="t=10<sup>6")</sup>
```</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6_2.png" alt="" /></p>

<p>シミュレーション回数を![t=10<sup>4</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=t%3D10%3Csup%3E4%3C%2Fsup%3E+)と![t=10<sup>6</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=t%3D10%3Csup%3E6%3C%2Fsup%3E+)としてランダム・ウォークを実行した結果が上図である．左図に系列のヒストグラム，右図に試行回数を横軸に取った系列をプロットしている．上のように図示すると，たとえ10<sup>6</sup> 回試行したとしても何らかの分布に収束しないことがわかる．</p>

<h3>雑感</h3>

<p>練習問題 6.1と練習問題6.2を比較すると，ランダム・ウォークにおいて先行する状態に![0 \leq \rho &lt; 1 ](http://chart.apis.google.com/chart?cht=tx&chl=0+%5Cleq+%5Crho+%26lt%3B+1+)のような値を掛け合わせるだけで定常分布を取るというのは，なんとも面白い結果となっている．</p>

<h3>補足：<a href="http://www.stat.ufl.edu/~casella/ShortCourse/MCMC-UseR.pdf">MCMC-UseR.pdf</a>のP.132</h3>

<ul>
<li>練習問題の![\rho ](http://chart.apis.google.com/chart?cht=tx&chl=%5Crho+)と以下図の![\theta ](http://chart.apis.google.com/chart?cht=tx&chl=%5Ctheta+)は同じ</li>
<li>pdfにも書いてあるがスケール（x軸とy軸の描写範囲）に注意．いかに![\theta ](http://chart.apis.google.com/chart?cht=tx&chl=%5Ctheta+)が効いているかがわかる</li>
<li>左上はマルコフ連鎖ではない</li>
</ul>


<p>```r
par(mfrow=c(2,2))
for(rho in c(0, 0.4, 0.8, 0.95)){
  x &lt;- rnorm(1)
  y &lt;- rnorm(1)
  for(t in 2:1000){</p>

<pre><code>x[t] &lt;- x[t-1]*rho + rnorm(1)
y[t] &lt;- y[t-1]*rho + rnorm(1)
</code></pre>

<p>  }
  plot(x,y, type="l", main=paste("theta=",rho))
}
```</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6_extra.png" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[「Rによるモンテカルロ法入門」読書ノート：6章 メトロポリス・ヘイスティング・アルゴリズム その1]]></title>
    <link href="http://yagays.github.io/blog/2012/11/18/imcmr-6-1/"/>
    <updated>2012-11-18T14:37:00+09:00</updated>
    <id>http://yagays.github.io/blog/2012/11/18/imcmr-6-1</id>
    <content type="html"><![CDATA[<ul>
<li>読書ノート アーカイブ：<a href="http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/">http://yagays.github.com/blog/2012/10/20/archive-introducing-monte-carlo-methods-with-r/</a></li>
</ul>


<iframe src="http://rcm-jp.amazon.co.jp/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=yagays-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4621065270" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" align="right"></iframe>


<h3>例 6.1 メトロポリス・ヘイスティング・アルゴリズムでベータ分布の乱数を生成する</h3>

<p><a href="http://yagays.github.com/blog/2012/10/22/imcmr-2-2/">例2.7</a>では受理・棄却法を用いてベータ分布の乱数を生成したが，本問題ではメトロポリス・ヘイスティング・アルゴリズムを使ってベータ分布からサンプリングを行うことを目的とする．</p>

<p>```r
a &lt;- 2.7
b &lt;- 6.3
c &lt;- 2.669
Nsim &lt;- 5000
X &lt;- rep(runif(1), Nsim)</p>

<p>for(i in 2:Nsim){
  Y &lt;- runif(1)
  rho &lt;- dbeta(Y, a, b)/dbeta(X[i-1], a, b)
  X[i] &lt;- X[i-1] + (Y - X[i-1])*(runif(1)&lt;rho)
}</p>

<p>plot(1:Nsim, X, type="l", xlab="Iterations", main="Sequence X<sup>t")</sup>
plot(4500:4800, X[4500:4800], type="l", xlab="Iterations", main="Sequence X<sup>t</sup> for t = 4500 - 4800")
```</p>

<p>まず，以下の図は系列![{X<sup>{(t)}}</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%7BX%3Csup%3E%7B%28t%29%7D%7D%3C%2Fsup%3E+)をプロットしたものである．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-1_1.png" alt="" /></p>

<p>そして，その中からシミュレーション回数が4500〜4800回までの系列を抜き出したのが以下の図となっている．このように一部分を拡大して見てみると，系列を表す線が変化せずにx軸に並行に遷移している部分が見られる．これは![\rho(x<sup>{(t)},Y_t)</sup> ](http://chart.apis.google.com/chart?cht=tx&chl=%5Crho%28x%3Csup%3E%7B%28t%29%7D%2CY_t%29%3C%2Fsup%3E+)の確率で棄却されて値が変化していないことを表している．これは対応する![Y_t ](http://chart.apis.google.com/chart?cht=tx&chl=Y_t+)に依存し，マルコフ連鎖の性質から次の状態にも影響するため，値が変化しない状態が一定期間続くことがあるからである．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-1_2.png" alt="" /></p>

<p>また，得られた系列がベータ分布の乱数となっているかを確かめるため，左側に今回のメトロポリス・ヘイスティング・アルゴリズムで作成した乱数，右側にRの組込み関数rbeta()で生成した乱数をヒストグラムで図示し，今回実験で設定したベータ分布![\mathcal{Be}(2.7,6.3) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BBe%7D%282.7%2C6.3%29+)を赤の曲線で表した．</p>

<p><code>r
par(mfrow=c(1,2))
hist(X, nclass=100, freq=F, xlim=c(0,1.0), main="Metropolis-Hastings")
curve(dbeta(x,a,b), add=T, col="red", lwd=2)
hist(rbeta(Nsim,a,b), freq=F, nclass=100, xlim=c(0,1.0), main="Direct Generation")
curve(dbeta(x,a,b), add=T, col="red", lwd=2)
</code></p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-1_3.png" alt="" /></p>

<p>この図を見ると，メトロポリス・ヘイスティング・アルゴリズムを使った場合でも，受理・棄却法の時と同じく乱数の生成に成功していることがわかる．</p>

<h3>例 6.2 メトロポリス・ヘイスティング・アルゴリズムでコーシー分布の乱数を生成する</h3>

<p>例6.1のベータ分布の乱数生成における提案分布は![\mathcal{U}_{0,1} ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BU%7D_%7B0%2C1%7D+)だったが，コーシー分布の乱数生成における提案分布には，</p>

<ul>
<li>標準正規分布：![\mathcal{N}(0,1) ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BN%7D%280%2C1%29+)</li>
<li>自由度0.5のスチューデントt分布：![\mathcal{T}_{1/2} ](http://chart.apis.google.com/chart?cht=tx&chl=%5Cmathcal%7BT%7D_%7B1%2F2%7D+)</li>
</ul>


<p>を使うことができる．このような提案分布は独立提案分布であり，マルコフ連鎖ではない．</p>

<p>なお，本問題ではこれらの分布を表す単語として候補分布と提案分布という2つの言葉が出てくるが，今回は表記として提案分布で統一する．</p>

<p>```r</p>

<h1>Standard Normal Distributionp</h1>

<p>Nsim &lt;- 10<sup>4</sup>
X &lt;- c(rt(1,1))
for(t in 2:Nsim){
  Y &lt;- rnorm(1)
  rho &lt;- min(1, dt(Y, 1)<em>dnorm(X[t-1]) / (dt(X[t-1],1)</em>dnorm(Y)))
  X[t] &lt;- X[t-1] + (Y - X[t-1])*(runif(1) &lt; rho)
}</p>

<h1>t-distribution (0.5 degree of freedom)</h1>

<p>X2 &lt;- c(rt(1,1))
for(t in 2:Nsim){
  Y &lt;- rt(1, 0.5)
  rho &lt;- min(1, dt(Y, 1)<em>dt(X2[t-1], 0.5) / (dt(X2[t-1],1)</em>dt(Y, 0.5)))
  X2[t] &lt;- X2[t-1] + (Y - X2[t-1])*(runif(1) &lt; rho)
}
```</p>

<p>まずはそれぞれの系列をプロットして特徴を見ていく．左側に提案分布を標準正規分布とした場合，右側に提案分布をスチューデントt分布とした場合で，上から順に系列のプロット，系列のヒストグラム，系列の自己相関プロットを図示したのが以下の図になっている．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-2_1.png" alt="" /></p>

<p>まずは標準正規分布を使った場合からみていく．系列のプロットは例6.1と同じような形を示しているが，イテレーションが8500を過ぎたあたりで値が一定期間変化しない部分がある．これは乱数から生成する正規候補![Y_t ](http://chart.apis.google.com/chart?cht=tx&chl=Y_t+)が大きい（または小さい）値を取ってしまい，連鎖で長い間引きずることになったからである．この現象は，系列のヒストグラムの右端において値が少し大きくなっていることからも確認することができる．</p>

<p>一方，スチューデントt分布を使った場合においては，系列のプロットは0付近で集中しており，たまに正規候補![Y_t ](http://chart.apis.google.com/chart?cht=tx&chl=Y_t+)が非常に大きい値を取ることはあるものの，それが継続して続くわけではないことがわかる．系列のヒストグラムを見ても，標準正規分布の場合と比べて分布がなだらかでコーシー分布に当てはまっていることがわかる．ただし，実際には両端の外れ値を除外して系列のヒストグラムをプロットしているので，このヒストグラムの描写範囲から外れている値があることには注意が必要である．</p>

<br />


<p>次に，2つの提案分布におけるメトロポリス・ヘイスティング・アルゴリズムによって生成したコーシー乱数の累積収束プロット，すなわち乱数の平均値がどのように収束していくかを図示する．</p>

<p><img src="http://dl.dropbox.com/u/142306/b/imcmr/chp6_6-2_2.png" alt="" /></p>

<p>黒線が提案分布に標準正規分布を使った場合，黄色の線が提案分布にスチューデントt分布を使った場合となっている．今回シミュレートしているコーシー分布から求めた正確な値は0.896なので，スチューデントt分布はイテレーション回数を重ねるごとに真の値に収束していくことがわかる．一方で標準正規分布においては，今回のイテレーション回数(N=5000)では真の値に収束していないようにみえる．しかし，平均値の傾向を見ると値が徐々に上昇しては一気に下がり...といった傾向が見られ，理論的にも標準正規分布を提案分布として用いた場合でも真の値に収束することがわかっている．なので，今回の場合はイテレーション回数が少なすぎるために，収束の様子が見られない．</p>
]]></content>
  </entry>
  
</feed>
