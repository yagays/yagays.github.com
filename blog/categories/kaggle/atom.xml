<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Kaggle | Wolfeyes Bioinformatics beta]]></title>
  <link href="http://yagays.github.io/blog/categories/kaggle/atom.xml" rel="self"/>
  <link href="http://yagays.github.io/"/>
  <updated>2015-02-09T09:25:05+09:00</updated>
  <id>http://yagays.github.io/</id>
  <author>
    <name><![CDATA[yag_ays]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[私は如何にしてKaggleで9位から600位台まで順位を落とし，private leaderboardでベンチマークすら下回ったか？]]></title>
    <link href="http://yagays.github.io/blog/2014/10/23/kaggle-africa-soil-property-prediction-challenge/"/>
    <updated>2014-10-23T06:55:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/10/23/kaggle-africa-soil-property-prediction-challenge</id>
    <content type="html"><![CDATA[<p>タイトルは釣りです（元ネタ：<a href="http://d.hatena.ne.jp/repose/20120723/1343025035">過学習の恐怖，またはいかにして私は1分間でランキングを50位も落としたか(要約) - 糞ネット弁慶</a>）</p>

<h3>Africa Soil Property Prediction Challenge</h3>

<p>8月終わりからKaggleで行われていた<a href="https://www.kaggle.com/c/afsis-soil-properties">"Africa Soil Property Prediction Challenge"</a>，通称AfSISが終わりました．このコンペは衛星から取得したアフリカの各地点の吸光度などの数値情報を元に，その場所のSOC,pH,Ca,P,Sandの計5種類の地質学的な測定値を推定するという問題でした．問題設定としては定番っぽくて取っ付き易いものの，実際にやってみるとこれまた難しい感じでした．</p>

<p>私は開催当初から参加していて，一時期9位まで上がったものの，そこから何もしなかったらどんどん抜かされたというわけです．</p>

<blockquote class="twitter-tweet" lang="en"><p>Hold my calls. Top 10 on <a href="https://twitter.com/hashtag/kaggle?src=hash">#kaggle</a> - <a href="https://t.co/EUmPGDB0oq">https://t.co/EUmPGDB0oq</a></p>&mdash; やぐ (@yag_ays) <a href="https://twitter.com/yag_ays/status/506999657243766785">September 3, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>




<blockquote class="twitter-tweet" lang="en"><p>忙しさが一段落したのでkaggleに戻ってきたらランクが150位くらい下がってて厳しさがある</p>&mdash; やぐ (@yag_ays) <a href="https://twitter.com/yag_ays/status/512983920262918144">September 19, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>


<p>それに加えて開催期間が終わってテストデータ全体での評価が出た結果，おそらく過学習でスコアが下がり，開催側が設定したBART Benchmarkよりも下回るという有り様でした．Kaggle怖いです...．</p>

<h3>私は如何にして（ry</h3>

<p>今回は時間があったので，今回は色々試した気がします．定番のSVRに始まり，Gradient Boosting Regression Treesしたり，Random Forest Regressor使ったり，あとはForumに投稿されたH2Oでのdeep learningもどきもひと通り動かしたのですが，結果的に一番良かったのがSVRだったのでその中から前処理を幾つかやったやつを最終的にサブミット．実際はAbhishekの<a href="https://www.kaggle.com/c/afsis-soil-properties/forums/t/10351/beating-the-benchmark">Beating the Benchmark ;)</a>のやり方とほとんど変わらないと思います．どこで差が付いたのか，あとAbhishekを代表とするSVR勢は過学習を回避して大勝利となったのか，気になるところです．</p>

<p>いや確かにpublic leaderboardは手元で算出したスコアとかなり乖離があって謎いとは常々思っていたのですが，一応scikit-learnのgrid searchでチューニングはしているので大丈夫だと...厳しい．</p>

<p>といっても上位陣もかなり大荒れだった模様．以下のランクはpublic→privateの順で，これを見てもらえればわかる通り上位陣は著しくランクを落としている人が多い．逆にprivateでは100位以内くらいから上がってきた人が多く，今回は本当に結果が読めなかったようでした．</p>

<h4>public上位</h4>

<p><a href="http://www.kaggle.com/c/afsis-soil-properties/leaderboard/public">Public Leaderboard - Africa Soil Property Prediction Challenge | Kaggle</a></p>

<ul>
<li>sorpmaL：1位→515位</li>
<li>Dmitry &amp; Abhishek：2位→7位</li>
<li>vsu：3位→484位</li>
<li>Redwoods：4位→34位</li>
<li>ahaldenby：5位→517位</li>
</ul>


<h4>private上位</h4>

<p><a href="http://www.kaggle.com/c/afsis-soil-properties/leaderboard/private">Private Leaderboard - Africa Soil Property Prediction Challenge | Kaggle</a></p>

<ul>
<li>Yasser Tabandeh 14位→1位</li>
<li>Charly B. ：428位→2位</li>
<li>CodiLime.com：42位→3位</li>
<li>seewaters：61位→4位</li>
<li>UK calling Africa：88位→5位</li>
</ul>


<p>詳しいことは後々明らかになっていくことでしょう．Forumを静観．</p>

<p>あと，悔しいので念のために書いておきますが最終サブミッションに選択した以外のやつではきちんとベンチマーク上回っているのありました．ただ，スコアがいいやつに限って最初の方にサブミットした何のひねりも無いSVRだったりして，心が折れそう．</p>

<h3>Lessons Learned</h3>

<p>社会は厳しい．</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kaggle初心者がDisplay Advertising Challengeに挑んだ結果354th/718だった]]></title>
    <link href="http://yagays.github.io/blog/2014/09/26/kaggle-criteo-display-advertising-challenge/"/>
    <updated>2014-09-26T16:41:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/09/26/kaggle-criteo-display-advertising-challenge</id>
    <content type="html"><![CDATA[<p>Kaggleで行われていたcriteoのDisplay Advertising Challengeが終了し，最終的にPublic LB:0.47880，Private LB:0.47831の354th/718だった．1位のチームが0.44464，Top10あたりが0.44台のスコアを叩き出しているので，結果としては惨敗だけれども，初めてにしては健闘できたほうだと思う．まあ最初の方はLogistic regressionのBenchmarkすら越せなくて厳しい状態だったが，そこから抜けだしてある程度成果が出始めると，あとは計算してはサブミットしてを繰り返しスコアに一喜一憂するという感じで競技性があって非常に楽しめた．次はもっと上の方に行きたいと思いつつ，現在参加しているAfrica Soil Property Prediction Challengeは一時期10位圏内まで行ったもののそこから怒涛のランク落ちで現在300位くらいまで下がってしまったので，世間は厳しい．Kaggle Masterへの道はまだまだ遠い．</p>

<h3>予測方法</h3>

<p>さて，こんな中途半端な順位のヤツの解法なんて見てもどうしょうもないとは思うけれども，個人的な記録のためにも書いておく．</p>

<p>使用したのは<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">Vowpal Wabbit</a>(VW)．主に参考にしたのはMLWaveの<a href="http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/">Predicting CTR with online machine learning</a>で，とりあえず動くコードの例があって，あとはVWのパラメータチューニングで頑張ったという流れ．実はこれ以前にscikit-learn + pandasも試していたのだけれども，あまりにデータ量が多すぎてpandasのget_dummiesでダミー変数作るのが不可能だったりと早々に諦めていた．その点VWは高速で動いてメモリ消費量も少ないので，初心者にとっては使いやすいソフトウェアだった．あと<a href="https://github.com/MLWave/kaggle-criteo">MLWave/kaggle-criteo</a>でデータ形式の変換コードがあったのが助かった．</p>

<p>さて，最終的なサブミットに使用したのは以下のパラメータ．</p>

<ul>
<li>損失関数(--loss_function)：logistic</li>
<li>Feature Hashingのbit数(-b)：30</li>
<li>L2正則化(--l2): 1e-08</li>
<li>データのイテレーション回数(--passes):10</li>
</ul>


<p>少し前の記事の<a href="http://yagays.github.io/blog/2014/08/31/vowpal-wabbit/">私的Vowpal Wabbitまとめ - Wolfeyes Bioinformatics beta</a>にも書いたけど，loss_functionはlogisticにしておくと学習が終わったときにだいたいのスコアがわかって便利．あと-bを増やすとfeature hashingでcollisionしなくなるけれども，そのかわり必要なメモリ容量が増える．L2正則化はL1とともに1e-01から1e-12くらいまで試したんだけど，スコアが劇的に変わるわけではなかった．--passesは必須だけど，ある程度のイテレーション回数でスコアに変動がなければ途中で切られるみたいなので，パラメータを変更後に必要回数を確認してからは変えていない．</p>

<p><code>sh
$ vw click.train.vw -f click.model.b30.pass10.l2_1e-08.vw --loss_function logistic -c -k -b 30 --passes 10 --l2 0.00000001
$ vw click.test.vw -t -i click.model.b30.pass10.l2_1e-08.vw -p click.preds.b30.pass10.l2_1e-08.vw
</code></p>

<h3>感想戦</h3>

<ul>
<li><a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners">Congratulations to the winners! - Display Advertising Challenge | Kaggle</a></li>
</ul>


<p>Kaggleのフォーラムで上位ランクの人が自分の解析方法を公開してくれているので，その中からVWに関するトピックを幾つか拾ってみる．</p>

<p>まずは，15thのLuca MassaronがVWを使った解析例を示してくれている(<a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners/54591#post54591">link</a>)．VWのコマンドは非常に参考になるし，自分もNNのHidden Unitsを10とか20でやったんだけどなーと思いつつ，何よりもまずデータの前処理の必要性を感じた．</p>

<p>あとは19thのKonrad BanachewiczはVWのより詳細な結果を示してくれていて(<a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners/54595#post54595">link</a>)，こっちではNNが効かないみたいな話があったり，quadratic feature頑張ってたり．</p>

<p>あとはLibFMとかNNとかAutoencoderとか色々な方法で予測している人がいて，非常に参考になる．</p>

<h3>今後のCriteo Display Advertising Challengeの動向</h3>

<p>Kaggleでのコンペは終わってしまったが，上に書いたようなフォーラムでの議論は続くし，それにコンペ用のデータセットが学術向けに公開された．これでもしかしたら上位ランクのグループの成果が論文として出てくるかもしれない．</p>

<ul>
<li><a href="http://labs.criteo.com/2014/09/kaggle-contest-dataset-now-available-academic-use/">Kaggle contest dataset is now available for academic use! - Criteo Labs</a></li>
</ul>


<p>あと，<a href="https://docs.google.com/file/d/0BzrlDxVZWSUpNFdscnRmUUdJWk5qYVhkVVE0WjV1LUxpZlhr/edit">Criteoの資料</a>によると"Winners will release code publicly(Popular OSI-approved license)"らしいので，ぜひともコードを公開してほしいところ．</p>

<p>といった感じで，まだまだCriteo Display Advertising Challengeは終わらない．</p>

<h4>追記：</h4>

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/yag_ays">@yag_ays</a> kaggleのコンペのほとんど（全て？）は、Prizeに入った人は手法の説明とコード(OSI承認ライセンス)をフォーラムに投稿しなければならないとルールに書いてあるので、なんらかトラブルがない限り上位陣の成果は公開されると思います。</p>&mdash; id:ultraist (@ultraistter) <a href="https://twitter.com/ultraistter/status/515428100847304704">September 26, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[私的Vowpal Wabbitまとめ]]></title>
    <link href="http://yagays.github.io/blog/2014/08/31/vowpal-wabbit/"/>
    <updated>2014-08-31T10:47:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/08/31/vowpal-wabbit</id>
    <content type="html"><![CDATA[<h2>VWとは</h2>

<blockquote><p>The Vowpal Wabbit (VW) project is a fast out-of-core learning system sponsored by Microsoft Research and (previously) Yahoo! Research.</p>

<p><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">Home · JohnLangford/vowpal_wabbit Wiki</a></p></blockquote>

<h2>Install</h2>

<p>要Boost．</p>

<h4>Linux</h4>

<p><a href="https://github.com/JohnLangford/vowpal_wabbit/blob/master/README.md">vowpal_wabbit/README.md</a>に書いてある通り，git cloneしてmakeする．それが駄目なら./autogen.shしてからmakeする．</p>

<p>自分の場合は./autogen.shがエラーを吐いたので調べたところ，./autogen.sh内部でldconfigに失敗してBOOST_DIR_ARGが取得できていないのが原因だった．su権限でldconfigをしてLIBFILEの箇所を以下のように書き換えて対処した．当然ながらこれは環境に依存するので，自身の環境でLIBFILEに渡すコマンドを実行して置き換える．</p>

<p>```sh</p>

<h1>LIBFILE=<code>ldconfig -p | grep program_options | tail -n 1 | cut -d '&gt;' -f 2</code></h1>

<p>  LIBFILE="/usr/lib64/libboost_program_options-mt.so"
```</p>

<h4>Mac OS X</h4>

<p>Mac OS Xの場合Homebrewでバイナリをインストール可能だが，vw-varinfo等のutil系は入らない．</p>

<p>```sh
$ brew info vowpal-wabbit
vowpal-wabbit: stable 7.7 (bottled), HEAD
https://github.com/JohnLangford/vowpal_wabbit
/usr/local/Cellar/vowpal-wabbit/7.7 (30 files, 4.7M) *
  Poured from bottle
From: https://github.com/Homebrew/homebrew/blob/master/Library/Formula/vowpal-wabbit.rb
==> Dependencies
Build: boost ✔, autoconf ✔, automake ✔, libtool ✔</p>

<p>$ brew install vowpal-wabbit
```</p>

<h4>Windows</h4>

<ul>
<li><a href="http://qiita.com/shima_x/items/9147eaa3626fab87ada2">機械学習 - windowsマシンでvowpal wabbitを使う（個人的メモ） - Qiita</a></li>
</ul>


<h2>VWを始めるときに気をつけるポイント</h2>

<ul>
<li>VWの独自フォーマット

<ul>
<li>VWを使いはじめるときの最初の難関ポイント</li>
<li>自分でcsvなどのデータをVWフォーマットに変換する必要がある</li>
<li>カテゴリ変数やテキストはそのまま列挙しても大丈夫．VWの方でn-gramも取ることができる</li>
</ul>
</li>
<li>VWのパラメータ名

<ul>
<li>資料によってパラメータの名前が違うので注意</li>
<li>自分の環境で<code>vw --help</code>して適宜読み替える</li>
</ul>
</li>
</ul>


<h2>Tutorial</h2>

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial">Tutorial · JohnLangford/vowpal_wabbit Wiki</a>

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/v7.0_tutorial.pdf">https://github.com/JohnLangford/vowpal_wabbit/wiki/v7.0_tutorial.pdf</a>

<ul>
<li>Binary Classification and Regression</li>
<li>Multiclass Classification</li>
<li>“Offline” Contextual Bandit</li>
<li>Sequence Predictions</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://zinkov.com/posts/2013-08-13-vowpal-tutorial/">Convex Optimized - Vowpal Wabbit tutorial for the Uninitiated</a>

<ul>
<li>かなり幅広く網羅したtutorial</li>
</ul>
</li>
</ul>


<h2>vw-varinfoについて</h2>

<p>vw-varinfoを使うことによって，変数ごとに重み等の情報を出力することができる．</p>

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/using-vw-varinfo">using vw varinfo · JohnLangford/vowpal_wabbit Wiki</a></li>
</ul>


<h2>Other Resources</h2>

<ul>
<li><a href="http://www.slideshare.net/pauldix/terascale-learning">Terascale Learning</a></li>
<li><a href="http://www.slideshare.net/jakehofman/technical-tricks-of-vowpal-wabbit">Technical Tricks of Vowpal Wabbit</a></li>
<li><a href="http://fastml.com/large-scale-l1-feature-selection-with-vowpal-wabbit/">Large scale L1 feature selection with Vowpal Wabbit - FastML</a>

<ul>
<li>L1 Regularizationについて

<ul>
<li><a href="http://www.kaggle.com/c/job-salary-prediction">Job Salary Prediction | Kaggle</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="http://fastml.com/vowpal-wabbit-eats-big-data-from-the-criteo-competition-for-breakfast/">Vowpal Wabbit eats big data from the Criteo competition for breakfast - FastML</a>

<ul>
<li>コンペの評価方法がLogarithmic Lossだから，VWの<code>--loss_function</code>をlogisticにしてくとVWの標準出力のaverage lossの部分がだいたいKaggleのスコアになるという話

<ul>
<li><a href="http://www.kaggle.com/c/criteo-display-ad-challenge">Display Advertising Challenge | Kaggle</a></li>
</ul>
</li>
<li>変数が大量にあるとfeature hashingの時にHashValが衝突(collision)するから，<code>-b</code>でhashing spaceをちょっと大きめにしておくといいという話

<ul>
<li><a href="https://github.com/JohnLangford/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction">Feature Hashing and Extraction · JohnLangford/vowpal_wabbit Wiki</a></li>
<li>-bのデフォルトが18なので，2<sup>18</sup> =262,144くらいのfeature数なら問題無い．むやみに大きくしても意味がないので，使用するデータのfeature数に合わせて調節する</li>
<li>VWは通常メモリ使わないほうだけど，<code>-b</code>を大きくするとGBレベルでメモリ消費するようになる．最大の<code>-b 32</code>だと64GB程度</li>
</ul>
</li>
</ul>
</li>
<li><a href="http://blogs.technet.com/b/machinelearning/archive/2014/08/13/vowpal-wabbit-for-fast-learning.aspx">Vowpal Wabbit for Fast Learning - Machine Learning - Site Home - TechNet Blogs</a>

<ul>
<li>Vowpal Wabbitの名前の由来が書いてある</li>
</ul>
</li>
<li><a href="http://fastml.com/go-non-linear-with-vowpal-wabbit/">Go non-linear with Vowpal Wabbit - FastML</a>

<ul>
<li>VWの様々な機能(Neural Network,Quadratic and cubic features, N-grams)について

<ul>
<li><a href="https://www.kaggle.com/c/amazon-employee-access-challenge">Amazon.com - Employee Access Challenge | Kaggle</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="http://mlwave.com/movie-review-sentiment-analysis-with-vowpal-wabbit/">Movie Review Sentiment Analysis with Vowpal Wabbit | MLWave</a>

<ul>
<li>映画レビューサイトのテキストを使ったsentiment analysisにVWを使った話

<ul>
<li><a href="http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews">Sentiment Analysis on Movie Reviews | Kaggle</a></li>
</ul>
</li>
<li>vw-varinfoを使うことによってpositive/negativeな単語のfeature relevanceを可視化している</li>
</ul>
</li>
<li><a href="http://fastml.com/vowpal-wabbit-liblinear-sbm-and-streamsvm-compared/">Vowpal Wabbit, Liblinear/SBM and StreamSVM compared - FastML</a>

<ul>
<li>Vowpal Wabbit，LiblinearとStreamSVMの比較</li>
</ul>
</li>
<li><a href="http://hunch.net/~nyoml/">Open Machine Learning</a>

<ul>
<li>以下の2つの講演を見ることができる</li>
<li>" Vowpal Wabbit and Learning to Search by John Langford and Hal Daume"

<ul>
<li><a href="http://msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4">msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4</a></li>
<li><a href="http://research.microsoft.com/apps/video/default.aspx?id=227011">Vowpal Wabbit - Microsoft Research</a>のほうが，講演とスライドが並列に見ることができて便利</li>
</ul>
</li>
<li>"Vowpal Wabbit future plans"

<ul>
<li><a href="http://msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4">msrvideo.vo.msecnd.net/rmcvideos/227009/dl/227009.mp4</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="http://fastml.com/how-to-run-external-programs-from-python-and-capture-their-output/">How to run external programs from Python and capture their output - FastML</a>

<ul>
<li>Vowpal WabbitをPythonから動かして出力をスクリプト内で取得する方法</li>
<li>記事内にも書いてあるけれども，PythonでVowpal Wabbitを扱うならvowpal_porpoiseやpyvw，wabbit_wappaなどのパッケージを使うという手もある</li>
</ul>
</li>
<li><a href="http://hunch.net/?p=222592">Vowpal Wabbit 7.8 at NIPS « Machine Learning (Theory)</a>

<ul>
<li>Vowpal Wabbit 7.8のリリースノート</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[kimonoでKaggleユーザのクロールをしてみた]]></title>
    <link href="http://yagays.github.io/blog/2014/08/18/kaggle-users-japan/"/>
    <updated>2014-08-18T20:37:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/08/18/kaggle-users-japan</id>
    <content type="html"><![CDATA[<p>ふとKaggleに参加している日本人がどれくらいいるのかが気になったので，簡単にクローラーを作って調べてみた．</p>

<h3>Kimonoを使ったクロール</h3>

<p>手動でクローラーを書いてもいいのだけれども，今回は<a href="https://www.kimonolabs.com/">kimono</a>というクローラーを使ってみた．</p>

<ul>
<li>参考：<a href="http://blog.takuros.net/entry/2014/08/13/212838">プログラミング・レスで5分でサックリWebスクレイピング「kimonolabs」 - プログラマになりたい</a></li>
</ul>


<p>kimonoはWebから簡単にクローラーを作成してAPIやJSON形式で取得できるようにするようなアプリケーションで，Chrome Extensionを使うことでインタラクティブにクロールする内容を選択することができる．今回は，<a href="http://www.kaggle.com/users/">Kaggle Rankings</a>のランキング500ページ分をクロールして，20000人分のユーザの情報（名前，ランク，ポイント，ロケーション）を取得した．今回クロールした結果は，以下のkimonoのウェブページから誰でも利用できるはず(アカウント持ってないと見れないかな)．ただしrankとptsが一緒になってたりとちょっと汚いので注意．</p>

<ul>
<li><a href="https://www.kimonolabs.com/apis/dyo7tdm8">https://www.kimonolabs.com/apis/dyo7tdm8</a></li>
</ul>


<p>ちなみに，どれくらい簡単にできるかをgif動画にしてみた．最初は色々戸惑った部分もあったけれど，慣れてしまえば本当に簡単に扱える．以下の場合だと，ユーザ情報がページあたり50人分あるので，ある部分を選択したあとに他の部分も同様に取得するようにチェックを付けるのが重要．あと，paginationはいわゆる「次」にあたる部分を選択する．本当は選択した部分に対して正規表現を掛けてテキスト処理をかけることもできるのだけれども，今回は行っていない．</p>

<p><img src="http://dl.dropboxusercontent.com/u/142306/b/kimono.gif" alt="" /></p>

<h3>後処理</h3>

<p>クロール自体はkimonoに任せることができたので，ここからはpythonスクリプトをちゃちゃっと書いて整形作業．クロールしたデータはJSON形式やcsv形式でダウンロードすることもできるが，今回はAPIから叩いてみる．kimonoの"Use in code"というタブに，CurlやjQuery，Node，PHP，Python，Rubyでそれぞれ書かれたスクリプトがあるので，それを使ってデータを取得する．例えば，curlとPythonだと以下のようになる</p>

<p><code>
$ curl --include --request GET "https://www.kimonolabs.com/api/dyo7tdm8?apikey=7ZTTugRoP8xgIlOdAdyiHmwP4rFLviDO"
</code></p>

<p>```python
import json
import urllib</p>

<p>results = json.load(urllib.urlopen("https://www.kimonolabs.com/api/dyo7tdm8?apikey=7ZTTugRoP8xgIlOdAdyiHmwP4rFLviDO"))
```</p>

<p>今回は日本人のアカウント一覧が欲しいので，"Country of residence"にJapanと書かれていてかつポイントを持っているアカウント一覧を出力した．なお，ユーザプロフィールの記入は基本任意なので，<strong>プロフィールで"Country of residence"を編集していない日本人は対象外になっている</strong>．</p>

<h3>リスト(2014/08/18現在)</h3>

<p>ユーザページに飛べるように一応HTMLにした．気が向いたら定期的にアップデートするようにして，もっときちんと体裁整えるかも．こういった公開も含めてkimono側で簡単なインターフェイスがあると楽なんだけどなーと思った．</p>

<ul>
<li><a href="https://dl.dropboxusercontent.com/u/142306/kaggle_jpn.html">https://dl.dropboxusercontent.com/u/142306/kaggle_jpn.html</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
