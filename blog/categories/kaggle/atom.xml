<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Kaggle | Wolfeyes Bioinformatics beta]]></title>
  <link href="http://yagays.github.io/blog/categories/kaggle/atom.xml" rel="self"/>
  <link href="http://yagays.github.io/"/>
  <updated>2014-09-27T00:54:24+09:00</updated>
  <id>http://yagays.github.io/</id>
  <author>
    <name><![CDATA[yag_ays]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Kaggle初心者がDisplay Advertising Challengeに挑んだ結果354th/718だった]]></title>
    <link href="http://yagays.github.io/blog/2014/09/26/kaggle-criteo-display-advertising-challenge/"/>
    <updated>2014-09-26T16:41:00+09:00</updated>
    <id>http://yagays.github.io/blog/2014/09/26/kaggle-criteo-display-advertising-challenge</id>
    <content type="html"><![CDATA[<p>Kaggleで行われていたcriteoのDisplay Advertising Challengeが終了し，最終的にPublic LB:0.47880，Private LB:0.47831の354th/718だった．1位のチームが0.44464で，Top10あたりが0.44台のスコアを叩き出しているので，結果は惨敗だけれども，個人的には初めてにしては健闘できたほうだと思う．まあ最初の方はLogistic regressionのBenchmarkすら越せなくて厳しい状態だったけれども，そこから抜けだしてある程度成果が出始めると，あとは計算してはサブミットしてを繰り返しスコアに一喜一憂するという感じで競技性があって非常に楽しめた．次はもっと上の方に行きたいと思いつつ，現在参加しているAfrica Soil Property Prediction Challengeは一時期10位圏内まで行ったもののそこから怒涛のランク落ちで現在300位くらいまで下がってしまったので，世間は厳しい．Kaggle Masterへの道はまだまだ遠い．</p>

<h3>予測方法</h3>

<p>さて，こんな中途半端な順位のヤツの解法なんて見てもどうしょうもないとは思うけれども，個人的な記録のためにも書いておく．</p>

<p>使用したのは<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">Vowpal Wabbit</a>(VW)．主に参考にしたのはMLWaveの<a href="http://mlwave.com/predicting-click-through-rates-with-online-machine-learning/">Predicting CTR with online machine learning</a>で，とりあえず動くコードの例があって，あとはVWのパラメータチューニングで頑張ったという流れ．実はこれ以前にscikit-learn+pandasも試していたのだけれども，あまりにデータ量多すぎてpandasのget_dummiesでダミー変数作るのが不可能だったりと早々に諦めていた．その点VWは高速で動いてメモリ消費量も少ないので，初心者にとっては使いやすいソフトウェアだった．あと<a href="https://github.com/MLWave/kaggle-criteo">MLWave/kaggle-criteo</a>でデータ形式の変換コードがあったのが助かった．</p>

<p>さて，最終的なサブミットに使用したのは以下のパラメータ．</p>

<ul>
<li>損失関数(--loss_function)：logistic</li>
<li>Feature Hashingのbit数(-b)：30</li>
<li>L2正則化(--l2): 1e-08</li>
<li>データのイテレーション回数(--passes):10</li>
</ul>


<p>少し前の記事の<a href="http://yagays.github.io/blog/2014/08/31/vowpal-wabbit/">私的Vowpal Wabbitまとめ - Wolfeyes Bioinformatics beta</a>にも書いたけど，loss_functionはlogisticにしておくと学習が終わったときにだいたいのスコアがわかって便利．あと-bを増やすとfeature hashingでcollisionしなくなるけれども，そのかわり必要なメモリ容量が増える．L2正則化はL1とともに1e-01から1e-12くらいまで試したんだけど，スコアが劇的に変わるわけではなかった．--passesは必須だけど，ある程度のイテレーション回数でスコアに変動がなければ途中で切られるみたいなので，最初の方で必要回数を確認してからは変えていない．</p>

<p><code>sh
$ vw click.train.vw -f click.model.b30.pass10.l2_1e-08.vw --loss_function logistic -c -k -b 30 --passes 10 --l2 0.00000001
$ vw click.test.vw -t -i click.model.b30.pass10.l2_1e-08.vw -p click.preds.b30.pass10.l2_1e-08.vw
</code></p>

<h3>感想戦</h3>

<ul>
<li><a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners">Congratulations to the winners! - Display Advertising Challenge | Kaggle</a></li>
</ul>


<p>kaggleのフォーラムで上位ランクの人が自分の解析方法を公開してくれているので，その中からVWに関するトピックを幾つか拾ってみる．</p>

<p>まずは，15thのLuca MassaronがVWを使った解析例を示してくれている(<a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners/54591#post54591">link</a>)．VWのコマンドは非常に参考になるし，自分もNNのHidden Unitsを10とか20でやったんだけどなーと思いつつ，何よりもまずデータの前処理の必要性を感じた．</p>

<p>あとは19thのKonrad BanachewiczはVWのより詳細な結果を示してくれていて(<a href="https://www.kaggle.com/c/criteo-display-ad-challenge/forums/t/10429/congratulations-to-the-winners/54595#post54595">link</a>)，こっちではNNが効かないみたいな話があったり，quadratic feature頑張ってたり，こちらも非常に参考になる．</p>

<p>あとはLibFMとかNNとかAutoencoderとか色々な方法で予測している人がいて，非常に参考になる．</p>

<h3>今後のCriteo Display Advertising Challengeの動向</h3>

<p>Kaggleでのコンペは終わってしまったが，上に書いたようなフォーラムでの議論は続くし，それにコンペ用のデータセットが学術向けに公開された．これでもしかしたら上位ランクのグループの成果が論文として出てくるかもしれない．</p>

<ul>
<li><a href="http://labs.criteo.com/2014/09/kaggle-contest-dataset-now-available-academic-use/">Kaggle contest dataset is now available for academic use! - Criteo Labs</a></li>
</ul>


<p>あと，<a href="https://docs.google.com/file/d/0BzrlDxVZWSUpNFdscnRmUUdJWk5qYVhkVVE0WjV1LUxpZlhr/edit">Criteoの資料</a>によると"Winners will release code publicly(Popular OSI-approved license)"らしいので，ぜひともコードを公開してほしいところ．</p>

<p>といった感じで，まだまだCriteo Display Advertising Challengeは終わらない．</p>

<h4>追記：</h4>

<blockquote class="twitter-tweet" lang="en"><p><a href="https://twitter.com/yag_ays">@yag_ays</a> kaggleのコンペのほとんど（全て？）は、Prizeに入った人は手法の説明とコード(OSI承認ライセンス)をフォーラムに投稿しなければならないとルールに書いてあるので、なんらかトラブルがない限り上位陣の成果は公開されると思います。</p>&mdash; id:ultraist (@ultraistter) <a href="https://twitter.com/ultraistter/status/515428100847304704">September 26, 2014</a></blockquote>


<script async src="http://yagays.github.io//platform.twitter.com/widgets.js" charset="utf-8"></script>



]]></content>
  </entry>
  
</feed>
